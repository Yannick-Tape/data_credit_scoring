th√®se :
# > Chapitre empirique : "AI-Driven Fair Creditworthiness and Credit Scoring:
# > A Two-Decade Analysis in the Tri-State Area (2007‚Äì2024)"


# 0. Imports # # Chapitre empirique ‚Äì Notebook ma√Ætre HMDA + ACS (Tri-State, 2007‚Äì2023)
#
# Ce notebook produit **tous les tableaux et graphiques** mentionn√©s dans le chapitre :
# - Comparaison des cohortes pr√©-IA (2007‚Äì2017) vs IA (2018‚Äì2023)
# - Mod√®les logit "miroirs"
# - Analyses ACS (hmda_acs_tristate_2018_2023_FINAL)
# - Mod√®les ML (RF / XGBoost) et premi√®res m√©triques de fairness
#
# üîó R√©f√©rence et configuration globale

import os
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt

import statsmodels.api as sm
import statsmodels.formula.api as smf

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# XGBoost est optionnel : installe-le si besoin via `pip install xgboost`
try:
    from xgboost import XGBClassifier
    HAS_XGBOOST = True
except ImportError:
    HAS_XGBOOST = False

plt.style.use("default")

# Pour que les DataFrames s'affichent proprement
pd.set_option("display.max_columns", 100)
pd.set_option("display.width", 160)

# Chemin de travail (adapter si n√©cessaire)
BASE_DIR = r"C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work"

CORE_PATH  = os.path.join(BASE_DIR, "hmda_tristate_core_2007_2024_v2.parquet")
MODEL_PATH = os.path.join(BASE_DIR, "hmda_tristate_model_2018_2023_FIXED.parquet")
ACS_PATH   = os.path.join(BASE_DIR, "hmda_acs_tristate_2018_2023_FINAL.parquet")
## 1. Chargement des trois bases et sanity checks
#
# üîó R√©f√©rence chapitre :
# - Section 1.1 et 1.2 : "Pr√©sentation des sources" et "Construction des cohortes"
# - Tableau 1.1 : Vue d'ensemble des trois bases

# 1.1. Chargement des fichiers Parquet

core = pd.read_parquet(CORE_PATH)
model = pd.read_parquet(MODEL_PATH)
hmda_acs = pd.read_parquet(ACS_PATH)

print("core shape :", core.shape)
print("model shape:", model.shape)
print("acs shape  :", hmda_acs.shape)
core shape : (14163286, 12)
model shape: (571820, 15)
acs shape  : (571820, 35)
# 1.2. Aper√ßu des colonnes principales pour v√©rifier la coh√©rence
# (On imprime quelques colonnes cl√©s seulement)

def quick_cols(df, name, n=30):
    print(f"\n=== {name} ‚Äì colonnes (top {n}) ===")
    print(list(df.columns[:n]))

quick_cols(core, "CORE 2007‚Äì2024")
quick_cols(model, "MODEL 2018‚Äì2023")
quick_cols(hmda_acs, "HMDA+ACS 2018‚Äì2023") 


=== CORE 2007‚Äì2024 ‚Äì colonnes (top 30) ===
['action_taken', 'applicant_sex', 'county_code', 'hoepa_status', 'lien_status', 'loan_purpose', 'loan_type', 'preapproval', 'purchaser_type', 'rate_spread', 'state_code', 'year']

=== MODEL 2018‚Äì2023 ‚Äì colonnes (top 30) ===
['year', 'state_code', 'county_code', 'census_tract', 'geoid_tract', 'loan_amount', 'loan_purpose', 'loan_type', 'lien_status', 'hoepa_status', 'action_taken', 'applicant_sex', 'derived_ethnicity', 'derived_race', 'approved']

=== HMDA+ACS 2018‚Äì2023 ‚Äì colonnes (top 30) ===
['year', 'state_code', 'county_code', 'census_tract', 'geoid_tract', 'loan_amount', 'loan_purpose', 'loan_type', 'lien_status', 'hoepa_status', 'action_taken', 'applicant_sex', 'derived_ethnicity', 'derived_race', 'approved', 'NAME', 'acs_median_income', 'acs_pop_total', 'acs_white', 'acs_black', 'acs_asian', 'acs_hispanic', 'acs_unemployed', 'acs_labor_force', 'acs_poverty_num', 'acs_poverty_den', 'state', 'county', 'tract', 'acs_poverty_rate']

## 2. Construction des cohortes pr√©-IA vs IA
#
# üîó R√©f√©rence chapitre :
# - Section 1.2 : "Construction des deux cohortes"
# - Graphique 0.1 : chronologie avec la coupure 2017/2018
#
# Cohortes :
# - pre_ai : ann√©es 2007‚Äì2017 dans la base `core`
# - ai_hmda : ann√©es 2018‚Äì2023 dans la base `model`
# - ai_acs : ann√©es 2018‚Äì2023 dans la base fusionn√©e HMDA+ACS

# 2.1. On suppose que la variable d'ann√©e s'appelle "year" dans les trois bases.
# Adapter si besoin (ex: "activity_year", etc.)

# Filtre pr√©-IA (2007‚Äì2017)
pre_ai = core[(core["year"] >= 2007) & (core["year"] <= 2017)].copy()

# Cohorte IA HMDA-only (le fichier 'model' est d√©j√† restreint √† 2018‚Äì2023)
ai_hmda = model.copy()

# Cohorte IA HMDA+ACS fusionn√©e
ai_acs = hmda_acs.copy()

for name, df in [("pre_ai", pre_ai), ("ai_hmda", ai_hmda), ("ai_acs", ai_acs)]:
    print(f"{name} ‚Äì shape: {df.shape}, ann√©es uniques: {sorted(df['year'].unique())}")

pre_ai ‚Äì shape: (13512746, 12), ann√©es uniques: [np.float64(2007.0), np.float64(2008.0), np.float64(2009.0), np.float64(2010.0), np.float64(2011.0), np.float64(2012.0), np.float64(2013.0), np.float64(2014.0), np.float64(2015.0), np.float64(2016.0), np.float64(2017.0)]
ai_hmda ‚Äì shape: (571820, 15), ann√©es uniques: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]
ai_acs ‚Äì shape: (571820, 35), ann√©es uniques: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]

## 3. Analyse descriptive ‚Äì Taux d'approbation et profils de demandeurs
#
# üîó R√©f√©rence chapitre :
# - Section 2.1 : "Taux d‚Äôapprobation"
# - Section 2.2 : "Profil socio-√©conomique"
# - Figures 2.1‚Äì2.4 et Tableaux 2.1‚Äì2.2
#
# Hypoth√®se :
# - La variable d'approbation est `approved` (0/1) ou d√©riv√©e de "action_taken".

# 3.1. Si la variable "approved" n'existe pas encore, on la cr√©e √† partir d'action_taken.
# Exemple : HMDA moderne -> action_taken = 1 (loan originated) => approved = 1

def ensure_approved_flag(df, action_col="action_taken", approved_col="approved"):
    """
    Cr√©e une variable binaire 'approved' si elle n'existe pas,
    en se basant sur 'action_taken' (HMDA).
    """
    if approved_col in df.columns:
        return df
    df = df.copy()
    # Exemple : 1 = loan originated, 2/3 = applications approved but not accepted ?
    # Ici on code : 1, 2, 3 => 1 ; le reste => 0
    df[approved_col] = df[action_col].isin([1, 2, 3]).astype(int)
    return df

pre_ai = ensure_approved_flag(pre_ai)
ai_hmda = ensure_approved_flag(ai_hmda)
ai_acs = ensure_approved_flag(ai_acs)


print("pre_ai")
pre_ai["approved"].value_counts(normalize=True).head()

pre_ai
approved
1    0.706829
0    0.293171
Name: proportion, dtype: float64

print("ai_hmda")
ai_hmda["approved"].value_counts(normalize=True).head()


ai_hmda
approved
1    0.542304
0    0.457696
Name: proportion, dtype: float64


print("ai_acs")
ai_acs["approved"].value_counts(normalize=True).head()

ai_acs
approved
1    0.542304
0    0.457696
Name: proportion, dtype: float64


'''
√Ä un niveau agr√©g√©, la comparaison entre les deux r√©gimes met en √©vidence une rupture 
nette dans l‚Äôintensit√© globale de l‚Äôoctroi de cr√©dit. Sur la p√©riode pr√©-IA (2007‚Äì2017), 
la proportion moyenne de demandes approuv√©es dans la cohorte pre_ai s‚Äô√©l√®ve √† environ 70,7 %, 
contre 54,2 % seulement dans la cohorte ai_hmda (2018‚Äì2023), soit une baisse de plus de 16 points 
de pourcentage. Autrement dit, le r√©gime d√©cisionnel associ√© √† la phase de g√©n√©ralisation des outils 
algorithmiques op√®re dans un environnement globalement plus restrictif en termes d‚Äôapprobation brute 
des demandes. Cette observation ne constitue pas en soi une preuve causale de l‚Äôimpact de l‚ÄôIA, mais 
elle sugg√®re que le passage d‚Äôun r√©gime pr√©-algorithmique, plus g√©n√©reux en volume d‚Äôapprobations, √† 
un r√©gime post-algorithmique, plus s√©lectif, s‚Äôaccompagne d‚Äôun resserrement structurel de l‚Äôacc√®s au cr√©dit, 
qui doit √™tre examin√© de mani√®re plus fine dans les sections suivantes, en particulier sous l‚Äôangle des 
disparit√©s raciales et territoriales.
'''

# 3.2. Taux d'approbation annuel sur 2007‚Äì2023 (base core)
# üîó Graphique 2.1 ‚Äì "Taux d'approbation, 2007‚Äì2023"

core = ensure_approved_flag(core)
approval_year = (
    core.groupby("year")["approved"]
    .mean()
    .reset_index()
    .rename(columns={"approved": "approval_rate"})
)

fig, ax = plt.subplots(figsize=(8, 4))
ax.plot(approval_year["year"], approval_year["approval_rate"], marker="o")
ax.axvline(2017.5, color="red", linestyle="--", label="Rupture 2017/2018 (IA)")
ax.set_title("Taux d'approbation moyen ‚Äì Tri-State, 2007‚Äì2023")
ax.set_ylabel("Taux d'approbation")
ax.set_xlabel("Ann√©e")
ax.legend()
plt.tight_layout()
plt.show()

approval_year.head()

'''
  # Interpr√©tation du Graphique 2.1 ‚Äì Taux d‚Äôapprobation moyen (2007‚Äì2023)

Le Graphique 2.1 retrace l‚Äô√©volution du taux d‚Äôapprobation moyen des demandes 
de pr√™ts hypoth√©caires dans la r√©gion Tri-State sur la p√©riode 2007‚Äì2023. La s√©rie 
met en √©vidence un niveau initialement √©lev√© des taux d‚Äôapprobation en 2007 et 2008, 
oscillant autour de 72 %, avant de conna√Ætre une rupture nette en 2009, ann√©e marqu√©e par 
l‚Äôintensification de la crise financi√®re mondiale. Cette chute, qui ram√®ne le taux d‚Äôapprobation 
√† environ 67 %, traduit un durcissement brutal des conditions d‚Äôoctroi du cr√©dit, cons√©cutif aux 
pertes massives des institutions financi√®res et aux modifications rapides de leurs politiques de gestion du risque.

√Ä partir de 2010, on observe une phase de stabilisation progressive du taux d‚Äôapprobation, qui se 
maintient autour de 70 %. Cette relative normalisation r√©v√®le l‚Äôinstallation d‚Äôun nouvel √©quilibre 
post-crise, caract√©ris√© par des standards prudentiels plus stricts et une surveillance r√©glementaire renforc√©e. 
Cette p√©riode constitue ainsi une transition entre un r√©gime de d√©cision majoritairement fond√© sur l‚Äô√©valuation 
humaine et des syst√®mes de scoring statistiques relativement simples, vers un environnement plus structur√© et encadr√©.

Enfin, la ligne verticale mat√©rialisant la rupture 2017/2018 permet d‚Äôintroduire visuellement le basculement 
vers ce que cette √©tude qualifie de ¬´ r√©gime algorithmique ¬ª. Cette s√©paration graphique ne pr√©tend pas identifier 
une rupture instantan√©e des pratiques, mais sert de rep√®re analytique pour comparer deux architectures 
d√©cisionnelles : un syst√®me pr√©-algorithmique, domin√© par l‚Äôintervention humaine et les r√®gles internes, 
et un syst√®me post-algorithmique, caract√©ris√© par l‚Äôint√©gration progressive d‚Äôoutils automatis√©s et de mod√®les 
d‚Äôapprentissage automatique. Le graphique constitue ainsi un √©l√©ment cl√© pour comprendre le cadre temporel de 
l‚Äôanalyse comparative d√©velopp√©e dans les sections suivantes.
'''

0	2007.0	0.717529
1	2008.0	0.721486
2	2009.0	0.673220
3	2010.0	0.699725
4	2011.0	0.700351

# 3.3. Tableau 2.1 ‚Äì Taux d'approbation moyen par cohorte et par √âtat (si 'state' ou √©quivalent existe)

if "state" in core.columns:
    approval_by_state = (
        core.groupby(["state", pd.cut(core["year"], [2006, 2017, 2023],
                                      labels=["pre_IA", "IA"])])["approved"]
        .mean()
        .unstack()
    )
    display(approval_by_state)

    # Sauvegarde √©ventuelle pour LaTeX
    out_dir = os.path.join(BASE_DIR, "tables")
    os.makedirs(out_dir, exist_ok=True)
    approval_by_state.to_csv(os.path.join(out_dir, "table_2_1_approval_by_state.csv"))


# Dictionnaire FIPS -> Nom de l'√âtat
state_fips_to_name = {
    9: "Connecticut",
    34: "New Jersey",
    36: "New York"
}

# On garde state_code et on ajoute une nouvelle colonne "state"
approval_by_state_named = approval_by_state.copy()

# Cr√©ation de la colonne lisible "state"
approval_by_state_named["state"] = (
    approval_by_state_named.index
        .astype(int)
        .map(state_fips_to_name)
)

# R√©organisation : state_code reste l'index, state devient une colonne
approval_by_state_named = approval_by_state_named.reset_index()

# Affichage propre
display(approval_by_state_named)

'''
# Commentaire du Tableau 2.1 ‚Äì Taux d‚Äôapprobation par √âtat (p√©riode pr√©-IA, 2007‚Äì2017)
Le Tableau 2.1 met en √©vidence des diff√©rences substantielles dans les taux d‚Äôapprobation moyens 
des demandes de pr√™ts hypoth√©caires entre les √âtats de la r√©gion Tri-State au cours de la p√©riode 
pr√©-algorithmique. L‚Äô√âtat de New York affiche le taux d‚Äôapprobation le plus √©lev√© (environ 73 %), 
suivi du Connecticut (environ 70 %), tandis que le New Jersey pr√©sente le niveau d‚Äôapprobation le 
plus faible (environ 68 %). Ces √©carts, bien que relativement modestes en amplitude, traduisent des 
h√©t√©rog√©n√©it√©s structurelles persistantes dans les pratiques locales d‚Äôoctroi de cr√©dit, qui peuvent 
refl√©ter des diff√©rences institutionnelles entre √©tablissements pr√™teurs, des conditions de march√© 
immobilier distinctes, ainsi que des disparit√©s socio-√©conomiques territoriales.

Ces r√©sultats sugg√®rent que, m√™me avant l‚Äôint√©gration √† grande √©chelle de syst√®mes algorithmiques, 
les d√©cisions de cr√©dit n‚Äô√©taient pas spatialement neutres et s‚Äôinscrivaient d√©j√† dans des logiques 
territorialis√©es. Le fait que New York pr√©sente un taux d‚Äôapprobation syst√©matiquement plus √©lev√© peut 
√™tre interpr√©t√© comme le reflet d‚Äôun march√© plus profond, d‚Äôune plus forte concurrence entre pr√™teurs, 
ou d‚Äôun meilleur acc√®s au cr√©dit pour certaines cat√©gories de m√©nages. √Ä l‚Äôinverse, le New Jersey appara√Æt 
comme un environnement plus contraignant, ce qui constitue un point de comparaison essentiel pour l‚Äôanalyse 
des transformations induites par le passage au r√©gime algorithmique dans les sections suivantes.

Ces √©carts inter√©tatiques servent ainsi de point de d√©part analytique pour √©valuer si l‚Äô√®re de l‚ÄôIA a 
amplifi√©, att√©nu√© ou recompos√© les in√©galit√©s territoriales pr√©existantes dans l‚Äôacc√®s au cr√©dit.
'''
cohort	state_code	pre_IA	state
0	9.0	0.704873	Connecticut
1	34.0	0.681274	New Jersey
2	36.0	0.729269	New York


### 3.4. Profils de revenu et de montant de pr√™t
#
# üîó R√©f√©rence chapitre :
# - Section 2.2 : distribution des revenus et montants de pr√™ts
# - Figures 2.2 et 2.3

# 3.4. Distribution des revenus (si 'applicant_income' existe)

fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)

for ax, df, title in zip(
    axes,
    [ai_hmda, ai_acs],
    ["Cohorte IA (HMDA)", "Cohorte IA (HMDA + ACS)"]
):
    s = pd.to_numeric(df["loan_amount"], errors="coerce").dropna()
    s = s.clip(upper=s.quantile(0.99))
    s.hist(ax=ax, bins=50)

    ax.set_title(title)
    ax.set_xlabel("Montant du pr√™t (99e percentile)")
    ax.set_ylabel("Nombre d'observations")

plt.tight_layout()
plt.show()

'''
La figure 2.2 pr√©sente la distribution des montants de pr√™ts pour la cohorte algorithmique (2018‚Äì2023), 
en comparant la base HMDA standard et la base enrichie HMDA+ACS. Dans les deux cas, les distributions 
affichent une forte asym√©trie √† droite, caract√©ristique des donn√©es de cr√©dit immobilier, avec une 
concentration marqu√©e des observations dans les tranches de montants relativement faibles et interm√©diaires, 
et une longue tra√Æne correspondant aux pr√™ts de tr√®s grande valeur.
La troncation au 99e percentile permet de neutraliser l‚Äôinfluence des valeurs extr√™mes tout en conservant la 
structure centrale de la distribution. Les deux histogrammes pr√©sentent une forme remarquablement similaire, 
ce qui confirme que l‚Äôenrichissement par les donn√©es ACS n‚Äôalt√®re pas la structure des montants de pr√™t observ√©s, 
mais agit principalement comme un enrichissement informationnel contextuel plut√¥t que comme une transformation de l‚Äô√©chantillon.

Ces r√©sultats sugg√®rent que, dans le r√©gime algorithmique, la dynamique du march√© du cr√©dit reste domin√©e par des 
pr√™ts de montants mod√©r√©s, tandis que les pr√™ts de montants exceptionnellement √©lev√©s repr√©sentent une part marginale 
mais non n√©gligeable de l‚Äôactivit√©. Cette structure est coh√©rente avec l‚Äôid√©e que les algorithmes interviennent dans 
un environnement o√π le volume d‚Äôactivit√© est majoritairement concentr√© sur des profils de risque standardis√©s, tandis 
que les cas extr√™mes demeurent relativement rares et potentiellement trait√©s de mani√®re plus sp√©cifique.

En bref, Les distributions des montants de pr√™ts dans les bases HMDA et HMDA+ACS montrent une asym√©trie marqu√©e √† droite, 
avec une concentration importante des observations sur les montants interm√©diaires. La similarit√© des formes entre les deux 
distributions confirme que l‚Äôenrichissement ACS n‚Äôalt√®re pas la structure des montants de pr√™t, mais apporte principalement 
un compl√©ment contextuel pour l‚Äôanalyse des in√©galit√©s territoriales.
'''

fig, ax = plt.subplots(figsize=(6, 4))

s = ai_acs["acs_median_income"]
s = s[(s > 0) & (s < 2_000_000)].dropna()

ax.hist(s, bins=50, log=True)

ax.set_title("Revenu m√©dian de la zone (ACS) ‚Äì √©chelle log")
ax.set_xlabel("Revenu ACS")
ax.set_ylabel("Fr√©quence (log)")

plt.tight_layout()
plt.show()

'''
La figure 2.3 repr√©sente la distribution du revenu m√©dian des zones de recensement (tracts) 
issue de l‚ÄôAmerican Community Survey (ACS) pour la cohorte algorithmique, en utilisant une 
√©chelle logarithmique sur l‚Äôaxe des ordonn√©es. Ce choix m√©thodologique permet de visualiser 
efficacement une distribution fortement asym√©trique, caract√©ris√©e par une concentration importante 
d‚Äôobservations dans les tranches de revenu interm√©diaire et l‚Äôexistence d‚Äôune longue tra√Æne 
correspondant aux zones les plus ais√©es.
La forme de la distribution sugg√®re une h√©t√©rog√©n√©it√© territoriale marqu√©e des conditions socio-√©conomiques 
dans la r√©gion √©tudi√©e. La majorit√© des observations se situent dans une plage de revenus m√©dians relativement 
√©troite, tandis qu‚Äôun nombre plus restreint de tracts affiche des niveaux de revenu tr√®s √©lev√©s. L‚Äô√©chelle 
logarithmique met en √©vidence la structure r√©elle de cette distribution, qui serait difficilement interpr√©table 
sous une √©chelle lin√©aire en raison de la dominance visuelle des valeurs extr√™mes.
Ces r√©sultats confirment que l‚Äôenvironnement √©conomique dans lequel op√®rent les algorithmes de d√©cision de cr√©dit 
est loin d‚Äô√™tre homog√®ne. Ils fournissent une base empirique essentielle pour l‚Äôanalyse des disparit√©s territoriales 
d‚Äôacc√®s au cr√©dit, en montrant que les d√©cisions algorithmiques s‚Äôinscrivent dans un espace de fortes in√©galit√©s de 
richesse locale. Cette h√©t√©rog√©n√©it√© constitue un √©l√©ment central pour interpr√©ter les r√©sultats ult√©rieurs relatifs 
aux biais potentiels et aux m√©canismes de fairness.

En bref, La distribution du revenu m√©dian des tracts, repr√©sent√©e en √©chelle logarithmique, met en √©vidence une forte 
asym√©trie et une h√©t√©rog√©n√©it√© marqu√©e des territoires. La majorit√© des zones se situent dans des niveaux de revenu 
interm√©diaires, tandis qu‚Äôune minorit√© de tracts concentre des niveaux de richesse nettement plus √©lev√©s, soulignant 
l‚Äôimportance du contexte territorial dans l‚Äôanalyse des d√©cisions de cr√©dit.
'''
# ## 4. Mod√®les logit comparatifs (HMDA-only) ‚Äì cohorte pr√©-IA vs IA
#
# üîó R√©f√©rence chapitre :
# - Section 3 : "Mod√®les logit comparatifs"
# - Tableaux 3.1 et 3.2
#
# Ici on estime deux mod√®les logit avec la m√™me sp√©cification :
# - Mod√®le A : pr√©-IA, 2007‚Äì2017 (`pre_ai`)
# - Mod√®le B : IA, 2018‚Äì2023 (`ai_hmda`)

# 4.1. D√©finition de la formule logit commune et estimation

'''
Choix de la sp√©cification des mod√®les : alternatives m√©thodologiques et justification
La construction des mod√®les logit comparatifs entre la p√©riode pr√©-algorithmique (2007‚Äì2017) 
et la p√©riode algorithmique (2018‚Äì2023) a n√©cessit√© un arbitrage m√©thodologique important, li√© 
aux limites structurelles des bases de donn√©es disponibles. En th√©orie, une sp√©cification 
enrichie aurait pu int√©grer des variables continues d√©crivant la situation financi√®re des 
emprunteurs, notamment le montant du pr√™t demand√© (loan_amount) et le revenu individuel (applicant_income)
, g√©n√©ralement consid√©r√©es comme des d√©terminants centraux des d√©cisions d‚Äôoctroi de cr√©dit.

Plusieurs strat√©gies alternatives ont √©t√© envisag√©es.
Une premi√®re option consistait √† estimer des mod√®les asym√©triques, en incluant loan_amount uniquement 
dans la cohorte IA, et en conservant une sp√©cification plus pauvre pour la cohorte pr√©-IA. Bien que 
techniquement faisable, cette approche aurait compromis la comparabilit√© directe des coefficients 
entre les deux r√©gimes, puisque les mod√®les n‚Äôauraient pas repos√© sur la m√™me information. Dans ce cas, 
toute diff√©rence observ√©e entre les p√©riodes aurait pu refl√©ter autant une diff√©rence de sp√©cification 
qu‚Äôun changement r√©el de logique d√©cisionnelle.

Une deuxi√®me alternative aurait √©t√© de restreindre l‚Äôanalyse √† la cohorte IA enrichie par les donn√©es 
ACS, et de substituer au revenu individuel des variables de contexte territorial (revenu m√©dian de la 
zone, taux de pauvret√©, ch√¥mage local). Cette approche est pertinente pour analyser les disparit√©s socio-spatiales, 
mais elle ne permet pas de maintenir un strict parall√®le avec la p√©riode pr√©-IA, qui ne dispose pas de variables 
√©quivalentes. Elle aurait donc d√©plac√© l‚Äôobjet de l‚Äôanalyse, en passant d‚Äôune comparaison de r√©gimes d√©cisionnels 
√† une analyse transversale propre √† la seule p√©riode algorithmique.

Une troisi√®me possibilit√© aurait √©t√© d‚Äôintroduire des imputations statistiques ou des proxys de revenu pour la p√©riode 
pr√©-IA, √† partir de donn√©es agr√©g√©es externes. Toutefois, une telle strat√©gie aurait introduit un niveau d‚Äôincertitude 
m√©thodologique √©lev√©, difficilement d√©fendable dans un cadre de recherche doctorale ax√©e sur la robustesse et la 
transparence des inf√©rences.

Compte tenu de ces contraintes, le choix m√©thodologique retenu repose sur le principe de parcimonie comparablistique : les 
mod√®les A (pr√©-IA) et B (IA) sont estim√©s avec une sp√©cification strictement identique, limit√©e aux variables effectivement 
observ√©es et communes aux deux cohortes. Cette sp√©cification inclut uniquement la finalit√© du pr√™t, le type de pr√™t, le statut 
HOEPA et une tendance temporelle, excluant volontairement toute variable absente d‚Äôau moins une des p√©riodes.

Ce choix permet de garantir que les diff√©rences estim√©es entre les deux mod√®les refl√®tent effectivement des transformations 
dans la structure des d√©cisions de cr√©dit, et non des artefacts li√©s √† une asym√©trie d‚Äôinformation entre les bases. Il offre 
ainsi un cadre d‚Äôidentification plus cr√©dible pour analyser la transition d‚Äôun r√©gime domin√© par la d√©cision humaine 
discr√©tionnaire vers un r√©gime caract√©ris√© par une plus forte formalisation algorithmique.

En ce sens, l‚Äôadoption d‚Äôune sp√©cification commune peut √™tre interpr√©t√©e non comme une limitation, mais comme une condition 
de validit√© interne de la comparaison intertemporelle, assurant que les contrastes observ√©s entre les coefficients du mod√®le 
A et du mod√®le B traduisent bien des diff√©rences structurelles de comportement institutionnel, plut√¥t que des effets m√©caniques
de disponibilit√© des donn√©es.

En bref, Plusieurs sp√©cifications alternatives ont √©t√© envisag√©es, notamment l‚Äôint√©gration asym√©trique du montant 
du pr√™t uniquement dans la cohorte IA ou l‚Äôutilisation de proxys territoriaux du revenu issus de l‚ÄôACS. 
Ces approches ont √©t√© √©cart√©es afin de pr√©server la comparabilit√© stricte des mod√®les. Le choix a √©t√© fait 
d‚Äôestimer deux mod√®les logit reposant sur une sp√©cification strictement identique, limit√©e aux variables 
communes aux deux p√©riodes, afin de garantir que les diff√©rences observ√©es refl√®tent bien une transformation 
du r√©gime d√©cisionnel et non une simple asym√©trie d‚Äôinformation entre les bases.
'''

def remove_rare_categories(df, col, min_freq=5000):
    counts = df[col].value_counts()
    keep = counts[counts >= min_freq].index
    return df[df[col].isin(keep)]

# Nettoyage des cat√©gories probl√©matiques
for col in ["loan_purpose", "loan_type", "hoepa_status"]:
    pre_ai = remove_rare_categories(pre_ai, col)
    ai_hmda = remove_rare_categories(ai_hmda, col)

logit_formula_stable = (
    "approved ~ C(loan_purpose) + C(loan_type) + C(hoepa_status) + year"
)

logit_pre = smf.logit(logit_formula_stable, data=pre_ai).fit(disp=False)
print("=== Mod√®le pr√©-IA (stable) ===")
print(logit_pre.summary())

logit_ai = smf.logit(logit_formula_stable, data=ai_hmda).fit(disp=False)
print("=== Mod√®le IA (stable) ===")
print(logit_ai.summary())

'''
    # Commentaire interpr√©tatif ‚Äì Mod√®les logit pr√©-IA vs IA (HMDA-only)
Les r√©sultats pr√©sent√©s dans les tableaux 3.1 (p√©riode pr√©-IA) et 3.2 (p√©riode IA) mettent en √©vidence 
une transformation profonde de la structure des d√©cisions d‚Äôoctroi de cr√©dit entre les deux r√©gimes.
Dans la p√©riode pr√©-algorithmique (2007‚Äì2017), le mod√®le pr√©sente un pseudo R¬≤ d‚Äôenviron 0,03, ce qui 
indique une capacit√© explicative relativement faible des variables observ√©es issues du reporting HMDA. 
Cette faible performance sugg√®re que les d√©cisions d‚Äôoctroi reposaient largement sur des √©l√©ments non 
observables dans les donn√©es standardis√©es, tels que le jugement discr√©tionnaire des underwriters, des 
informations qualitatives issues de la relation bancaire, ou des processus internes propres aux institutions 
financi√®res. N√©anmoins, certaines variables contractuelles conservent un pouvoir explicatif significatif : certaines 
finalit√©s de pr√™t sont associ√©es √† des probabilit√©s d‚Äôapprobation plus √©lev√©es, tandis que plusieurs types de 
pr√™ts pr√©sentent des p√©nalit√©s statistiques robustes.
√Ä l‚Äôinverse, dans la p√©riode algorithmique (2018‚Äì2023), le mod√®le atteint un pseudo R¬≤ d‚Äôenviron 0,38, ce qui 
traduit une structuration beaucoup plus forte des d√©cisions autour de r√®gles explicites et codifiables. 
Les coefficients associ√©s aux finalit√©s de pr√™t pr√©sentent des amplitudes beaucoup plus marqu√©es, avec 
certaines cat√©gories fortement favoris√©es et d‚Äôautres quasi syst√©matiquement rejet√©es. Le statut HOEPA 
appara√Æt comme un d√©terminant particuli√®rement discriminant, traduisant l‚Äôint√©gration de contraintes 
r√©glementaires et de filtres de risque directement incorpor√©s dans les logiques d√©cisionnelles. 
La tendance temporelle est √©galement beaucoup plus prononc√©e, sugg√©rant un ajustement dynamique du seuil 
d‚Äôacceptation au cours de la p√©riode algorithmique.

    # Justification du choix de sp√©cification commune
Le choix de cette sp√©cification repose sur une contrainte structurelle majeure li√©e √† la disponibilit√© des donn√©es. 
La base pr√©-IA ne contient ni le montant du pr√™t (loan_amount), ni le revenu individuel de l‚Äôemprunteur (applicant_income). 
La base IA (HMDA-only) contient le montant du pr√™t, mais ne dispose pas non plus d‚Äôune variable de revenu individuel. 
En cons√©quence, il est impossible de construire des variables transform√©es homog√®nes telles que log_loan_amount et 
log_income de mani√®re coh√©rente sur l‚Äôensemble de l‚Äô√©chantillon.

Plusieurs alternatives ont √©t√© envisag√©es, notamment l‚Äôestimation de mod√®les enrichis sp√©cifiques √† la p√©riode IA, 
ou l‚Äôutilisation de proxys territoriaux issus de l‚ÄôACS. Ces options ont √©t√© volontairement √©cart√©es dans le cadre de 
la comparaison principale, car elles auraient rompu la sym√©trie informationnelle entre les deux p√©riodes. Le choix a 
donc √©t√© fait de privil√©gier une approche de comparabilit√© stricte, en estimant deux mod√®les reposant sur une sp√©cification 
rigoureusement identique et limit√©e aux variables r√©ellement observ√©es dans les deux cohortes.

Ce choix m√©thodologique permet d‚Äôinterpr√©ter les diff√©rences entre les coefficients du mod√®le pr√©-IA et du mod√®le IA comme 
le reflet d‚Äôune transformation r√©elle du r√©gime d√©cisionnel, et non comme un artefact li√© √† une asym√©trie de donn√©es. Autrement 
dit, la diff√©rence de performance et de structure entre les deux mod√®les constitue un indice empirique robuste d‚Äôune formalisation 
accrue des r√®gles d‚Äôoctroi dans la p√©riode post-2017.

    # En bref,
Les estimations comparatives des mod√®les logit r√©v√®lent une rupture nette entre les p√©riodes pr√©-IA et IA. Alors que les 
d√©cisions d‚Äôoctroi apparaissent faiblement expliqu√©es par les variables observables durant la p√©riode pr√©-algorithmique, 
elles deviennent beaucoup plus syst√©matiques et pr√©visibles dans la p√©riode algorithmique. Ce contraste soutient l‚Äôhypoth√®se 
d‚Äôune mont√©e en puissance de r√®gles formalis√©es et de proc√©dures automatis√©es dans le processus d‚Äôoctroi du cr√©dit.

'''
=== Mod√®le pr√©-IA (stable) ===
                           Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:             13511720
Model:                          Logit   Df Residuals:                 13511713
Method:                           MLE   Df Model:                            6
Date:                Mon, 24 Nov 2025   Pseudo R-squ.:                 0.02917
Time:                        18:59:22   Log-Likelihood:            -7.9359e+06
converged:                       True   LL-Null:                   -8.1744e+06
Covariance Type:            nonrobust   LLR p-value:                     0.000
==========================================================================================
                             coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------------
Intercept                -20.0442      0.390    -51.418      0.000     -20.808     -19.280
C(loan_purpose)[T.2.0]     1.0863      0.003    342.960      0.000       1.080       1.093
C(loan_purpose)[T.3.0]    -0.0148      0.001    -11.440      0.000      -0.017      -0.012
C(loan_type)[T.2.0]       -0.7786      0.002   -510.010      0.000      -0.782      -0.776
C(loan_type)[T.3.0]       -0.4629      0.004   -118.745      0.000      -0.471      -0.455
C(loan_type)[T.4.0]       -0.5534      0.008    -68.006      0.000      -0.569      -0.537
year                       0.0105      0.000     53.950      0.000       0.010       0.011
==========================================================================================
=== Mod√®le IA (stable) ===
                           Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:               569500
Model:                          Logit   Df Residuals:                   569490
Method:                           MLE   Df Model:                            9
Date:                Mon, 24 Nov 2025   Pseudo R-squ.:                  0.3812
Time:                        18:59:39   Log-Likelihood:            -2.4301e+05
converged:                       True   LL-Null:                   -3.9270e+05
Covariance Type:            nonrobust   LLR p-value:                     0.000
=========================================================================================
                            coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------
Intercept              -213.3616      4.705    -45.351      0.000    -222.583    -204.141
C(loan_purpose)[T.2]      0.3186      0.016     20.012      0.000       0.287       0.350
C(loan_purpose)[T.4]      0.3594      0.017     20.999      0.000       0.326       0.393
C(loan_purpose)[T.5]     -4.6193      0.088    -52.375      0.000      -4.792      -4.446
C(loan_purpose)[T.31]     0.3716      0.010     37.261      0.000       0.352       0.391
C(loan_purpose)[T.32]     0.3505      0.011     32.863      0.000       0.330       0.371
C(loan_type)[T.2]        -0.7475      0.011    -69.893      0.000      -0.768      -0.727
C(loan_type)[T.3]        -0.4651      0.017    -27.020      0.000      -0.499      -0.431
C(hoepa_status)[T.3]     -3.5122      0.008   -432.025      0.000      -3.528      -3.496
year                      0.1064      0.002     45.673      0.000       0.102       0.111
=========================================================================================
Variable / Indicateur	Pr√©-IA (2007‚Äì2017)	IA (2018‚Äì2023)	Interpr√©tation comparative
Nombre d‚Äôobservations	13 511 720	569 500	Forte asym√©trie d‚Äô√©chantillons entre p√©riodes, mais stabilit√© des r√©sultats structurels.
Pseudo R¬≤	0,029	0,381	Le mod√®le explique tr√®s peu de variance en pr√©-IA, mais devient tr√®s explicatif en r√©gime IA ‚Üí d√©cisions plus codifi√©es.
Effet loan_purpose (g√©n√©ral)	Effets h√©t√©rog√®nes, un cas fortement favorable (T.2.0)	Effets structur√©s, plusieurs cat√©gories favoris√©es	Passage d‚Äôun sch√©ma flou √† un sch√©ma d√©cisionnel standardis√©.
loan_purpose = 2	Coef ‚âà +1,09 (odds √ó2,96)	Coef ‚âà +0,32 (odds √ó1,38)	Impact toujours positif mais plus mod√©r√© en r√©gime IA.
loan_purpose = 3	Coef ‚âà ‚àí0,015 (quasi neutre)	Non pr√©sent	Diff√©rences de codification entre p√©riodes.
loan_purpose = 5	Non pr√©sent	Coef ‚âà ‚àí4,62 (odds √ó0,01)	En IA : cat√©gorie pratiquement automatiquement rejet√©e.
loan_purpose = 31‚Äì32	Non pr√©sent	Coef ‚âà +0,35 √† +0,37	En IA : cat√©gories syst√©matiquement favoris√©es.
Effet loan_type (g√©n√©ral)	Tous les types alternatifs p√©nalis√©s	M√™me structure de p√©nalisation	Continuit√© du syst√®me de pr√©f√©rence de risque entre r√©gimes.
loan_type = 2	Coef ‚âà ‚àí0,78 (odds √ó0,46)	Coef ‚âà ‚àí0,75 (odds √ó0,47)	Effet n√©gatif stable dans le temps.
loan_type = 3	Coef ‚âà ‚àí0,46 (odds √ó0,63)	Coef ‚âà ‚àí0,47 (odds √ó0,63)	Stabilit√© remarquable des p√©nalit√©s.
loan_type = 4	Coef ‚âà ‚àí0,55	Non pr√©sent	Diff√©rences de structure des donn√©es entre cohortes.
Effet HOEPA (hoepa_status)	Non discriminant / non structur√©	Coef ‚âà ‚àí3,51 (odds √ó0,03)	En IA : filtrage du risque tr√®s agressif sur produits √† risque.
Effet du temps (year)	Coef ‚âà +0,0105 (~+1,1 %/an)	Coef ‚âà +0,1064 (~+11 %/an)	Acc√©l√©ration forte de l‚Äôassouplissement post-IA.
Lecture globale	D√©cisions peu explicables par variables HMDA	D√©cisions fortement gouvern√©es par r√®gles observables	Transition vers d√©cision algorithmique plus standardis√©e.
# %% [markdown]
# ## 5. Disparit√©s raciales ‚Äì mod√®les logit avec race/ethnicit√©
#
# üîó R√©f√©rence chapitre :
# - Section 4 : "Disparit√©s raciales pr√©-IA vs IA"
# - Tableaux 4.1 et 4.2
#
# Hypoth√®se :
# - Variables de race : `race_white`, `race_black`, `race_hispanic`, etc. OU `applicant_race_1_name`.
# Adapter la formule √† ton encoding r√©el.


# On repart de la formule stable commune (sans race)
logit_formula_stable = (
    "approved ~ C(loan_purpose) + C(loan_type) + C(hoepa_status) + year"
)

print("Colonnes pr√©-IA :", [c for c in pre_ai.columns if "race" in c.lower() or "ethnic" in c.lower()])
print("Colonnes IA     :", [c for c in ai_hmda.columns if "race" in c.lower() or "ethnic" in c.lower()])

# 5.1. Mod√®le avec race pour la cohorte IA uniquement
if "derived_race" in ai_hmda.columns:
    logit_formula_ia_race = logit_formula_stable + " + C(derived_race)"
elif "derived_ethnicity" in ai_hmda.columns:
    logit_formula_ia_race = logit_formula_stable + " + C(derived_ethnicity)"
else:
    raise ValueError("Aucune variable de race/ethnicit√© trouv√©e dans ai_hmda.")

# Estimation mod√®le IA avec race
logit_ai_race = smf.logit(logit_formula_ia_race, data=ai_hmda.dropna()).fit(disp=False)
print(logit_ai_race.summary().tables[1])

Colonnes pr√©-IA : []
Colonnes IA     : ['derived_ethnicity', 'derived_race']
================================================================================================================================
                                                                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------------------------
Intercept                                                     -268.7664      4.834    -55.597      0.000    -278.241    -259.292
C(loan_purpose)[T.2]                                             0.3019      0.016     18.456      0.000       0.270       0.334
C(loan_purpose)[T.4]                                             0.3427      0.018     19.543      0.000       0.308       0.377
C(loan_purpose)[T.5]                                            -4.1515      0.101    -41.291      0.000      -4.349      -3.954
C(loan_purpose)[T.31]                                            0.3932      0.010     38.742      0.000       0.373       0.413
C(loan_purpose)[T.32]                                            0.3880      0.011     35.646      0.000       0.367       0.409
C(loan_type)[T.2]                                               -0.6386      0.011    -58.219      0.000      -0.660      -0.617
C(loan_type)[T.3]                                               -0.3850      0.017    -22.135      0.000      -0.419      -0.351
C(hoepa_status)[T.3]                                            -3.6233      0.008   -426.523      0.000      -3.640      -3.607
C(derived_race)[T.American Indian or Alaska Native]             -0.0203      0.129     -0.157      0.875      -0.274       0.233
C(derived_race)[T.Asian]                                         0.4341      0.108      4.013      0.000       0.222       0.646
C(derived_race)[T.Black or African American]                     0.1389      0.108      1.283      0.199      -0.073       0.351
C(derived_race)[T.Free Form Text Only]                          -0.2858      0.238     -1.200      0.230      -0.753       0.181
C(derived_race)[T.Joint]                                         0.3687      0.112      3.301      0.001       0.150       0.588
C(derived_race)[T.Native Hawaiian or Other Pacific Islander]    -0.0758      0.140     -0.540      0.589      -0.351       0.199
C(derived_race)[T.Race Not Available]                           -0.7873      0.108     -7.321      0.000      -0.998      -0.577
C(derived_race)[T.White]                                         0.2776      0.107      2.585      0.010       0.067       0.488
year                                                             0.1338      0.002     55.925      0.000       0.129       0.138
================================================================================================================================

'''
    # Analyse fairness :

Les r√©sultats du mod√®le logit int√©grant les variables de race pour la p√©riode IA (2018‚Äì2023) mettent en 
√©vidence une reconfiguration des dynamiques de fairness sous r√©gime algorithmique.
Contrairement aux attentes issues de la litt√©rature sur la discrimination historique du cr√©dit, le mod√®le 
ne d√©tecte aucune p√©nalit√© statistiquement significative associ√©e aux emprunteurs noirs, une fois contr√¥l√©s 
les d√©terminants structurels du pr√™t (type, finalit√©, statut HOEPA, ann√©e).

Ce r√©sultat sugg√®re une transition d‚Äôun r√©gime de discrimination potentiellement directe vers des logiques 
de s√©lection davantage indirectes, structurelles ou informationnelles.

   ## Trois r√©gularit√©s fortes √©mergent :
        1. Avantage relatif pour certains groupes
Les emprunteurs asiatiques et blancs b√©n√©ficient d‚Äôun avantage statistiquement significatif, ce qui sugg√®re 
que les algorithmes capturent des signaux corr√©l√©s √† des profils historiquement favoris√©s (stabilit√© patrimoniale, 
zones g√©ographiques, type de produits financiers).

        2. P√©nalit√© informationnelle comme proxy de risque
La variable Race Not Available est tr√®s fortement p√©nalis√©e, ce qui indique que les syst√®mes automatis√©s valorisent 
fortement la compl√©tude de l‚Äôinformation. Ce m√©canisme peut produire une forme de discrimination indirecte, car les 
groupes historiquement marginalis√©s sont plus susceptibles d‚Äôavoir des dossiers incomplets.

        3. Effacement de la discrimination explicite
L‚Äôabsence de significativit√© pour les emprunteurs noirs ne signifie pas absence d‚Äôin√©galit√©s, mais plut√¥t une mutation 
de leur nature : la discrimination ne passe plus par la race d√©clar√©e, mais par des variables corr√©l√©es (type de produit, 
localisation, statut r√©glementaire, qualit√© du dossier).

En somme, le r√©gime IA ne supprime pas les in√©galit√©s, il les reconfigure sous une forme plus algorithmique, plus indirecte 
et potentiellement plus difficile √† d√©tecter.
'''

Groupe racial (derived_race)	Coefficient (logit)	p-value	Significativit√©	Odds Ratio (‚âà)	Effet sur la probabilit√© d‚Äôapprobation	Lecture en termes de fairness
Asian	+0.434	< 0.001	Oui	1.54	+54 %	Avantage significatif ‚Üí profil favoris√© par l‚Äôalgorithme
White	+0.278	0.010	Oui	1.32	+32 %	Avantage significatif ‚Üí traitement pr√©f√©rentiel relatif
Joint	+0.369	0.001	Oui	1.45	+45 %	Les dossiers conjoints sont favoris√©s
Black or African American	+0.139	0.199	Non	1.15	Non significatif	Aucune preuve de discrimination directe dans le mod√®le conditionnel
American Indian / Alaska Native	‚àí0.020	0.875	Non	0.98	Non significatif	Pas d‚Äôeffet mesurable
Native Hawaiian / Pacific Islander	‚àí0.076	0.589	Non	0.93	Non significatif	Aucun effet d√©tect√©
Free Form Text Only	‚àí0.286	0.230	Non	0.75	Non significatif	Effet n√©gatif non robuste
Race Not Available	‚àí0.787	< 0.001	Oui	0.46	‚àí54 %	Forte p√©nalit√© ‚Üí discrimination indirecte via qualit√© de l‚Äôinformation
Effet temporel (year)	+0.134	< 0.001	Oui	1.14/an	Hausse annuelle des chances d‚Äôapprobation	L‚Äôalgorithme devient progressivement plus permissif

'''
Les r√©sultats mettent en √©vidence une transformation des m√©canismes de discrimination sous r√©gime algorithmique. 
La race noire n‚Äôest plus associ√©e √† une p√©nalit√© directe statistiquement significative, mais des disparit√©s 
persistent via des canaux indirects, notamment la qualit√© de l‚Äôinformation et les cat√©gories administratives. 
Les emprunteurs asiatiques et blancs b√©n√©ficient d‚Äôun avantage syst√©matique, traduisant une reconfiguration de 
la fairness davantage fond√©e sur la structure informationnelle des dossiers que sur la race d√©clar√©e.
'''

Groupe racial (derived_race)	Coefficient (logit)	Significatif ? (p-value)	Odds ratio approx.	Interpr√©tation conditionnelle (√† caract√©ristiques de pr√™t identiques)
Asian	+0.4341	Oui (p < 0.001)	‚âà 1.54	Les emprunteurs asiatiques ont ‚âà 54 % de chances d‚Äôapprobation en plus que la cat√©gorie de r√©f√©rence.
White	+0.2776	Oui (p ‚âà 0.010)	‚âà 1.32	Les emprunteurs blancs ont ‚âà 32 % de chances d‚Äôapprobation en plus que la cat√©gorie de r√©f√©rence.
Joint (dossier conjoint)	+0.3687	Oui (p ‚âà 0.001)	‚âà 1.45	Les demandes conjointes pr√©sentent ‚âà 45 % de chances d‚Äôapprobation en plus.
Race Not Available	‚àí0.7873	Oui (p < 0.001)	‚âà 0.46	Les dossiers sans information de race ont ‚âà 54 % de chances d‚Äôapprobation en moins ‚Üí forte p√©nalit√©.
American Indian or Alaska Native	‚àí0.0203	Non (p ‚âà 0.875)	‚âà 0.98	Pas de diff√©rence statistiquement d√©tectable par rapport √† la cat√©gorie de r√©f√©rence.
Black or African American	+0.1389	Non (p ‚âà 0.199)	‚âà 1.15	Coefficient positif mais non significatif ‚Üí aucune preuve statistique d‚Äôun traitement diff√©rent.
Native Hawaiian or Other Pacific Islander	‚àí0.0758	Non (p ‚âà 0.589)	‚âà 0.93	Pas d‚Äôeffet significatif identifi√©.
Free Form Text Only	‚àí0.2858	Non (p ‚âà 0.230)	‚âà 0.75	Effet n√©gatif non significatif ‚Üí interpr√©tation prudente.

'''
Lecture : les coefficients sont interpr√©t√©s relativement √† une cat√©gorie de r√©f√©rence implicite. 
Les r√©sultats montrent un avantage significatif pour les emprunteurs asiatiques et blancs, ainsi 
qu‚Äôune forte p√©nalit√© pour les dossiers sans information de race, tandis qu‚Äôaucune diff√©rence 
statistiquement significative n‚Äôest d√©tect√©e pour les emprunteurs noirs dans ce mod√®le conditionnel.
'''

race_cols_pre = [c for c in pre_ai.columns if "race" in c.lower() or "ethnic" in c.lower()]
if len(race_cols_pre) == 0:
    print("‚ö†Ô∏è Aucun indicateur de race/ethnicit√© disponible dans la cohorte pr√©-IA :")
    print("   ‚Üí impossible d‚Äôestimer un mod√®le logit avec race pour 2007‚Äì2017 avec cette base.")


'''
        # Notes pour la section ¬´ Disparit√©s raciales ¬ª / limites m√©thodologiques :

L‚Äôabsence totale d‚Äôindicateur de race ou d‚Äôethnicit√© dans la cohorte pr√©-IA (2007‚Äì2017) a des cons√©quences 
m√©thodologiques majeures pour l‚Äôanalyse des in√©galit√©s. Concr√®tement, cela signifie qu‚Äôil est **impossible 
d‚Äôestimer un mod√®le logit conditionnel int√©grant la race** pour la p√©riode pr√©-algorithmique √† partir de 
cette base. On ne peut donc pas comparer de mani√®re sym√©trique les coefficients raciaux entre le r√©gime 
pr√©-IA et le r√©gime IA : toute analyse des disparit√©s raciales reste structurellement cantonn√©e √† la p√©riode 2018‚Äì2023.

Cette contrainte limite la port√©e des conclusions en termes d‚Äô√©volution historique de la discrimination. 
On peut montrer, pour la cohorte IA, comment les probabilit√©s d‚Äôapprobation varient selon la race, toutes 
choses √©gales par ailleurs, mais on ne peut pas dire si ces √©carts se sont accentu√©s, r√©duits ou simplement 
reconfigur√©s** par rapport √† la p√©riode ant√©rieure. En d‚Äôautres termes, l‚Äôanalyse de fairness est transversale 
pour la p√©riode algorithmique, mais ne peut pas √™tre pleinement intertemporelle.

En pratique, cela impose une strat√©gie en deux temps :
    1. utiliser des mod√®les **sans race** pour comparer la structure globale des d√©cisions pr√©-IA vs IA (sp√©cification commune, 
        centr√©e sur les caract√©ristiques du pr√™t) ;
    2. analyser les **disparit√©s raciales uniquement dans le r√©gime IA**, en reconnaissant explicitement que cette partie de 
        l‚Äôanalyse ne dispose pas de contre-factuel direct avant 2018.

Cette limitation n‚Äôinvalide pas les r√©sultats, mais elle doit √™tre clairement assum√©e comme une contrainte 
de donn√©es : les conclusions sur la fairness raciale portent sur l‚Äôarchitecture algorithmique contemporaine, 
et non sur une trajectoire longue de la discrimination de 2007 √† 2023.

'''
‚ö†Ô∏è Aucun indicateur de race/ethnicit√© disponible dans la cohorte pr√©-IA :
   ‚Üí impossible d‚Äôestimer un mod√®le logit avec race pour 2007‚Äì2017 avec cette base.


## 6. Mod√®les enrichis HMDA+ACS (2018‚Äì2023)
#
# üîó R√©f√©rence chapitre :
# - Section 5 : "Mod√®les enrichis ACS"
# - Tableaux 5.1 et 5.2, Figures 5.X
#
# Dans cette section, on utilise `ai_acs` pour :
# - estimer un logit enrichi avec variables ACS,
# - comparer HMDA-only vs HMDA+ACS,
# - analyser l'√©volution des coefficients raciaux apr√®s ajout ACS.

# 6.1. Exemple de variables ACS (adapter aux vrais noms de colonnes)
acs_cols = [c for c in ai_acs.columns if c.startswith("acs_")]
print("Variables ACS d√©tect√©es :", acs_cols[:20])

# 6.1. Exemple de variables ACS (adapter aux vrais noms de colonnes)
acs_cols = [c for c in ai_acs.columns if c.startswith("acs_")]
print("Variables ACS d√©tect√©es :", acs_cols[:20])

Variables ACS d√©tect√©es : ['acs_median_income', 'acs_pop_total', 'acs_white', 'acs_black', 'acs_asian', 'acs_hispanic', 'acs_unemployed', 'acs_labor_force', 'acs_poverty_num', 'acs_poverty_den', 'acs_poverty_rate', 'acs_unemployment_rate', 'acs_share_white', 'acs_share_black', 'acs_share_asian', 'acs_share_hispanic']


# 6.2. Construction d'un mod√®le logit enrichi HMDA+ACS

# Mod√®le HMDA-only (r√©f√©rence)
logit_hmda = smf.logit(
    "approved ~ C(loan_purpose) + C(loan_type) + C(hoepa_status) + year",
    data=ai_hmda.dropna()
).fit(disp=False)

print(logit_hmda.summary())


                           Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:               565880
Model:                          Logit   Df Residuals:                   565870
Method:                           MLE   Df Model:                            9
Date:                Tue, 25 Nov 2025   Pseudo R-squ.:                  0.3809
Time:                        16:43:12   Log-Likelihood:            -2.4146e+05
converged:                      False   LL-Null:                   -3.8999e+05
Covariance Type:            nonrobust   LLR p-value:                     0.000
=========================================================================================
                            coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------
Intercept              -208.5348      4.723    -44.156      0.000    -217.791    -199.279
C(loan_purpose)[T.2]      0.3146      0.016     19.665      0.000       0.283       0.346
C(loan_purpose)[T.4]      0.3491      0.017     20.240      0.000       0.315       0.383
C(loan_purpose)[T.5]     -4.8747      0.100    -48.587      0.000      -5.071      -4.678
C(loan_purpose)[T.31]     0.3669      0.010     36.710      0.000       0.347       0.387
C(loan_purpose)[T.32]     0.3487      0.011     32.609      0.000       0.328       0.370
C(loan_type)[T.2]        -0.7453      0.011    -69.556      0.000      -0.766      -0.724
C(loan_type)[T.3]        -0.4649      0.017    -26.983      0.000      -0.499      -0.431
C(hoepa_status)[T.3]     -3.5132      0.008   -430.075      0.000      -3.529      -3.497
year                      0.1040      0.002     44.478      0.000       0.099       0.109
=========================================================================================


# 6.2. Construction d'un mod√®le logit enrichi HMDA+ACS
acs_vars = [
    "acs_median_income",
    "acs_poverty_rate",
    "acs_unemployment_rate",
    "acs_share_black",
    "acs_share_hispanic"
]

# Conversion en num√©rique + nettoyage
for col in acs_vars:
    ai_acs[col] = pd.to_numeric(ai_acs[col], errors="coerce")

logit_acs = smf.logit(
    "approved ~ C(loan_purpose) + C(loan_type) + C(hoepa_status) + year "
    "+ acs_median_income + acs_poverty_rate + acs_unemployment_rate "
    "+ acs_share_black + acs_share_hispanic",
    data=ai_acs.dropna()
).fit(disp=False)

print(logit_acs.summary())


                          Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:               520457
Model:                          Logit   Df Residuals:                   520440
Method:                           MLE   Df Model:                           16
Date:                Tue, 25 Nov 2025   Pseudo R-squ.:                  0.3779
Time:                        16:44:20   Log-Likelihood:            -2.2340e+05
converged:                       True   LL-Null:                   -3.5910e+05
Covariance Type:            nonrobust   LLR p-value:                     0.000
=========================================================================================
                            coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------
Intercept              -194.9197      5.000    -38.984      0.000    -204.720    -185.120
C(loan_purpose)[T.2]      0.3259      0.017     19.634      0.000       0.293       0.358
C(loan_purpose)[T.4]      0.3617      0.018     20.147      0.000       0.327       0.397
C(loan_purpose)[T.5]     -4.8315      0.101    -47.862      0.000      -5.029      -4.634
C(loan_purpose)[T.31]     0.4185      0.010     40.095      0.000       0.398       0.439
C(loan_purpose)[T.32]     0.3872      0.011     34.645      0.000       0.365       0.409
C(loan_type)[T.2]        -0.7643      0.011    -67.334      0.000      -0.787      -0.742
C(loan_type)[T.3]        -0.4581      0.018    -25.682      0.000      -0.493      -0.423
C(loan_type)[T.4]        -0.4399      0.060     -7.316      0.000      -0.558      -0.322
C(hoepa_status)[T.2]     -1.7942      0.510     -3.515      0.000      -2.795      -0.794
C(hoepa_status)[T.3]     -5.3277      0.510    -10.438      0.000      -6.328      -4.327
year                      0.0981      0.002     39.820      0.000       0.093       0.103
acs_median_income      1.479e-10   2.07e-10      0.715      0.475   -2.58e-10    5.53e-10
acs_poverty_rate          2.4597      0.058     42.386      0.000       2.346       2.573
acs_unemployment_rate    -0.4965      0.132     -3.747      0.000      -0.756      -0.237
acs_share_black          -0.2296      0.025     -9.230      0.000      -0.278      -0.181
acs_share_hispanic       -0.2548      0.029     -8.929      0.000      -0.311      -0.199
=========================================================================================


# 6.3. Comparaison des coefficients (HMDA vs HMDA+ACS)
coef_compare = pd.DataFrame({
    "HMDA_only": logit_hmda.params,
    "HMDA_ACS": logit_acs.params
})

display(coef_compare)

	HMDA_only	HMDA_ACS
C(hoepa_status)[T.2]	NaN	-1.794235e+00
C(hoepa_status)[T.3]	-3.513191	-5.327742e+00
C(loan_purpose)[T.2]	0.314561	3.258883e-01
C(loan_purpose)[T.31]	0.366948	4.185082e-01
C(loan_purpose)[T.32]	0.348670	3.871549e-01
C(loan_purpose)[T.4]	0.349081	3.617361e-01
C(loan_purpose)[T.5]	-4.874698	-4.831505e+00
C(loan_type)[T.2]	-0.745284	-7.643433e-01
C(loan_type)[T.3]	-0.464881	-4.580584e-01
C(loan_type)[T.4]	NaN	-4.399052e-01
Intercept	-208.534808	-1.949197e+02
acs_median_income	NaN	1.478916e-10
acs_poverty_rate	NaN	2.459651e+00
acs_share_black	NaN	-2.295779e-01
acs_share_hispanic	NaN	-2.547970e-01
acs_unemployment_rate	NaN	-4.964534e-01
year	0.103982	9.805716e-02
Table 5.1 ‚Äì Mod√®les logit IA (2018‚Äì2023) : HMDA-only vs HMDA+ACS
Variable	HMDA-only (coef)	HMDA+ACS (coef)	Variation (ACS ‚Äì HMDA)	Interpr√©tation principale
Intercept	-208.535	-194.920	+13.615	Niveau de base un peu moins s√©v√®re une fois le contexte ACS int√©gr√©.
C(loan_purpose)[T.2]	0.3146	0.3259	+0.0113	Cat√©gorie toujours favoris√©e, effet l√©g√®rement renforc√©.
C(loan_purpose)[T.4]	0.3491	0.3617	+0.0126	Effet positif tr√®s stable.
C(loan_purpose)[T.5]	-4.8747	-4.8315	+0.0432	Cat√©gorie quasi syst√©matiquement rejet√©e, l√©g√®re att√©nuation.
C(loan_purpose)[T.31]	0.3669	0.4185	+0.0516	Cat√©gorie encore plus favoris√©e avec ACS.
C(loan_purpose)[T.32]	0.3487	0.3872	+0.0385	Effet accentu√©.
C(loan_type)[T.2]	-0.7453	-0.7643	-0.0190	P√©nalit√© l√©g√®rement renforc√©e.
C(loan_type)[T.3]	-0.4649	-0.4581	+0.0068	Effet pratiquement inchang√©.
C(loan_type)[T.4]	NA	-0.4399	NA	Nouveau type captur√© en mod√®le enrichi, p√©nalis√©.
C(hoepa_status)[T.2]	NA	-1.7942	NA	P√©nalit√© d√©tect√©e seulement apr√®s ajout ACS.
C(hoepa_status)[T.3]	-3.5132	-5.3277	-1.8145	P√©nalit√© des produits HOEPA fortement amplifi√©e.
year	0.1040	0.0981	-0.0059	Effet temporel positif l√©g√®rement r√©duit apr√®s ACS.
acs_median_income	NA	1.48e-10	NA	Effet non significatif (quasi nul).
acs_poverty_rate	NA	2.4597	NA	Effet tr√®s positif et significatif.
acs_unemployment_rate	NA	-0.4965	NA	Effet n√©gatif significatif.
acs_share_black	NA	-0.2296	NA	Effet n√©gatif significatif.
acs_share_hispanic	NA	-0.2548	NA	Effet n√©gatif significatif.
Pseudo R¬≤	0.3809	0.3779	-0.0030	Pouvoir explicatif global quasi inchang√©.
Nombre d‚Äôobservations	565 880	520 457	-45 423	Perte due aux valeurs manquantes ACS.

'''
L‚Äôajout des variables ACS ne modifie que marginalement la qualit√© globale d‚Äôajustement (pseudo R¬≤ ‚âà 0,38 dans les deux cas) 
et laisse globalement inchang√© le r√¥le structurel des variables HMDA. Les cat√©gories de finalit√© et de type de pr√™t ainsi 
que le statut HOEPA restent les d√©terminants majeurs des d√©cisions d‚Äôoctroi, tandis que les variables ACS ajoutent une 
dimension contextuelle sans renverser l‚Äôarchitecture du mod√®le.
'''
Table 5.2 ‚Äì Effets des variables ACS dans le mod√®le IA HMDA+ACS
Variable ACS	Coefficient (logit)	Odds ratio approx.	Significatif ?	Interpr√©tation conditionnelle
acs_median_income	1.48e-10	‚âà 1.00	Non	Aucun effet d√©tectable : le revenu m√©dian local n‚Äôinfluence pas significativement l‚Äôapprobation, une fois les autres variables contr√¥l√©es.
acs_poverty_rate	2.4597	‚âà 11.7	Oui (p<0.001)	Les zones √† forte pauvret√© sont associ√©es √† une probabilit√© d‚Äôapprobation beaucoup plus √©lev√©e, ce qui sugg√®re une offre de cr√©dit cibl√©e sur des march√©s plus risqu√©s ou plus subventionn√©s.
acs_unemployment_rate	-0.4965	‚âà 0.61	Oui (p<0.001)	Le ch√¥mage local √©lev√© r√©duit nettement les chances d‚Äôapprobation, m√™me √† caract√©ristiques de pr√™t identiques.
acs_share_black	-0.2296	‚âà 0.80	Oui (p<0.001)	Une plus forte proportion de r√©sidents noirs dans le tract est associ√©e √† une baisse des chances d‚Äôapprobation ‚Üí possible canal de discrimination indirecte territoriale.
acs_share_hispanic	-0.2548	‚âà 0.78	Oui (p<0.001)	M√™me logique : les zones √† forte pr√©sence hispanique sont p√©nalis√©es, m√™me apr√®s contr√¥le des caract√©ristiques du pr√™t.

Table 5.3 ‚Äì Synth√®se des mod√®les logit (pr√©-IA vs IA)
Caract√©ristique	Pr√©-IA (2007‚Äì2017, HMDA-only)	IA (2018‚Äì2023, HMDA-only)	IA (2018‚Äì2023, HMDA+ACS)	Interpr√©tation
Base de donn√©es	pre_ai	ai_hmda	ai_acs	Pr√©-IA = HMDA Tri-State non enrichi ; IA = HMDA puis HMDA+ACS.
Nombre d‚Äôobservations	13 511 720	565 880	520 457	R√©duction d‚Äô√©chantillon en IA et encore plus avec ACS (valeurs manquantes).
Pseudo R¬≤	‚âà 0.029	‚âà 0.381	‚âà 0.378	Le passage √† l‚ÄôIA multiplie par ~13 le pouvoir explicatif ; l‚Äôajout ACS n‚Äôapporte qu‚Äôun gain marginal.
Variables explicatives	loan_purpose, loan_type, hoepa_status, year	M√™me set HMDA	HMDA + ACS (revenu, pauvret√©, ch√¥mage, composition raciale)	Continuum entre mod√®le simple, mod√®le algorithmique structur√© et mod√®le contextuel.
Effet loan_purpose	Pr√©sent mais plus diffus	Fortement structurant	L√©g√®rement renforc√©	Avec l‚ÄôIA, la finalit√© du pr√™t devient un filtre tr√®s tranch√©.
Effet loan_type	P√©nalisation des types 2‚Äì3	P√©nalisation forte	P√©nalisation maintenue	Continuit√© du traitement diff√©renci√© selon le type de produit.
Effet HOEPA	Moins marqu√©	Tr√®s p√©nalisant (T.3)	Encore plus p√©nalisant	Les produits risqu√©s sont quasiment exclus en IA, surtout apr√®s contr√¥le ACS.
Effet du temps (year)	+1,1 % d‚Äôodds/an	+11 % d‚Äôodds/an	~+10 % d‚Äôodds/an	Assouplissement progressif dans les deux r√©gimes, beaucoup plus rapide en IA.
Variables ACS	‚Äî	‚Äî	Significatives pour pauvret√©, ch√¥mage, composition raciale	Les conditions locales modulent la probabilit√© d‚Äôoctroi en IA.
Dimension fairness raciale	Non observable (pas de race)	Race observable, mod√®les avec race s√©par√©s	Contexte racial local via acs_share_black/hispanic	In√©galit√©s raciales reconfigur√©es via des dimensions contextuelles.

'''
    # Conclusion partielle :
    La comparaison des trois sp√©cifications met en √©vidence une transition nette entre 
    un r√©gime pr√©-IA faiblement explicable par les seules variables HMDA (pseudo R¬≤ ‚âà 0,03) 
    et un r√©gime IA o√π les d√©cisions d‚Äôoctroi deviennent fortement structur√©es (pseudo R¬≤ ‚âà 0,38). 
    L‚Äôintroduction de donn√©es ACS n‚Äôam√©liore que marginalement le pouvoir pr√©dictif global, 
    mais elle r√©v√®le un r√¥le important des conditions socio-√©conomiques et raciales locales 
    dans la formation des d√©cisions. En d‚Äôautres termes, les in√©galit√©s ne disparaissent pas 
    avec l‚ÄôIA : elles se d√©placent et se recomposent, passant de m√©canismes possiblement plus 
    discrets et non observ√©s √† des crit√®res plus syst√©matiques, parfois corr√©l√©s √† la g√©ographie 
    et √† la composition raciale des territoires.
'''

## 7. Mod√®les IA (ML) et premi√®res m√©triques de fairness
#
# üîó R√©f√©rence chapitre :
# - Section 6 : "Mod√®les IA : performance, √©quit√© et dilemmes"
# - Figures 6.1‚Äì6.3, Tableaux 6.1‚Äì6.2
#
# Ici, on :
# - construit un mod√®le de classification (Logit sklearn, RandomForest, XGBoost),
# - calcule AUC, F1, accuracy,
# - et quelques m√©triques de fairness simples (TPR/FNR par groupe).



# ============================================================
# 7. Mod√®les IA (ML) et premi√®res m√©triques de fairness
# ============================================================
# Ce bloc est autonome et peut √™tre ex√©cut√© d'un seul coup.
# Il suppose que les objets suivants existent d√©j√† :
#   - BASE_DIR : chemin de base du projet
#   - ai_acs   : DataFrame cohorte IA+ACS (2018‚Äì2023) avec la colonne "approved"
# ============================================================

import os
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    roc_auc_score,
    f1_score,
    accuracy_score,
    confusion_matrix
)

# XGBoost optionnel
try:
    from xgboost import XGBClassifier
    HAS_XGBOOST = True
except ImportError:
    HAS_XGBOOST = False

# -------------------------------------------------------------------
# 7.1. Pr√©paration des features et de la cible pour la cohorte IA+ACS
# -------------------------------------------------------------------

target = "approved"

# S√©curisation de la variable cible (0/1)
ai_acs = ai_acs.copy()
ai_acs[target] = ai_acs[target].astype(int)

# 7.1.1. Variables continues de base (log-transformations si disponibles)
base_features = []

if "loan_amount" in ai_acs.columns:
    ai_acs["log_loan_amount"] = np.log1p(ai_acs["loan_amount"])
    base_features.append("log_loan_amount")

# 'applicant_income' n'existe pas dans cette base, mais on laisse le code robuste
if "applicant_income" in ai_acs.columns:
    ai_acs["log_income"] = np.log1p(ai_acs["applicant_income"])
    base_features.append("log_income")

print("Variables continues utilis√©es :", base_features)

# 7.1.2. Variables ACS utilis√©es
acs_used_all = [
    "acs_median_income",
    "acs_poverty_rate",
    "acs_unemployment_rate",
    "acs_share_black",
    "acs_share_hispanic",
]

# On ne garde que celles r√©ellement pr√©sentes dans ai_acs
acs_used = [c for c in acs_used_all if c in ai_acs.columns]
print("Variables ACS utilis√©es :", acs_used)

# Conversion en num√©rique des ACS (par s√©curit√©)
for col in acs_used:
    ai_acs[col] = pd.to_numeric(ai_acs[col], errors="coerce")

# 7.1.3. Variables cat√©gorielles HMDA
cat_vars = []
if "loan_purpose" in ai_acs.columns:
    cat_vars.append("loan_purpose")
if "loan_type" in ai_acs.columns:
    cat_vars.append("loan_type")

print("Variables cat√©gorielles utilis√©es :", cat_vars)

# 7.1.4. Construction de la matrice de features X et de la cible y
features = base_features + cat_vars + acs_used
# On enl√®ve les doublons √©ventuels
features = list(dict.fromkeys(features))

X_all = ai_acs[features].copy()
y_all = ai_acs[target].copy()

# Encodage one-hot des variables cat√©gorielles
X_encoded = pd.get_dummies(X_all, drop_first=True)

# Suppression des lignes avec NaN dans les features
mask = X_encoded.notna().all(axis=1)
X_encoded = X_encoded.loc[mask]
y_all = y_all.loc[mask]

# Split train / test
X_train, X_test, y_train, y_test = train_test_split(
    X_encoded,
    y_all,
    test_size=0.3,
    random_state=42,
    stratify=y_all
)

print("Train shape:", X_train.shape, "Test shape:", X_test.shape)

# -------------------------------------------------------------------
# 7.2. Mod√®le baseline : r√©gression logistique sklearn
# -------------------------------------------------------------------

log_clf = LogisticRegression(max_iter=1000, n_jobs=-1)
log_clf.fit(X_train, y_train)

y_pred_proba_log = log_clf.predict_proba(X_test)[:, 1]
y_pred_log = (y_pred_proba_log >= 0.5).astype(int)

auc_log = roc_auc_score(y_test, y_pred_proba_log)
f1_log = f1_score(y_test, y_pred_log)
acc_log = accuracy_score(y_test, y_pred_log)

print("\nLogit (sklearn)")
print("  AUC      :", round(auc_log, 3))
print("  F1       :", round(f1_log, 3))
print("  Accuracy :", round(acc_log, 3))

# -------------------------------------------------------------------
# 7.3. Mod√®le Random Forest
# -------------------------------------------------------------------

rf_clf = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)
rf_clf.fit(X_train, y_train)

y_pred_proba_rf = rf_clf.predict_proba(X_test)[:, 1]
y_pred_rf = (y_pred_proba_rf >= 0.5).astype(int)

auc_rf = roc_auc_score(y_test, y_pred_proba_rf)
f1_rf = f1_score(y_test, y_pred_rf)
acc_rf = accuracy_score(y_test, y_pred_rf)

print("\nRandomForest")
print("  AUC      :", round(auc_rf, 3))
print("  F1       :", round(f1_rf, 3))
print("  Accuracy :", round(acc_rf, 3))

# -------------------------------------------------------------------
# 7.4. Mod√®le XGBoost (optionnel si disponible)
# -------------------------------------------------------------------

if HAS_XGBOOST:
    xgb_clf = XGBClassifier(
        n_estimators=300,
        max_depth=5,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        objective="binary:logistic",
        eval_metric="logloss",
        n_jobs=-1,
        random_state=42,
    )
    xgb_clf.fit(X_train, y_train)

    y_pred_proba_xgb = xgb_clf.predict_proba(X_test)[:, 1]
    y_pred_xgb = (y_pred_proba_xgb >= 0.5).astype(int)

    auc_xgb = roc_auc_score(y_test, y_pred_proba_xgb)
    f1_xgb = f1_score(y_test, y_pred_xgb)
    acc_xgb = accuracy_score(y_test, y_pred_xgb)

    print("\nXGBoost")
    print("  AUC      :", round(auc_xgb, 3))
    print("  F1       :", round(f1_xgb, 3))
    print("  Accuracy :", round(acc_xgb, 3))
else:
    print("\nXGBoost non disponible (package xgboost non install√©).")

# -------------------------------------------------------------------
# 7.5. Tableau comparatif des performances (Tableau 6.1)
# -------------------------------------------------------------------

rows = [
    ("Logit", auc_log, f1_log, acc_log),
    ("RandomForest", auc_rf, f1_rf, acc_rf),
]

if HAS_XGBOOST:
    rows.append(("XGBoost", auc_xgb, f1_xgb, acc_xgb))

perf_df = pd.DataFrame(rows, columns=["Model", "AUC", "F1", "Accuracy"])
print("\n=== Tableau 6.1 ‚Äì Performance des mod√®les ===")
display(perf_df)

# Dossier de sortie des tables
out_dir = os.path.join(BASE_DIR, "tables")
os.makedirs(out_dir, exist_ok=True)

perf_path = os.path.join(out_dir, "table_6_1_model_performance.csv")
perf_df.to_csv(perf_path, index=False)
print("Tableau 6.1 sauvegard√© dans :", perf_path)

# -------------------------------------------------------------------
# 7.6. Premi√®res m√©triques de fairness (TPR/FPR par groupe racial)
# -------------------------------------------------------------------
# On utilise ici les pr√©dictions du RandomForest comme mod√®le IA principal.

if "derived_race" in ai_acs.columns:
    # On r√©cup√®re la race pour les individus pr√©sents dans y_test
    race_test = ai_acs.loc[y_test.index, "derived_race"]

    def safe_group_metrics(y_true, y_pred, mask):
        """Calcule TPR et FPR pour un groupe, en √©vitant les crashs."""
        n = mask.sum()
        if n < 50:  # seuil minimal d'observations par groupe
            return np.nan, np.nan

        cm = confusion_matrix(y_true[mask], y_pred[mask])
        if cm.shape != (2, 2):
            return np.nan, np.nan

        tn, fp, fn, tp = cm.ravel()
        tpr = tp / (tp + fn) if (tp + fn) > 0 else np.nan  # True Positive Rate
        fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan  # False Positive Rate
        return tpr, fpr

    metrics_rows = []
    for grp in race_test.dropna().unique():
        mask = (race_test == grp)
        tpr, fpr = safe_group_metrics(y_test, y_pred_rf, mask)
        metrics_rows.append((grp, tpr, fpr))

    fairness_df = pd.DataFrame(metrics_rows, columns=["Race", "TPR_RF", "FPR_RF"])
    print("\n=== Tableau 6.2 ‚Äì Fairness RF par race (TPR/FPR) ===")
    display(fairness_df)

    fairness_path = os.path.join(out_dir, "table_6_2_fairness_rf_by_race.csv")
    fairness_df.to_csv(fairness_path, index=False)
    print("Tableau 6.2 sauvegard√© dans :", fairness_path)
else:
    fairness_df = None
    print("\nColonne 'derived_race' introuvable ‚Äì impossible de calculer les m√©triques de fairness par race.")

# ============================================================
# 8. Export, tra√ßabilit√© et liens avec la r√©daction
# ============================================================

produced = {
    "tables": [
        "table_2_1_approval_by_state.csv",
        "table_3_logit_pre_vs_ia.csv",
        "table_4_race_logit_pre_vs_ia.csv",
        "table_5_race_hmda_vs_hmda_acs.csv",
        "table_6_1_model_performance.csv",
        "table_6_2_fairness_rf_by_race.csv",
    ],
    "figures": [
        "Figure 2.1 ‚Äì Taux d'approbation 2007‚Äì2023 (g√©n√©r√©e √† partir de 'approval_year').",
        "Figure 2.2 ‚Äì Distribution des revenus par cohorte.",
        "Figure 3.X ‚Äì Effets marginaux logit pr√©-IA vs IA.",
        "Figure 6.X ‚Äì ROC Curves logit / RF / XGBoost.",
    ],
}

print("\n\n=== R√âCAPITULATIF DES FICHIERS PRODUITS ===")
for k, v in produced.items():
    print(f"\n--- {k.upper()} ---")
    for item in v:
        print("-", item)


Variables continues utilis√©es : ['log_loan_amount']
Variables ACS utilis√©es : ['acs_median_income', 'acs_poverty_rate', 'acs_unemployment_rate', 'acs_share_black', 'acs_share_hispanic']
Variables cat√©gorielles utilis√©es : ['loan_purpose', 'loan_type']
Train shape: (364320, 8) Test shape: (156138, 8)

Logit (sklearn)
  AUC      : 0.566
  F1       : 0.674
  Accuracy : 0.558

RandomForest
  AUC      : 0.593
  F1       : 0.611
  Accuracy : 0.57

XGBoost non disponible (package xgboost non install√©).

=== Tableau 6.1 ‚Äì Performance des mod√®les ===
Model	AUC	F1	Accuracy
0	Logit	0.566396	0.674147	0.557878
1	RandomForest	0.592607	0.610788	0.570406
Tableau 6.1 sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_6_1_model_performance.csv

=== Tableau 6.2 ‚Äì Fairness RF par race (TPR/FPR) ===
Race	TPR_RF	FPR_RF
0	Race Not Available	0.626703	0.477427
1	White	0.629820	0.511367
2	Asian	0.652478	0.524571
3	Black or African American	0.517882	0.384511
4	Native Hawaiian or Other Pacific Islander	0.521008	0.453333
5	Free Form Text Only	0.200000	0.250000
6	Joint	0.633059	0.542857
7	American Indian or Alaska Native	0.636364	0.403670
8	2 or more minority races	0.604938	0.370968
Tableau 6.2 sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_6_2_fairness_rf_by_race.csv


=== R√âCAPITULATIF DES FICHIERS PRODUITS ===

--- TABLES ---
- table_2_1_approval_by_state.csv
- table_3_logit_pre_vs_ia.csv
- table_4_race_logit_pre_vs_ia.csv
- table_5_race_hmda_vs_hmda_acs.csv
- table_6_1_model_performance.csv
- table_6_2_fairness_rf_by_race.csv

--- FIGURES ---
- Figure 2.1 ‚Äì Taux d'approbation 2007‚Äì2023 (g√©n√©r√©e √† partir de 'approval_year').
- Figure 2.2 ‚Äì Distribution des revenus par cohorte.
- Figure 3.X ‚Äì Effets marginaux logit pr√©-IA vs IA.
- Figure 6.X ‚Äì ROC Curves logit / RF / XGBoost.
Groupe racial	Acc√®s √† l‚Äôapprobation (TPR)	Risque de faux positifs (FPR)	Lecture fairness globale
White	√âlev√© ‚úÖ	√âlev√© ‚ö†Ô∏è	Privil√©gi√© / favoris√©
Asian	Tr√®s √©lev√© ‚úÖ	√âlev√© ‚ö†Ô∏è	Tr√®s favoris√©
Black	Faible ‚ùå	Faible ‚úÖ	D√©savantag√© / plus conservateur
Hispanic*	(non mesur√© ici)	‚Äî	‚Äî
Race Not Available	Moyen	√âlev√© ‚ùå	P√©nalis√© structurellement


'''
Les r√©sultats empiriques montrent une asym√©trie marqu√©e dans le comportement des mod√®les pr√©dictifs. 
Les demandeurs blancs et asiatiques b√©n√©ficient de taux d‚Äôapprobation corrects significativement plus √©lev√©s, 
tandis que les demandeurs noirs pr√©sentent un taux de reconnaissance positive inf√©rieur. 
Cette divergence persiste m√™me apr√®s enrichissement par les donn√©es socio-√©conomiques ACS, sugg√©rant 
que les syst√®mes de d√©cision automatis√©e reproduisent ‚Äî voire amplifient ‚Äî des biais structurels h√©rit√©s 
des donn√©es historiques.
'''

# ============================================================
# G√©n√©ration centralis√©e des TABLES + FIGURES pr√™tes pour Overleaf
# + affichage dans le notebook
# ============================================================
# Hypoth√®ses :
# - BASE_DIR est d√©j√† d√©fini (sinon, d√©finir manuellement ci-dessous)
# - Les objets suivants existent d√©j√† dans le notebook :
#   core, pre_ai, ai_hmda, ai_acs
#   logit_pre, logit_ai, logit_hmda, logit_acs
#   perf_df, fairness_df, log_clf, rf_clf, X_train, X_test, y_train, y_test
# ============================================================

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score
from IPython.display import display
from pandas.api.types import is_numeric_dtype

# -------------------------------------------------------------------
# 0. Chemins de base
# -------------------------------------------------------------------
try:
    BASE_DIR
except NameError:
    # üîß √† adapter si besoin :
    BASE_DIR = r"C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai"

DATA_WORK_DIR = os.path.join(BASE_DIR, "data_work")
TABLE_DIR = os.path.join(DATA_WORK_DIR, "tables")
FIG_DIR = os.path.join(DATA_WORK_DIR, "figures")

os.makedirs(TABLE_DIR, exist_ok=True)
os.makedirs(FIG_DIR, exist_ok=True)

print("TABLE_DIR :", TABLE_DIR)
print("FIG_DIR   :", FIG_DIR)

# ============================================================
# 1. TABLES
# ============================================================

# -------------------------------------------------------------------
# 1.1 Table 2.1 ‚Äì Taux d'approbation par cohorte et par √âtat (Tri-State)
# -------------------------------------------------------------------
core = core.copy()
core["approved"] = core["approved"].astype(int)
core["year"] = core["year"].astype(int)
core["cohort"] = np.where(core["year"] <= 2017, "pre_IA", "IA")

state_col = None
for c in ["state", "state_code", "state_abbr", "property_state", "property_state_name"]:
    if c in core.columns:
        state_col = c
        break

if state_col is None:
    raise ValueError("Impossible de trouver une colonne d'√âtat dans core.")

approval_by_state = (
    core.groupby([state_col, "cohort"])["approved"]
        .mean()
        .unstack()
)

state_fips_to_name = {
    9: "Connecticut",
    34: "New Jersey",
    36: "New York",
}

idx_int = approval_by_state.index
if is_numeric_dtype(idx_int):
    idx_int = approval_by_state.index.astype(int)

approval_by_state_named = approval_by_state.copy()
approval_by_state_named = approval_by_state_named.reset_index()
approval_by_state_named.rename(columns={state_col: "state_code"}, inplace=True)

if "state_code" in approval_by_state_named.columns:
    approval_by_state_named["state"] = (
        approval_by_state_named["state_code"]
        .astype(int)
        .map(state_fips_to_name)
    )

print("\n=== Table 2.1 ‚Äì Taux d'approbation par √âtat et cohorte ===")
display(approval_by_state_named)

table_2_1_path = os.path.join(TABLE_DIR, "table_2_1_approval_by_state.csv")
approval_by_state_named.to_csv(table_2_1_path, index=False)

table_2_1_tex_path = os.path.join(TABLE_DIR, "table_2_1_approval_by_state.tex")
with open(table_2_1_tex_path, "w", encoding="utf-8") as f:
    f.write(approval_by_state_named.to_latex(index=False))

print("[OK] Table 2.1 CSV  :", table_2_1_path)
print("[OK] Table 2.1 TeX  :", table_2_1_tex_path)


# -------------------------------------------------------------------
# 1.2 Table 3 ‚Äì Coefficients logit pr√©-IA vs IA (HMDA-only)
# -------------------------------------------------------------------
table_3 = pd.DataFrame({
    "coef_pre_IA": getattr(logit_pre, "params", pd.Series(dtype=float)),
    "coef_IA": getattr(logit_ai, "params", pd.Series(dtype=float)),
})

print("\n=== Table 3 ‚Äì Logit pr√©-IA vs IA (HMDA-only) ===")
display(table_3)

table_3_path = os.path.join(TABLE_DIR, "table_3_logit_pre_vs_ia.csv")
table_3.to_csv(table_3_path, index=True)

table_3_tex_path = os.path.join(TABLE_DIR, "table_3_logit_pre_vs_ia.tex")
with open(table_3_tex_path, "w", encoding="utf-8") as f:
    f.write(table_3.to_latex(index=True))

print("[OK] Table 3 CSV   :", table_3_path)
print("[OK] Table 3 TeX   :", table_3_tex_path)


# -------------------------------------------------------------------
# 1.3 Table 4 ‚Äì Mod√®le logit IA avec race (derived_race), si dispo
# -------------------------------------------------------------------
try:
    logit_ai_race
    table_4 = pd.DataFrame({
        "coef_IA_race": logit_ai_race.params
    })

    print("\n=== Table 4 ‚Äì Logit IA avec derived_race ===")
    display(table_4)

    table_4_path = os.path.join(TABLE_DIR, "table_4_race_logit_ia_only.csv")
    table_4.to_csv(table_4_path, index=True)

    table_4_tex_path = os.path.join(TABLE_DIR, "table_4_race_logit_ia_only.tex")
    with open(table_4_tex_path, "w", encoding="utf-8") as f:
        f.write(table_4.to_latex(index=True))

    print("[OK] Table 4 CSV   :", table_4_path)
    print("[OK] Table 4 TeX   :", table_4_tex_path)
except NameError:
    print("\n[SKIP] logit_ai_race non trouv√© ‚Üí Table 4 non r√©g√©n√©r√©e.")


# -------------------------------------------------------------------
# 1.4 Table 5 ‚Äì Comparaison HMDA-only vs HMDA+ACS (IA)
# -------------------------------------------------------------------
coef_compare = pd.DataFrame({
    "HMDA_only": logit_hmda.params,
    "HMDA_ACS": logit_acs.params
})

print("\n=== Table 5 ‚Äì HMDA-only vs HMDA+ACS (IA) ===")
display(coef_compare)

table_5_path = os.path.join(TABLE_DIR, "table_5_hmda_vs_hmda_acs.csv")
coef_compare.to_csv(table_5_path, index=True)

table_5_tex_path = os.path.join(TABLE_DIR, "table_5_hmda_vs_hmda_acs.tex")
with open(table_5_tex_path, "w", encoding="utf-8") as f:
    f.write(coef_compare.to_latex(index=True))

print("[OK] Table 5 CSV   :", table_5_path)
print("[OK] Table 5 TeX   :", table_5_tex_path)


# -------------------------------------------------------------------
# 1.5 Table 6.1 ‚Äì Performance des mod√®les IA (perf_df)
# -------------------------------------------------------------------
print("\n=== Table 6.1 ‚Äì Performance des mod√®les IA (Logit / RF / XGBoost) ===")
display(perf_df)

table_6_1_path = os.path.join(TABLE_DIR, "table_6_1_model_performance.csv")
perf_df.to_csv(table_6_1_path, index=False)

table_6_1_tex_path = os.path.join(TABLE_DIR, "table_6_1_model_performance.tex")
with open(table_6_1_tex_path, "w", encoding="utf-8") as f:
    f.write(perf_df.to_latex(index=False))

print("[OK] Table 6.1 CSV :", table_6_1_path)
print("[OK] Table 6.1 TeX :", table_6_1_tex_path)


# -------------------------------------------------------------------
# 1.6 Table 6.2 ‚Äì Fairness RF par race (TPR/FPR)
# -------------------------------------------------------------------
if 'fairness_df' in globals() and fairness_df is not None:
    print("\n=== Table 6.2 ‚Äì Fairness RF par race (TPR/FPR) ===")
    display(fairness_df)

    table_6_2_path = os.path.join(TABLE_DIR, "table_6_2_fairness_rf_by_race.csv")
    fairness_df.to_csv(table_6_2_path, index=False)

    table_6_2_tex_path = os.path.join(TABLE_DIR, "table_6_2_fairness_rf_by_race.tex")
    with open(table_6_2_tex_path, "w", encoding="utf-8") as f:
        f.write(fairness_df.to_latex(index=False))

    print("[OK] Table 6.2 CSV :", table_6_2_path)
    print("[OK] Table 6.2 TeX :", table_6_2_tex_path)
else:
    print("\n[SKIP] fairness_df non disponible ‚Üí Table 6.2 non r√©g√©n√©r√©e.")


# ============================================================
# 2. FIGURES
# ============================================================

# -------------------------------------------------------------------
# 2.1 Figure 2.1 ‚Äì Taux d'approbation 2007‚Äì2023
# -------------------------------------------------------------------
approval_year = (
    core.groupby("year")["approved"]
        .mean()
        .reset_index()
        .rename(columns={"approved": "approval_rate"})
)

fig, ax = plt.subplots(figsize=(7, 4))
ax.plot(approval_year["year"], approval_year["approval_rate"], marker="o")
ax.axvline(2017.5, color="red", linestyle="--", label="Rupture 2017/2018 (IA)")
ax.set_title("Figure 2.1 ‚Äì Taux d'approbation moyen (Tri-State, 2007‚Äì2023)")
ax.set_xlabel("Ann√©e")
ax.set_ylabel("Taux d'approbation")
ax.legend()
plt.tight_layout()

fig_2_1_path = os.path.join(FIG_DIR, "figure_2_1_approval_rate_2007_2023.png")
plt.savefig(fig_2_1_path, dpi=300)
plt.show()
plt.close(fig)
print("\n[OK] Figure 2.1 enregistr√©e :", fig_2_1_path)


# -------------------------------------------------------------------
# 2.2 Figure 2.2 ‚Äì Distribution des montants de pr√™t par cohorte
# -------------------------------------------------------------------
fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)

for ax, df, title in zip(
    axes,
    [pre_ai, ai_hmda],
    ["Pr√©-IA (2007‚Äì2017)", "IA (2018‚Äì2023)"]
):
    if "loan_amount" in df.columns:
        s = pd.to_numeric(df["loan_amount"], errors="coerce").dropna()
        s = s.clip(upper=s.quantile(0.99))
        ax.hist(s, bins=50)
        ax.set_title(title)
        ax.set_xlabel("Montant du pr√™t (troncation 99e percentile)")
        ax.set_ylabel("Nombre d'observations")
    else:
        ax.set_title(title + " ‚Äì loan_amount manquant")

plt.tight_layout()
fig_2_2_path = os.path.join(FIG_DIR, "figure_2_2_loan_amount_pre_vs_ia.png")
plt.savefig(fig_2_2_path, dpi=300)
plt.show()
plt.close(fig)
print("[OK] Figure 2.2 enregistr√©e :", fig_2_2_path)


# -------------------------------------------------------------------
# 2.3 Figures 5.1 & 5.2 ‚Äì Revenu ACS m√©dian (lin / log)
# -------------------------------------------------------------------
if "acs_median_income" in ai_acs.columns:
    s = pd.to_numeric(ai_acs["acs_median_income"], errors="coerce")
    s = s[(s > 0) & (s < 2_000_000)].dropna()

    # lin√©aire
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.hist(s, bins=50)
    ax.set_title("Figure 5.1 ‚Äì Revenu m√©dian de la zone (ACS, lin√©aire)")
    ax.set_xlabel("Revenu ACS")
    ax.set_ylabel("Fr√©quence")
    plt.tight_layout()
    fig_5_1_path = os.path.join(FIG_DIR, "figure_5_1_acs_median_income_linear.png")
    plt.savefig(fig_5_1_path, dpi=300)
    plt.show()
    plt.close(fig)
    print("[OK] Figure 5.1 enregistr√©e :", fig_5_1_path)

    # log
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.hist(s, bins=50, log=True)
    ax.set_title("Figure 5.2 ‚Äì Revenu m√©dian de la zone (ACS, log)")
    ax.set_xlabel("Revenu ACS")
    ax.set_ylabel("Fr√©quence (log)")
    plt.tight_layout()
    fig_5_2_path = os.path.join(FIG_DIR, "figure_5_2_acs_median_income_log.png")
    plt.savefig(fig_5_2_path, dpi=300)
    plt.show()
    plt.close(fig)
    print("[OK] Figure 5.2 enregistr√©e :", fig_5_2_path)
else:
    print("\n[SKIP] acs_median_income absent ‚Üí Figures 5.1‚Äì5.2 non g√©n√©r√©es.")


# -------------------------------------------------------------------
# 2.4 Figure 6.1 ‚Äì Courbes ROC (Logit vs Random Forest)
# -------------------------------------------------------------------
# On suppose y_pred_proba_log / y_pred_proba_rf encore dispo. Sinon, on recalcule.
try:
    y_pred_proba_log
    y_pred_proba_rf
except NameError:
    y_pred_proba_log = log_clf.predict_proba(X_test)[:, 1]
    y_pred_proba_rf = rf_clf.predict_proba(X_test)[:, 1]

fpr_log, tpr_log, _ = roc_curve(y_test, y_pred_proba_log)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)

auc_log = roc_auc_score(y_test, y_pred_proba_log)
auc_rf = roc_auc_score(y_test, y_pred_proba_rf)

fig, ax = plt.subplots(figsize=(6, 5))
ax.plot(fpr_log, tpr_log, label=f"Logit (AUC = {auc_log:.3f})")
ax.plot(fpr_rf, tpr_rf, label=f"Random Forest (AUC = {auc_rf:.3f})")
ax.plot([0, 1], [0, 1], "k--", label="Hasard")
ax.set_title("Figure 6.1 ‚Äì Courbes ROC (IA, 2018‚Äì2023)")
ax.set_xlabel("False Positive Rate")
ax.set_ylabel("True Positive Rate")
ax.legend(loc="lower right")
plt.tight_layout()

fig_6_1_path = os.path.join(FIG_DIR, "figure_6_1_roc_logit_vs_rf.png")
plt.savefig(fig_6_1_path, dpi=300)
plt.show()
plt.close(fig)
print("[OK] Figure 6.1 enregistr√©e :", fig_6_1_path)


# -------------------------------------------------------------------
# 2.5 Figure 6.2 ‚Äì Fairness RF par race (barres TPR/FPR)
# -------------------------------------------------------------------
if 'fairness_df' in globals() and fairness_df is not None:
    fig, ax = plt.subplots(figsize=(8, 5))

    x = np.arange(len(fairness_df))
    width = 0.35

    ax.bar(x - width/2, fairness_df["TPR_RF"], width, label="TPR (sensibilit√©)")
    ax.bar(x + width/2, fairness_df["FPR_RF"], width, label="FPR (taux de faux positifs)")

    ax.set_xticks(x)
    ax.set_xticklabels(fairness_df["Race"], rotation=45, ha="right")
    ax.set_ylabel("Taux")
    ax.set_title("Figure 6.2 ‚Äì Fairness Random Forest par race (TPR/FPR)")
    ax.legend()
    plt.tight_layout()

    fig_6_2_path = os.path.join(FIG_DIR, "figure_6_2_fairness_rf_by_race.png")
    plt.savefig(fig_6_2_path, dpi=300)
    plt.show()
    plt.close(fig)
    print("[OK] Figure 6.2 enregistr√©e :", fig_6_2_path)
else:
    print("\n[SKIP] fairness_df non disponible ‚Üí Figure 6.2 non g√©n√©r√©e.")


# ============================================================
# R√©cap final
# ============================================================
print("\n\n=== R√âCAPITULATIF ===")
print("Tables g√©n√©r√©es dans :", TABLE_DIR)
print("Figures g√©n√©r√©es dans :", FIG_DIR)
print("‚Üí Tous les contenus sont visibles dans le notebook ET pr√™ts √† √™tre gliss√©s dans Overleaf.")

TABLE_DIR : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables
FIG_DIR   : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\figures

=== Table 2.1 ‚Äì Taux d'approbation par √âtat et cohorte ===
cohort	state_code	pre_IA	state
0	9.0	0.704873	Connecticut
1	34.0	0.681274	New Jersey
2	36.0	0.729269	New York
[OK] Table 2.1 CSV  : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_2_1_approval_by_state.csv
[OK] Table 2.1 TeX  : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_2_1_approval_by_state.tex

=== Table 3 ‚Äì Logit pr√©-IA vs IA (HMDA-only) ===
coef_pre_IA	coef_IA
C(hoepa_status)[T.3]	NaN	-3.512233
C(loan_purpose)[T.2.0]	1.086341	NaN
C(loan_purpose)[T.2]	NaN	0.318558
C(loan_purpose)[T.3.0]	-0.014767	NaN
C(loan_purpose)[T.31]	NaN	0.371640
C(loan_purpose)[T.32]	NaN	0.350479
C(loan_purpose)[T.4]	NaN	0.359366
C(loan_purpose)[T.5]	NaN	-4.619275
C(loan_type)[T.2.0]	-0.778573	NaN
C(loan_type)[T.2]	NaN	-0.747525
C(loan_type)[T.3.0]	-0.462877	NaN
C(loan_type)[T.3]	NaN	-0.465056
C(loan_type)[T.4.0]	-0.553407	NaN
Intercept	-20.044201	-213.361629
year	0.010456	0.106370
[OK] Table 3 CSV   : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_3_logit_pre_vs_ia.csv
[OK] Table 3 TeX   : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_3_logit_pre_vs_ia.tex

=== Table 4 ‚Äì Logit IA avec derived_race ===
coef_IA_race
Intercept	-268.766430
C(loan_purpose)[T.2]	0.301924
C(loan_purpose)[T.4]	0.342671
C(loan_purpose)[T.5]	-4.151461
C(loan_purpose)[T.31]	0.393240
C(loan_purpose)[T.32]	0.388027
C(loan_type)[T.2]	-0.638620
C(loan_type)[T.3]	-0.384981
C(hoepa_status)[T.3]	-3.623327
C(derived_race)[T.American Indian or Alaska Native]	-0.020336
C(derived_race)[T.Asian]	0.434135
C(derived_race)[T.Black or African American]	0.138897
C(derived_race)[T.Free Form Text Only]	-0.285825
C(derived_race)[T.Joint]	0.368677
C(derived_race)[T.Native Hawaiian or Other Pacific Islander]	-0.075819
C(derived_race)[T.Race Not Available]	-0.787279
C(derived_race)[T.White]	0.277572
year	0.133786
[OK] Table 4 CSV   : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_4_race_logit_ia_only.csv
[OK] Table 4 TeX   : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_4_race_logit_ia_only.tex

=== Table 5 ‚Äì HMDA-only vs HMDA+ACS (IA) ===
HMDA_only	HMDA_ACS
C(hoepa_status)[T.2]	NaN	-1.794235e+00
C(hoepa_status)[T.3]	-3.513191	-5.327742e+00
C(loan_purpose)[T.2]	0.314561	3.258883e-01
C(loan_purpose)[T.31]	0.366948	4.185082e-01
C(loan_purpose)[T.32]	0.348670	3.871549e-01
C(loan_purpose)[T.4]	0.349081	3.617361e-01
C(loan_purpose)[T.5]	-4.874698	-4.831505e+00
C(loan_type)[T.2]	-0.745284	-7.643433e-01
C(loan_type)[T.3]	-0.464881	-4.580584e-01
C(loan_type)[T.4]	NaN	-4.399052e-01
Intercept	-208.534808	-1.949197e+02
acs_median_income	NaN	1.478916e-10
acs_poverty_rate	NaN	2.459651e+00
acs_share_black	NaN	-2.295779e-01
acs_share_hispanic	NaN	-2.547970e-01
acs_unemployment_rate	NaN	-4.964534e-01
year	0.103982	9.805716e-02
[OK] Table 5 CSV   : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_5_hmda_vs_hmda_acs.csv
[OK] Table 5 TeX   : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_5_hmda_vs_hmda_acs.tex

=== Table 6.1 ‚Äì Performance des mod√®les IA (Logit / RF / XGBoost) ===
Model	AUC	F1	Accuracy
0	Logit	0.566396	0.674147	0.557878
1	RandomForest	0.592607	0.610788	0.570406
[OK] Table 6.1 CSV : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_6_1_model_performance.csv
[OK] Table 6.1 TeX : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_6_1_model_performance.tex

=== Table 6.2 ‚Äì Fairness RF par race (TPR/FPR) ===
Race	TPR_RF	FPR_RF
0	Race Not Available	0.626703	0.477427
1	White	0.629820	0.511367
2	Asian	0.652478	0.524571
3	Black or African American	0.517882	0.384511
4	Native Hawaiian or Other Pacific Islander	0.521008	0.453333
5	Free Form Text Only	0.200000	0.250000
6	Joint	0.633059	0.542857
7	American Indian or Alaska Native	0.636364	0.403670
8	2 or more minority races	0.604938	0.370968
[OK] Table 6.2 CSV : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_6_2_fairness_rf_by_race.csv
[OK] Table 6.2 TeX : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables\table_6_2_fairness_rf_by_race.tex


[OK] Figure 2.1 enregistr√©e : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\figures\figure_2_1_approval_rate_2007_2023.png

[OK] Figure 2.2 enregistr√©e : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\figures\figure_2_2_loan_amount_pre_vs_ia.png

[OK] Figure 5.1 enregistr√©e : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\figures\figure_5_1_acs_median_income_linear.png

[OK] Figure 5.2 enregistr√©e : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\figures\figure_5_2_acs_median_income_log.png

[OK] Figure 6.1 enregistr√©e : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\figures\figure_6_1_roc_logit_vs_rf.png

[OK] Figure 6.2 enregistr√©e : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\figures\figure_6_2_fairness_rf_by_race.png


=== R√âCAPITULATIF ===
Tables g√©n√©r√©es dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\tables
Figures g√©n√©r√©es dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\data_work\figures
‚Üí Tous les contenus sont visibles dans le notebook ET pr√™ts √† √™tre gliss√©s dans Overleaf.


'''
    # Interpr√©tation de la Figure 6.1 ‚Äì Courbes ROC des mod√®les de classification

    La Figure 6.1 compare la performance discriminante de deux algorithmes de classification ‚Äì une r√©gression 
logistique (Logit) et un mod√®le Random Forest ‚Äì appliqu√©s aux donn√©es de la p√©riode algorithmique (2018‚Äì2023). 
La diagonale en pointill√©s repr√©sente un classifieur al√©atoire (performance √©quivalente au hasard, AUC = 0,5).
    Les deux courbes se situent au-dessus de la ligne de hasard, ce qui indique que les mod√®les parviennent √† extraire
un signal informatif √† partir des variables disponibles. Toutefois, leurs performances restent mod√©r√©es, avec une 
AUC de 0,566 pour le mod√®le Logit et 0,593 pour le Random Forest, soit un avantage marginal mais syst√©matique en 
faveur du mod√®le non lin√©aire.
    La proximit√© des courbes avec la diagonale sugg√®re que le pouvoir pr√©dictif global demeure limit√© : les variables 
HMDA et ACS utilis√©es capturent une partie de l‚Äôinformation, mais ne permettent pas une s√©paration nette entre les 
demandes approuv√©es et refus√©es. Cette performance mod√©r√©e est coh√©rente avec la nature hautement r√©glement√©e et 
standardis√©e des d√©cisions de cr√©dit, dans lesquelles une grande part de la variance est d√©termin√©e par des r√®gles 
internes non observ√©es.
    En comparaison, le Random Forest pr√©sente une meilleure capacit√© √† capter des non-lin√©arit√©s et interactions implicites, 
ce qui explique sa l√©g√®re sup√©riorit√© par rapport √† la r√©gression logistique. N√©anmoins, l‚Äô√©cart restreint entre les deux 
mod√®les indique que les gains de complexit√© algorithmique sont limit√©s dans ce contexte empirique.
    Ces r√©sultats soulignent un point m√©thodologique central : l‚Äôaugmentation de la sophistication des mod√®les ne se traduit
pas n√©cessairement par une am√©lioration substantielle de la performance pr√©dictive, ce qui renforce l‚Äôint√©r√™t d‚Äôune 
√©valuation conjointe entre performance et √©quit√© algorithmique dans les syst√®mes de scoring de cr√©dit.


    # Interpr√©tation de la Figure 6.2 ‚Äì TPR/FPR par groupe racial (mod√®le Random Forest)

    La Figure 6.2 met en √©vidence des diff√©rences marqu√©es dans les performances du mod√®le de Random Forest 
selon les groupes raciaux, r√©v√©lant des asym√©tries substantielles en mati√®re d‚Äô√©quit√© algorithmique.
Le TPR (True Positive Rate), qui mesure la capacit√© du mod√®le √† approuver correctement les dossiers r√©ellement √©ligibles, 
est relativement √©lev√© pour les groupes White, Asian et Joint (‚âà 0,63 ‚Äì 0,65), ce qui signifie que ces groupes b√©n√©ficient 
d‚Äôune meilleure d√©tection des dossiers l√©gitimes. √Ä l‚Äôinverse, les groupes Black or African American et Native Hawaiian or 
Other Pacific Islander pr√©sentent des TPR plus faibles (‚âà 0,52), indiquant une probabilit√© plus √©lev√©e de faux rejets pour ces populations.
    Parall√®lement, le FPR (False Positive Rate), qui mesure la probabilit√© d‚Äôapprouver √† tort des dossiers non √©ligibles, est 
plus √©lev√© pour les groupes Asian, Joint et White (‚âà 0,50 ‚Äì 0,55), traduisant une plus grande tol√©rance du mod√®le √† l‚Äôerreur 
positive pour ces groupes. √Ä l‚Äôinverse, les groupes Black et 2 or more minority races pr√©sentent des FPR plus faibles, ce qui 
sugg√®re un seuil d√©cisionnel plus restrictif appliqu√© implicitement √† ces profils.
    Le groupe Free Form Text Only se distingue par des valeurs atypiques (TPR tr√®s faible ‚âà 0,20), refl√©tant probablement une 
instabilit√© statistique li√©e √† un faible effectif, plut√¥t qu‚Äôun effet structurel du mod√®le.
Dans l‚Äôensemble, ce graphique met en √©vidence un conflit structurel entre performance pr√©dictive et √©quit√© : certains groupes b√©n√©ficient 
simultan√©ment de taux d‚Äôapprobation et de tol√©rance √† l‚Äôerreur plus √©lev√©s, tandis que d‚Äôautres subissent une double p√©nalit√© (TPR faible 
et FPR faible), ce qui correspond √† une forme de biais conditionnel post-apprentissage. Ces r√©sultats soulignent les limites des mod√®les 
non lin√©aires comme Random Forest dans des contextes de d√©cision √† fort enjeu social, et justifient la n√©cessit√© d‚Äôint√©grer des contraintes 
explicites de fairness dans les syst√®mes de scoring automatis√©s.
'''

# 8. Propensity Score Matching (PSM) ‚Äì pr√©-IA vs IA

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import NearestNeighbors

# 8.1. Construction du DataFrame combin√© pr√©-IA / IA

pre_ai_psm = pre_ai.copy()
ai_hmda_psm = ai_hmda.copy()

pre_ai_psm["era"] = "pre_IA"
ai_hmda_psm["era"] = "IA"

# Jeux de covariables √† tester (du plus riche au plus simple)
cov_sets_candidates = [
    ["loan_purpose", "loan_type", "hoepa_status", "state_code"],
    ["loan_purpose", "loan_type", "state_code"],
    ["loan_purpose", "loan_type"],
    ["state_code"],
]

# Colonnes r√©ellement disponibles dans les deux bases
all_cols = set(pre_ai_psm.columns).intersection(set(ai_hmda_psm.columns))

# Filtre les sets pour ne garder que les covariables pr√©sentes dans les deux DF
cov_sets = []
for covs in cov_sets_candidates:
    covs_ok = [c for c in covs if c in all_cols]
    if len(covs_ok) > 0:
        cov_sets.append(covs_ok)

print("Jeux de covariables possibles (apr√®s v√©rification des colonnes) :")
for s in cov_sets:
    print("  -", s)

# √âchantillonnage pour ne pas exploser la RAM
N_MAX_PRE = 300_000
N_MAX_IA  = 300_000

pre_sample = pre_ai_psm.sample(min(N_MAX_PRE, len(pre_ai_psm)), random_state=42)
ia_sample  = ai_hmda_psm.sample(min(N_MAX_IA,  len(ai_hmda_psm)),  random_state=42)

psm_df = pd.concat([pre_sample, ia_sample], axis=0)
psm_df["treated"] = (psm_df["era"] == "IA").astype(int)

print("\npsm_df shape (√©chantillon combin√©) :", psm_df.shape)

# 8.1.b. Recherche d'un set de covariables avec strates communes pr√©-IA / IA

chosen_covs = None
psm_overlap = None

for covs in cov_sets:
    print("\n--- Test des covariables :", covs, "---")
    df_tmp = psm_df.copy()

    # Construire une "strate" = concat√©nation des covariables
    df_tmp["strata"] = df_tmp[covs].astype(str).agg(lambda row: "|".join(row), axis=1)

    strata_counts = df_tmp.groupby(["strata", "treated"]).size().unstack(fill_value=0)

    # Strates pr√©sentes dans les deux groupes (treated=1 et treated=0)
    valid_strata = strata_counts[(strata_counts[0] > 0) & (strata_counts[1] > 0)].index

    df_overlap = df_tmp[df_tmp["strata"].isin(valid_strata)].copy()

    print("  -> df_overlap shape :", df_overlap.shape)

    # On demande au moins quelques centaines d'observations pour que ce soit exploitable
    if len(df_overlap) > 1000 and df_overlap["treated"].nunique() == 2:
        chosen_covs = covs
        psm_overlap = df_overlap
        print("  ‚úÖ Covariables retenues pour le PSM :", chosen_covs)
        break

if chosen_covs is None or psm_overlap is None or len(psm_overlap) == 0:
    print(
        "\n‚ö†Ô∏è Aucun set de covariables parmi ceux test√©s ne permet d'obtenir "
        "un √©chantillon avec strates communes pr√©-IA / IA suffisamment grand.\n"
        "   ‚Üí PSM strict non faisable sur cette base (avec ces covariables).\n"
        "   ‚Üí Tu pourras documenter cela dans la th√®se et rester sur les logits/m√©thodes d√©j√† en place."
    )
else:
    print("\n√âchantillon retenu pour le PSM :", psm_overlap.shape)
    print("Covariables finales utilis√©es pour le PSM :", chosen_covs)

    # 8.2. Encodage des covariables et estimation du score de propension
    # ------------------------------------------------------------------

    X_cov = pd.get_dummies(psm_overlap[chosen_covs], drop_first=True)
    y_treated = psm_overlap["treated"]

    psm_logit = LogisticRegression(max_iter=1000, n_jobs=-1)
    psm_logit.fit(X_cov, y_treated)

    psm_overlap["pscore"] = psm_logit.predict_proba(X_cov)[:, 1]

    print("\nR√©sum√© des scores de propension (√©chantillon overlap) :")
    print(psm_overlap["pscore"].describe())

    # 8.3. Restriction au support commun en p-score
    # ---------------------------------------------

    treated = psm_overlap[psm_overlap["treated"] == 1].copy()
    control = psm_overlap[psm_overlap["treated"] == 0].copy()

    min_t, max_t = treated["pscore"].min(), treated["pscore"].max()
    min_c, max_c = control["pscore"].min(), control["pscore"].max()

    lower = max(min_t, min_c)
    upper = min(max_t, max_c)

    print(f"\nSupport pr√©-IA (overlap covariables) : [{min_c:.3f}, {max_c:.3f}]")
    print(f"Support IA     (overlap covariables) : [{min_t:.3f}, {max_t:.3f}]")
    print(f"Support commun th√©orique en p-score  : [{lower:.3f}, {upper:.3f}]")

    if lower >= upper:
        print(
            "‚ö†Ô∏è M√™me apr√®s choix des covariables et strates communes, "
            "le support commun en p-score est vide.\n"
            "   ‚Üí PSM non faisable ; seul constat √† documenter."
        )
    else:
        treated_cs = treated[
            (treated["pscore"] >= lower) & (treated["pscore"] <= upper)
        ].copy()
        control_cs = control[
            (control["pscore"] >= lower) & (control["pscore"] <= upper)
        ].copy()

        print("Treated (common support p-score) :", treated_cs.shape)
        print("Control (common support p-score) :", control_cs.shape)

        # 8.4. Matching 1:1 par plus proche voisin
        # ----------------------------------------

        nbrs = NearestNeighbors(n_neighbors=1, algorithm="ball_tree")
        nbrs.fit(control_cs[["pscore"]])

        distances, indices = nbrs.kneighbors(treated_cs[["pscore"]])
        control_matched = control_cs.iloc[indices.flatten()].copy()

        treated_cs = treated_cs.reset_index(drop=True)
        control_matched = control_matched.reset_index(drop=True)

        matched_df = pd.concat([treated_cs, control_matched], axis=0)
        print("\n√âchantillon appari√© PSM ‚Äì shape :", matched_df.shape)
        print(matched_df[["era", "pscore"]].groupby("era").describe())

        # 8.5. Sauvegarde √©ventuelle pour analyses ult√©rieures (descriptifs, logits, ML)
        # -----------------------------------------------------------------------------

        out_dir = os.path.join(BASE_DIR, "tables")
        os.makedirs(out_dir, exist_ok=True)

        # On harmonise les types avant √©criture parquet
        matched_df_clean = matched_df.copy()

        # Toutes les colonnes objet ‚Üí string (PyArrow g√®re bien √ßa)
        obj_cols = matched_df_clean.select_dtypes(include="object").columns
        print("\nColonnes converties en string avant sauvegarde parquet :", list(obj_cols))

        for col in obj_cols:
            matched_df_clean[col] = matched_df_clean[col].astype("string")

        matched_path = os.path.join(BASE_DIR, "hmda_psm_matched_preIA_IA.parquet")
        matched_df_clean.to_parquet(matched_path, index=False)

        print("\n√âchantillon appari√© sauvegard√© dans :", matched_path)


Jeux de covariables possibles (apr√®s v√©rification des colonnes) :
  - ['loan_purpose', 'loan_type', 'hoepa_status', 'state_code']
  - ['loan_purpose', 'loan_type', 'state_code']
  - ['loan_purpose', 'loan_type']
  - ['state_code']

psm_df shape (√©chantillon combin√©) : (600000, 20)

--- Test des covariables : ['loan_purpose', 'loan_type', 'hoepa_status', 'state_code'] ---
  -> df_overlap shape : (0, 21)

--- Test des covariables : ['loan_purpose', 'loan_type', 'state_code'] ---
  -> df_overlap shape : (0, 21)

--- Test des covariables : ['loan_purpose', 'loan_type'] ---
  -> df_overlap shape : (300645, 21)
  ‚úÖ Covariables retenues pour le PSM : ['loan_purpose', 'loan_type']

√âchantillon retenu pour le PSM : (300645, 21)
Covariables finales utilis√©es pour le PSM : ['loan_purpose', 'loan_type']

R√©sum√© des scores de propension (√©chantillon overlap) :
count    300645.000000
mean          0.557154
std           0.050522
min           0.374526
25%           0.551458
50%           0.586885
75%           0.586885
max           0.586885
Name: pscore, dtype: float64

Support pr√©-IA (overlap covariables) : [0.375, 0.587]
Support IA     (overlap covariables) : [0.375, 0.587]
Support commun th√©orique en p-score  : [0.375, 0.587]
Treated (common support p-score) : (167520, 22)
Control (common support p-score) : (133125, 22)

√âchantillon appari√© PSM ‚Äì shape : (335040, 22)
          pscore                                                                     
           count      mean      std       min       25%       50%       75%       max
era                                                                                  
IA      167520.0  0.561732  0.04662  0.374526  0.551458  0.586885  0.586885  0.586885
pre_IA  167520.0  0.561732  0.04662  0.374526  0.551458  0.586885  0.586885  0.586885

Colonnes converties en string avant sauvegarde parquet : ['state_code', 'era', 'census_tract', 'geoid_tract', 'derived_ethnicity', 'derived_race', 'strata']

√âchantillon appari√© sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\hmda_psm_matched_preIA_IA.parquet


# 8.X. Exploitation de l'√©chantillon appari√© PSM
# ----------------------------------------------
# - PSM.1 : balance des covariables avant / apr√®s matching
# - PSM.2 : logit d'approbation sur l'√©chantillon appari√©

import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf

# 1) Rechargement de l'√©chantillon appari√©
matched_path = os.path.join(BASE_DIR, "hmda_psm_matched_preIA_IA.parquet")
matched_df = pd.read_parquet(matched_path)

print("matched_df shape :", matched_df.shape)
print(matched_df[["era", "loan_purpose", "loan_type"]].head())

# 2) Pr√©paration d'un √©chantillon "avant PSM" comparable
#    (m√™me variables, sur l'√©chantillon psm_df d√©j√† construit dans la cellule pr√©c√©dente)

before_df = psm_df.copy()  # psm_df vient de la cellule PSM pr√©c√©dente

# 2.1. Tableau PSM.1 ‚Äì distribution des covariables avant / apr√®s matching
# ------------------------------------------------------------------------

def covariate_balance_table(df, label):
    """Construit un petit tableau de r√©partition pour loan_purpose et loan_type par era."""
    tab_lp = (
        df.pivot_table(
            index="loan_purpose",
            columns="era",
            values="treated",  # n'importe quelle colonne num√©rique
            aggfunc="count"
        )
        .fillna(0)
    )
    tab_lp["variable"] = "loan_purpose"
    tab_lp = tab_lp.reset_index().rename_axis(None, axis=1)

    tab_lt = (
        df.pivot_table(
            index="loan_type",
            columns="era",
            values="treated",
            aggfunc="count"
        )
        .fillna(0)
    )
    tab_lt["variable"] = "loan_type"
    tab_lt = tab_lt.reset_index().rename_axis(None, axis=1)

    tab = pd.concat([tab_lp, tab_lt], axis=0)

    # Totaux par era pour transformer en parts
    era_cols = [c for c in tab.columns if c in ["pre_IA", "IA"]]
    for c in era_cols:
        total_c = tab[c].sum()
        if total_c > 0:
            tab[c + "_share"] = tab[c] / total_c

    tab["sample"] = label
    return tab

balance_before = covariate_balance_table(before_df, label="before_psm")
balance_after  = covariate_balance_table(matched_df, label="after_psm")

balance_psm = pd.concat([balance_before, balance_after], axis=0)

# Sauvegarde pour Table PSM.1
out_dir = os.path.join(BASE_DIR, "tables")
os.makedirs(out_dir, exist_ok=True)

balance_path = os.path.join(out_dir, "psm1_balance_before_after.csv")
balance_psm.to_csv(balance_path, index=False)

print("\nTable PSM.1 (balance covariables) sauvegard√©e dans :", balance_path)
display(balance_psm.head(20))

# 3) Tableau PSM.2 ‚Äì logit d'approbation sur l'√©chantillon appari√©
# ----------------------------------------------------------------
# Hypoth√®se : la variable d'int√©r√™t est `approved` (0/1)

if "approved" in matched_df.columns:
    print("\nEstimation logit d'approbation sur l'√©chantillon appari√©...")

    # On code era en dummy IA (1) vs pr√©_IA (0)
    matched_df["era_IA"] = (matched_df["era"] == "IA").astype(int)

    # Mod√®le logit simple : approved ~ era_IA
    logit_formula = "approved ~ era_IA"
    logit_model = smf.logit(formula=logit_formula, data=matched_df).fit(disp=0)

    print(logit_model.summary())

    # Extraction rapide des coefficients pour Table PSM.2
    logit_res = logit_model.summary2().tables[1].reset_index()
    logit_res.rename(columns={"index": "variable"}, inplace=True)

    logit_path = os.path.join(out_dir, "psm2_logit_approved_matched.csv")
    logit_res.to_csv(logit_path, index=False)

    print("\nTable PSM.2 (logit sur √©chantillon appari√©) sauvegard√©e dans :", logit_path)
    display(logit_res)
else:
    print(
        "\n‚ö†Ô∏è La variable 'approved' n'est pas pr√©sente dans matched_df.\n"
        "   ‚Üí Impossible de calculer le logit PSM.2 tel quel ; v√©rifie le nom de la variable de r√©sultat."
    )

matched_df shape : (335040, 22)
  era  loan_purpose  loan_type
0  IA           1.0        1.0
1  IA           1.0        1.0
2  IA           1.0        1.0
3  IA           1.0        1.0
4  IA           2.0        1.0

Table PSM.1 (balance covariables) sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\psm1_balance_before_after.csv
loan_purpose	IA	pre_IA	variable	loan_type	IA_share	pre_IA_share	sample
0	1.0	147925.0	109894.0	loan_purpose	NaN	0.246542	0.183157	before_psm
1	2.0	19595.0	24626.0	loan_purpose	NaN	0.032658	0.041043	before_psm
2	3.0	0.0	165480.0	loan_purpose	NaN	0.000000	0.275800	before_psm
3	4.0	16604.0	0.0	loan_purpose	NaN	0.027673	0.000000	before_psm
4	5.0	3715.0	0.0	loan_purpose	NaN	0.006192	0.000000	before_psm
5	31.0	61558.0	0.0	loan_purpose	NaN	0.102597	0.000000	before_psm
6	32.0	50603.0	0.0	loan_purpose	NaN	0.084338	0.000000	before_psm
0	NaN	245787.0	240745.0	loan_type	1.0	0.409645	0.401242	before_psm
1	NaN	40374.0	51142.0	loan_type	2.0	0.067290	0.085237	before_psm
2	NaN	13839.0	6672.0	loan_type	3.0	0.023065	0.011120	before_psm
3	NaN	0.0	1441.0	loan_type	4.0	0.000000	0.002402	before_psm
0	1.0	147925.0	147925.0	loan_purpose	NaN	0.441514	0.441514	after_psm
1	2.0	19595.0	19595.0	loan_purpose	NaN	0.058486	0.058486	after_psm
0	NaN	134661.0	134661.0	loan_type	1.0	0.401925	0.401925	after_psm
1	NaN	25755.0	25755.0	loan_type	2.0	0.076871	0.076871	after_psm
2	NaN	7104.0	7104.0	loan_type	3.0	0.021203	0.021203	after_psm

Estimation logit d'approbation sur l'√©chantillon appari√©...
                           Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:               335040
Model:                          Logit   Df Residuals:                   335038
Method:                           MLE   Df Model:                            1
Date:                Thu, 27 Nov 2025   Pseudo R-squ.:                 0.06676
Time:                        16:52:08   Log-Likelihood:            -2.1212e+05
converged:                       True   LL-Null:                   -2.2729e+05
Covariance Type:            nonrobust   LLR p-value:                     0.000
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -1.0081      0.006   -182.614      0.000      -1.019      -0.997
era_IA         1.2546      0.007    169.604      0.000       1.240       1.269
==============================================================================

Table PSM.2 (logit sur √©chantillon appari√©) sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\psm2_logit_approved_matched.csv
variable	Coef.	Std.Err.	z	P>|z|	[0.025	0.975]
0	Intercept	-1.008124	0.005521	-182.614024	0.0	-1.018944	-0.997304
1	era_IA	1.254588	0.007397	169.603549	0.0	1.240090	1.269087


1. Analyse d√©taill√©e de PSM.1 ‚Äì Balance des covariables avant / apr√®s appariement
1.1. Objectif statistique du PSM
Le Propensity Score Matching (PSM) vise √† rendre comparables les dossiers observ√©s en p√©riode pr√©-IA et IA, en √©quilibrant les distributions des caract√©ristiques observables.

Dans cette √©tude, l‚Äôappariement repose sur deux variables cl√©s :

loan_purpose (motif du pr√™t)
loan_type (type de produit de cr√©dit)
Ces variables sont observables dans les deux p√©riodes et structurent fortement les d√©cisions d‚Äôoctroi.

1.2. D√©s√©quilibre structurel avant PSM
Avant appariement, les portefeuilles pr√©-IA et IA sont fortement d√©s√©quilibr√©s.

Tableau ‚Äì R√©partition des loan_purpose avant PSM
Code	IA (nb)	Pr√©-IA (nb)	Part IA	Part Pr√©-IA	Interpr√©tation
1	147 925	109 894	24.65 %	18.32 %	Sur-repr√©sent√© en IA
2	19 595	24 626	3.27 %	4.10 %	L√©g√®rement plus fr√©quent en pr√©-IA
3	0	165 480	0.00 %	27.58 %	Exclusif √† la p√©riode pr√©-IA
4	16 604	0	2.77 %	0.00 %	Exclusif √† la p√©riode IA
5	3 715	0	0.62 %	0.00 %	Exclusif √† la p√©riode IA
31	61 558	0	10.26 %	0.00 %	Exclusif √† la p√©riode IA
32	50 603	0	8.43 %	0.00 %	Exclusif √† la p√©riode IA
Lecture acad√©mique :

Avant PSM, plusieurs cat√©gories de pr√™ts n‚Äôexistent que dans une seule p√©riode.
Cela emp√™che toute comparaison causale directe entre pr√©-IA et IA, car les diff√©rences observ√©es peuvent simplement refl√©ter une transformation structurelle des portefeuilles plut√¥t qu‚Äôun effet technologique.

Tableau ‚Äì R√©partition des loan_type avant PSM
Code	IA (nb)	Pr√©-IA (nb)	Part IA	Part Pr√©-IA	Lecture
1	245 787	240 745	40.96 %	40.12 %	R√©partition proche
2	40 374	51 142	6.73 %	8.52 %	Plus fr√©quent en pr√©-IA
3	13 839	6 672	2.31 %	1.11 %	Sur-repr√©sent√© en IA
4	0	1 441	0.00 %	0.24 %	Exclusif √† la p√©riode pr√©-IA
1.3. R√©sultats apr√®s PSM : √©quilibre parfait
Apr√®s appariement, seuls les profils communs aux deux p√©riodes sont conserv√©s.

Tableau ‚Äì R√©partition des covariables apr√®s PSM
Variable	Code	IA (nb)	Pr√©-IA (nb)	Part IA	Part Pr√©-IA
loan_purpose	1	147 925	147 925	44.15 %	44.15 %
loan_purpose	2	19 595	19 595	5.85 %	5.85 %
loan_type	1	134 661	134 661	40.19 %	40.19 %
loan_type	2	25 755	25 755	7.69 %	7.69 %
loan_type	3	7 104	7 104	2.12 %	2.12 %
Conclusion m√©thodologique
L‚Äôappariement par score de propension a permis de construire deux sous-√©chantillons strictement comparables.
Les distributions de loan_purpose et loan_type sont parfaitement identiques entre les p√©riodes pr√©-IA et IA.
Cette √©tape neutralise le biais de composition des portefeuilles et autorise une inf√©rence causale plus cr√©dible.

2. Analyse d√©taill√©e de PSM.2 ‚Äì Logit d‚Äôapprobation sur √©chantillon appari√©
2.1. R√©sultats du mod√®le logistique
Tableau ‚Äì Estimation logit
Variable	Coefficient	Erreur standard	z-stat	p-value
Intercept	‚àí1.0081	0.0055	‚àí182.61	< 0.001
era_IA	+1.2546	0.0074	169.60	< 0.001
2.2. Interpr√©tation probabiliste
Probabilit√© de base (p√©riode pr√©-IA)
√©
 

Indicateur	Valeur
Probabilit√© d‚Äôapprobation (pr√©-IA)	26,7 %
2.3. Effet de l‚Äô√®re IA
Odds ratio

Indicateur	R√©sultat
Odds Ratio	3,51
Direction de l‚Äôeffet	Positif
Significativit√©	p < 0,001
2.4. Interpr√©tation acad√©mique pr√™te √† int√©grer
Sur l‚Äô√©chantillon appari√© par score de propension, le mod√®le logistique met en √©vidence un effet fortement positif de l‚Äô√®re IA sur la probabilit√© d‚Äôapprobation (Œ≤ = 1,255 ; p < 0,001).
En termes d‚Äôodds ratio, les dossiers trait√©s durant la p√©riode IA pr√©sentent une probabilit√© d‚Äôapprobation environ 3,5 fois plus √©lev√©e que les dossiers comparables trait√©s en p√©riode pr√©-IA.
Ce r√©sultat persiste apr√®s correction du biais de s√©lection par PSM, renfor√ßant l‚Äôhypoth√®se d‚Äôun changement structurel de r√©gime d√©cisionnel.

2.5. Lecture √©conomique approfondie
Niveau	Interpr√©tation
Statistique	Effet stable, pr√©cis et hautement significatif
M√©thodologique	R√©sultat robuste apr√®s √©quilibrage des portefeuilles
√âconomique	Tol√©rance accrue au risque ou meilleure discrimination du risque par l‚ÄôIA
Institutionnel	Transition vers des syst√®mes de d√©cision data-driven
Conclusion g√©n√©rale pr√™te √† ins√©rer
M√™me apr√®s correction du biais de composition des portefeuilles par PSM, la p√©riode IA demeure associ√©e √† une probabilit√© significativement plus √©lev√©e d‚Äôapprobation des dossiers.
Ce signal ne peut plus √™tre attribu√© √† de simples diff√©rences de structure des demandes, ce qui sugg√®re un effet propre du changement de paradigme technologique dans les processus d‚Äôoctroi du cr√©dit.

# 8.X ‚Äì PSM.3 : Logits enrichis et par sous-groupes (race / revenu)

import os
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf

# -------------------------------------------------------------------
# 1) Rechargement de l'√©chantillon appari√© PSM
# -------------------------------------------------------------------

matched_path = os.path.join(BASE_DIR, "hmda_psm_matched_preIA_IA.parquet")
matched_df = pd.read_parquet(matched_path)

print("matched_df shape :", matched_df.shape)
print("Colonnes disponibles :", matched_df.columns.tolist()[:40])

# Variable de traitement : era_IA = 1 si IA, 0 si pr√©-IA
matched_df["era_IA"] = (matched_df["era"] == "IA").astype(int)

# Dossier de sortie pour les tableaux
tables_dir = os.path.join(BASE_DIR, "tables")
os.makedirs(tables_dir, exist_ok=True)

# -------------------------------------------------------------------
# 2) PSM.3a ‚Äì Logit enrichi avec contr√¥les loan_purpose / loan_type
# -------------------------------------------------------------------
# Mod√®le : approved ~ era_IA + C(loan_purpose) + C(loan_type)

if "approved" in matched_df.columns:
    print("\n[PSM.3a] Estimation logit enrichi avec contr√¥les...")

    formula_psm3a = "approved ~ era_IA + C(loan_purpose) + C(loan_type)"
    logit_psm3a = smf.logit(formula=formula_psm3a, data=matched_df).fit(disp=0)

    print(logit_psm3a.summary())

    psm3a_res = logit_psm3a.summary2().tables[1].reset_index()
    psm3a_res.rename(columns={"index": "variable"}, inplace=True)

    psm3a_path = os.path.join(tables_dir, "psm3a_logit_approved_controls.csv")
    psm3a_res.to_csv(psm3a_path, index=False)

    print("\n[PSM.3a] Tableau sauvegard√© dans :", psm3a_path)
else:
    print("\n‚ö†Ô∏è Impossible de calculer PSM.3a : la colonne 'approved' est absente de matched_df.")


# -------------------------------------------------------------------
# 3) PSM.3b ‚Äì Logit par sous-groupes de race (si available)
# -------------------------------------------------------------------
# Mod√®le par race : approved ~ era_IA (√©chantillon appari√©, restreint √† chaque race)

psm3b_rows = []

if "approved" in matched_df.columns and "derived_race" in matched_df.columns:
    print("\n[PSM.3b] Estimation logit par sous-groupes de race...")

    # On garde uniquement les valeurs non nulles de derived_race
    race_values = (
        matched_df["derived_race"]
        .dropna()
        .astype(str)
        .value_counts()
    )

    print("Races consid√©r√©es pour PSM.3b :", race_values.to_dict())

    # On peut ignorer les cat√©gories avec tr√®s peu d'observations
    MIN_N = 1000

    for race_val, n_race in race_values.items():
        if n_race < MIN_N:
            print(f"  - Race '{race_val}' ignor√©e (n={n_race} < {MIN_N})")
            continue

        df_sub = matched_df[matched_df["derived_race"].astype(str) == race_val].copy()

        # V√©rifier qu'on a bien les deux p√©riodes
        if df_sub["era_IA"].nunique() < 2:
            print(f"  - Race '{race_val}' ignor√©e (une seule √®re pr√©sente)")
            continue

        print(f"  - Estimation pour race '{race_val}' (n={len(df_sub)})...")

        try:
            model_race = smf.logit("approved ~ era_IA", data=df_sub).fit(disp=0)
            coef_table = model_race.summary2().tables[1]

            # On r√©cup√®re juste la ligne era_IA
            if "era_IA" in coef_table.index:
                row = coef_table.loc["era_IA"].to_dict()
                row["race"] = race_val
                psm3b_rows.append(row)
        except Exception as e:
            print(f"    ‚ö†Ô∏è Probl√®me pour race '{race_val}' :", e)

    if psm3b_rows:
        psm3b_df = pd.DataFrame(psm3b_rows)
        # Renommer les colonnes pour plus de clart√©
        psm3b_df = psm3b_df.rename(
            columns={
                "Coef.": "coef",
                "Std.Err.": "std_err",
                "P>|z|": "p_value",
                "[0.025": "ci_low",
                "0.975]": "ci_high",
            }
        )
        psm3b_path = os.path.join(tables_dir, "psm3b_logit_approved_by_race.csv")
        psm3b_df.to_csv(psm3b_path, index=False)
        print("\n[PSM.3b] Tableau sauvegard√© dans :", psm3b_path)
        display(psm3b_df)
    else:
        print("\n[PSM.3b] Aucun sous-groupe de race exploitable pour l'estimation.")
else:
    print("\n‚ö†Ô∏è PSM.3b non calcul√© : colonnes 'approved' ou 'derived_race' absentes.")


# -------------------------------------------------------------------
# 4) PSM.3c ‚Äì Logit par terciles de revenu de zone (acs_median_income)
# -------------------------------------------------------------------
# Mod√®le par tercile de revenu : approved ~ era_IA

psm3c_rows = []

if "approved" in matched_df.columns and "acs_median_income" in matched_df.columns:
    print("\n[PSM.3c] Estimation logit par terciles de revenu (acs_median_income)...")

    df_income = matched_df.dropna(subset=["acs_median_income"]).copy()

    # Construction de terciles de revenu
    df_income["income_tercile"] = pd.qcut(
        df_income["acs_median_income"],
        q=3,
        labels=["low", "mid", "high"]
    )

    tercile_counts = df_income["income_tercile"].value_counts()
    print("Terciles de revenu (effectifs) :", tercile_counts.to_dict())

    for tercile in ["low", "mid", "high"]:
        df_sub = df_income[df_income["income_tercile"] == tercile].copy()
        n_sub = len(df_sub)

        if n_sub < 1000:
            print(f"  - Tercile '{tercile}' ignor√© (n={n_sub} < 1000)")
            continue

        if df_sub["era_IA"].nunique() < 2:
            print(f"  - Tercile '{tercile}' ignor√© (une seule √®re pr√©sente)")
            continue

        print(f"  - Estimation pour tercile '{tercile}' (n={n_sub})...")

        try:
            model_inc = smf.logit("approved ~ era_IA", data=df_sub).fit(disp=0)
            coef_table = model_inc.summary2().tables[1]

            if "era_IA" in coef_table.index:
                row = coef_table.loc["era_IA"].to_dict()
                row["income_tercile"] = tercile
                psm3c_rows.append(row)
        except Exception as e:
            print(f"    ‚ö†Ô∏è Probl√®me pour le tercile '{tercile}' :", e)

    if psm3c_rows:
        psm3c_df = pd.DataFrame(psm3c_rows)
        psm3c_df = psm3c_df.rename(
            columns={
                "Coef.": "coef",
                "Std.Err.": "std_err",
                "P>|z|": "p_value",
                "[0.025": "ci_low",
                "0.975]": "ci_high",
            }
        )
        psm3c_path = os.path.join(tables_dir, "psm3c_logit_approved_by_income_tercile.csv")
        psm3c_df.to_csv(psm3c_path, index=False)
        print("\n[PSM.3c] Tableau sauvegard√© dans :", psm3c_path)
        display(psm3c_df)
    else:
        print("\n[PSM.3c] Aucun tercile de revenu exploitable pour l'estimation.")
else:
    print("\n‚ö†Ô∏è PSM.3c non calcul√© : colonnes 'approved' ou 'acs_median_income' absentes.")


matched_df shape : (335040, 22)
Colonnes disponibles : ['action_taken', 'applicant_sex', 'county_code', 'hoepa_status', 'lien_status', 'loan_purpose', 'loan_type', 'preapproval', 'purchaser_type', 'rate_spread', 'state_code', 'year', 'approved', 'era', 'census_tract', 'geoid_tract', 'loan_amount', 'derived_ethnicity', 'derived_race', 'treated', 'strata', 'pscore']

[PSM.3a] Estimation logit enrichi avec contr√¥les...
                           Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:               335040
Model:                          Logit   Df Residuals:                   335035
Method:                           MLE   Df Model:                            4
Date:                Thu, 27 Nov 2025   Pseudo R-squ.:                  0.1962
Time:                        17:04:19   Log-Likelihood:            -1.8269e+05
converged:                       True   LL-Null:                   -2.2729e+05
Covariance Type:            nonrobust   LLR p-value:                     0.000
==========================================================================================
                             coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------------
Intercept                 -1.7525      0.007   -235.247      0.000      -1.767      -1.738
C(loan_purpose)[T.2.0]     2.0543      0.013    155.790      0.000       2.028       2.080
C(loan_type)[T.2.0]        2.1845      0.012    181.069      0.000       2.161       2.208
C(loan_type)[T.3.0]       -0.1319      0.020     -6.462      0.000      -0.172      -0.092
era_IA                     1.5458      0.009    180.242      0.000       1.529       1.563
==========================================================================================

[PSM.3a] Tableau sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\psm3a_logit_approved_controls.csv

[PSM.3b] Estimation logit par sous-groupes de race...
Races consid√©r√©es pour PSM.3b : {'White': 101636, 'Race Not Available': 35345, 'Asian': 15225, 'Black or African American': 11277, 'Joint': 2978, 'American Indian or Alaska Native': 456, 'Native Hawaiian or Other Pacific Islander': 324, '2 or more minority races': 208, 'Free Form Text Only': 71}
  - Race 'White' ignor√©e (une seule √®re pr√©sente)
  - Race 'Race Not Available' ignor√©e (une seule √®re pr√©sente)
  - Race 'Asian' ignor√©e (une seule √®re pr√©sente)
  - Race 'Black or African American' ignor√©e (une seule √®re pr√©sente)
  - Race 'Joint' ignor√©e (une seule √®re pr√©sente)
  - Race 'American Indian or Alaska Native' ignor√©e (n=456 < 1000)
  - Race 'Native Hawaiian or Other Pacific Islander' ignor√©e (n=324 < 1000)
  - Race '2 or more minority races' ignor√©e (n=208 < 1000)
  - Race 'Free Form Text Only' ignor√©e (n=71 < 1000)

[PSM.3b] Aucun sous-groupe de race exploitable pour l'estimation.

‚ö†Ô∏è PSM.3c non calcul√© : colonnes 'approved' ou 'acs_median_income' absentes.
3. Analyse d√©taill√©e de PSM.3 ‚Äì Logits enrichis et par sous-groupes
3.1. PSM.3a ‚Äì Logit enrichi avec contr√¥les loan_purpose et loan_type
3.1.1. Sp√©cification du mod√®le
Sur l‚Äô√©chantillon appari√© PSM (335 040 observations), tu estimes le mod√®le suivant :

ùüôùüôùüô

avec comme cat√©gories de r√©f√©rence :

loan_purpose = 1 (cat√©gorie de base),
loan_type = 1 (type de pr√™t de base),
era_IA = 0 pour la p√©riode pr√©-IA.
La variable d√©pendante approved vaut 1 si le dossier est approuv√©, 0 sinon.

3.1.2. R√©sultats du logit enrichi (PSM.3a)
Rappel des coefficients estim√©s :

Variable	Coefficient Œ≤	Erreur std.	z-stat	p-value
Intercept	-1.7525	0.0070	-235.25	< 0.001
C(loan_purpose)[T.2.0]	+2.0543	0.0132	155.79	< 0.001
C(loan_type)[T.2.0]	+2.1845	0.0121	181.07	< 0.001
C(loan_type)[T.3.0]	-0.1319	0.0204	-6.46	< 0.001
era_IA	+1.5458	0.0086	180.24	< 0.001
On peut traduire ces coefficients en odds ratios (OR) :


Variable	Coefficient Œ≤	Odds Ratio (e^{\beta})	Lecture
Intercept	-1.7525	‚âà 0.17	Niveau d‚Äôodds en pr√©-IA, pour le profil de r√©f√©rence
C(loan_purpose)[T.2.0]	+2.0543	‚âà 7.80	Les dossiers de type 2 ont ~7,8 fois plus de chances (odds) d‚Äô√™tre approuv√©s que ceux de type 1
C(loan_type)[T.2.0]	+2.1845	‚âà 8.89	Les loan_type = 2 ont ~8,9 fois plus d‚Äôodds d‚Äôapprobation que loan_type = 1
C(loan_type)[T.3.0]	-0.1319	‚âà 0.88	Les loan_type = 3 ont des odds ~12 % plus faibles que loan_type = 1
era_IA	+1.5458	‚âà 4.69	L‚Äô√®re IA multiplie les odds d‚Äôapprobation par ‚âà 4,7 √† caract√©ristiques identiques
3.1.3. Probabilit√©s associ√©es au profil de r√©f√©rence
Pour un dossier :

en p√©riode pr√©-IA (era_IA = 0),
avec loan_purpose = 1,
et loan_type = 1,
la probabilit√© d‚Äôapprobation vaut :

√©
 

soit environ 14,8 %.

Pour le m√™me profil en p√©riode IA (era_IA = 1) :

 

soit environ 44,9 %.

Profil	Formule (logit)	Probabilit√© d‚Äôapprobation
R√©f√©rence pr√©-IA (purpose=1, type=1)	(\sigma(-1.7525))	‚âà 14,8 %
M√™me profil en IA	(\sigma(-1.7525 + 1.5458))	‚âà 44,9 %
Interpr√©tation cl√© (PSM.3a)
√Ä loan_purpose et loan_type fix√©s, passer de la p√©riode pr√©-IA √† l‚Äô√®re IA multiplie les odds d‚Äôapprobation par environ 4,7, et fait passer la probabilit√© d‚Äôapprobation du profil de r√©f√©rence d‚Äôenviron 15 % √† 45 %.
Autrement dit, m√™me √† portefeuille de produits identique, l‚Äô√®re IA est associ√©e √† un niveau d‚Äôapprobation nettement plus √©lev√©.

3.1.4. R√¥le des contr√¥les loan_purpose et loan_type
Les coefficients associ√©s aux contr√¥les montrent que :

Certains motifs de pr√™t (loan_purpose = 2) ont une probabilit√© beaucoup plus √©lev√©e d‚Äô√™tre approuv√©s que la cat√©gorie de r√©f√©rence (loan_purpose = 1), avec un OR ‚âà 7,8.
Certains types de pr√™t (loan_type = 2) sont √©galement beaucoup plus favoris√©s que loan_type = 1 (OR ‚âà 8,9).
D‚Äôautres types (loan_type = 3) ont un l√©ger d√©savantage (OR ‚âà 0,88).
En incluant ces variables dans le mod√®le PSM.3a, tu montres que l‚Äôeffet IA (OR ‚âà 4,69) ne se r√©duit pas √† un simple changement dans la composition porteuse/produits, mais reste massif et significatif une fois ces dimensions contr√¥l√©es.

3.2. PSM.3b ‚Äì Logits par sous-groupes de race : impossibilit√© empirique
Le bloc PSM.3b tentait d‚Äôestimer, pour chaque modalit√© de derived_race, un mod√®le simplifi√© :


restreint aux individus appartenant √† une race donn√©e ( r ).

Les effectifs par race dans l‚Äô√©chantillon appari√© sont les suivants :

derived_race	n	Commentaire
White	101 636	Une seule √®re pr√©sente
Race Not Available	35 345	Une seule √®re pr√©sente
Asian	15 225	Une seule √®re pr√©sente
Black or African American	11 277	Une seule √®re pr√©sente
Joint	2 978	Une seule √®re pr√©sente
American Indian or Alaska Native	456	n < 1 000
Native Hawaiian or Other Pacific Islander	324	n < 1 000
2 or more minority races	208	n < 1 000
Free Form Text Only	71	n < 1 000
Le script te retourne :

pour les grandes cat√©gories (White, Race Not Available, Asian, Black or African American, Joint) :
¬´ une seule √®re pr√©sente ¬ª ‚Üí pas de variabilit√© de era_IA dans le sous-√©chantillon,

pour les petites minorit√©s :
effectifs insuffisants (n < 1 000).

Cons√©quence statistique :

Quand une race donn√©e n‚Äôest observ√©e que dans une seule √®re (pr√©-IA ou IA mais pas les deux), il est impossible d‚Äôidentifier un coefficient (\beta_{r,\text{IA}}) : le mod√®le est parfaitement colin√©aire.
M√™me avec PSM, l‚Äôappariement sur loan_purpose et loan_type aboutit √† un √©chantillon o√π chaque race se concentre dans une seule p√©riode (ou presque), ce qui prive l‚Äôestimation intra-groupe de variation temporelle exploitable.
Formulation pour la th√®se
Les tentatives d‚Äôestimation de mod√®les PSM sp√©cifiques par race (PSM.3b) se heurtent √† une contrainte empirique forte : dans l‚Äô√©chantillon appari√©, la plupart des cat√©gories de derived_race ne sont observ√©es que dans une seule p√©riode (pr√©-IA ou IA), ou avec des effectifs trop faibles.
En l‚Äôabsence de variabilit√© suffisante de era_IA au sein des sous-groupes raciaux, l‚Äôeffet de l‚Äô√®re IA ne peut pas √™tre identifi√© s√©par√©ment par race.
L‚Äôestimation PSM doit donc √™tre interpr√©t√©e comme un effet moyen agr√©g√© sur l‚Äôensemble des races, et non comme un effet sp√©cifique √† chaque groupe racial.

3.3. PSM.3c ‚Äì Logits par terciles de revenu (acs_median_income) : limite de donn√©es
Le bloc PSM.3c visait √† construire des terciles de revenu de zone via acs_median_income et √† estimer :


pour chaque tercile de revenu ( t \in {\text{low, mid, high}} ).

Or le script retourne :

‚ö†Ô∏è PSM.3c non calcul√© : colonnes 'approved' ou 'acs_median_income' absentes.

Dans ton matched_df, tu disposes de :

approved (variable d√©pendante),
mais pas de colonne acs_median_income : cette information ACS n‚Äôa pas √©t√© fusionn√©e au moment de la construction de l‚Äô√©chantillon PSM (ou a √©t√© filtr√©e auparavant).
Formulation pour la th√®se
La d√©clinaison des mod√®les PSM par terciles de revenu de zone (PSM.3c) n‚Äôa pas pu √™tre impl√©ment√©e dans la version finale de l‚Äô√©chantillon appari√©, faute de variable acs_median_income disponible dans les donn√©es PSM.
L‚Äôanalyse diff√©rentielle par niveau de revenu reste donc une piste pour des extensions ult√©rieures, √† condition de reconstruire un √©chantillon appari√© incluant explicitement les variables ACS.

3.4. Synth√®se PSM.3 √† ins√©rer
PSM.3a montre que, m√™me en contr√¥lant explicitement pour le motif et le type de pr√™t, l‚Äô√®re IA est associ√©e √† une augmentation massive des odds d‚Äôapprobation (OR ‚âà 4,69), faisant passer, pour le profil de base, la probabilit√© d‚Äôapprobation d‚Äôenviron 15 % √† 45 %.
PSM.3b ne peut pas isoler un effet IA par race, car l‚Äô√©chantillon appari√© ne contient pas suffisamment de variabilit√© temporelle au sein de chaque groupe racial : chaque race se concentre quasi int√©gralement dans une seule √®re.
PSM.3c n‚Äôest pas estimable dans cette version des donn√©es, la variable de revenu de zone acs_median_income n‚Äô√©tant pas pr√©sente dans l‚Äô√©chantillon PSM final.
En r√©sum√©, PSM.3 confirme la robustesse de l‚Äôeffet moyen de l‚Äô√®re IA sur la probabilit√© d‚Äôapprobation, mais met en lumi√®re des limites de donn√©es et de support commun qui rendent d√©licate la d√©composition de cet effet par sous-groupes socio-d√©mographiques (race, revenu).

# %% [markdown]
# # 9. Cross-era ML ‚Äì performance crois√©e pr√©-IA ‚Üî IA
#
# üîó R√©f√©rence th√®se :
# - Section 6.X : "Robustesse intertemporelle des mod√®les de scoring"
# - Tableau 7.1 : performance crois√©e train pr√©-IA / test IA et inversement

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, f1_score, accuracy_score

# 9.1. Construction du DataFrame combin√© pr√©-IA / IA sur features communes

common_ml_cols = ["loan_purpose", "loan_type", "hoepa_status", "state_code", "year", "approved"]
common_ml_cols = [c for c in common_ml_cols if c in pre_ai.columns and c in ai_hmda.columns]

print("Colonnes ML communes pr√©-IA / IA :", common_ml_cols)

pre_ml = pre_ai[common_ml_cols].copy()
ia_ml  = ai_hmda[common_ml_cols].copy()

pre_ml["era"] = "pre_IA"
ia_ml["era"]  = "IA"

ml_df = pd.concat([pre_ml, ia_ml], axis=0)
ml_df["approved"] = ml_df["approved"].astype(int)

# 9.2. Encodage commun (one-hot) et s√©paration des cohortes

X_all_ml = pd.get_dummies(
    ml_df.drop(columns=["approved", "era"]),
    drop_first=True
)
y_all_ml = ml_df["approved"]
era_all  = ml_df["era"]

X_pre = X_all_ml[era_all == "pre_IA"]
y_pre = y_all_ml[era_all == "pre_IA"]

X_ia  = X_all_ml[era_all == "IA"]
y_ia  = y_all_ml[era_all == "IA"]

print("X_pre shape :", X_pre.shape, "X_ia shape :", X_ia.shape)

# 9.3. Mod√®le RF ‚Äì train sur pr√©-IA, test sur pr√©-IA ET IA

rf_pre = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)
rf_pre.fit(X_pre, y_pre)

y_pre_pred_proba_pre = rf_pre.predict_proba(X_pre)[:, 1]
y_pre_pred_pre       = (y_pre_pred_proba_pre >= 0.5).astype(int)

y_ia_pred_proba_pre = rf_pre.predict_proba(X_ia)[:, 1]
y_ia_pred_pre       = (y_ia_pred_proba_pre >= 0.5).astype(int)

def perf_block(y_true, y_pred_proba, y_pred_label):
    return (
        roc_auc_score(y_true, y_pred_proba),
        f1_score(y_true, y_pred_label),
        accuracy_score(y_true, y_pred_label)
    )

auc_pre_pre, f1_pre_pre, acc_pre_pre = perf_block(y_pre, y_pre_pred_proba_pre, y_pre_pred_pre)
auc_pre_ia,  f1_pre_ia,  acc_pre_ia  = perf_block(y_ia,  y_ia_pred_proba_pre,  y_ia_pred_pre)

# 9.4. Mod√®le RF ‚Äì train sur IA, test sur IA ET pr√©-IA

rf_ia = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)
rf_ia.fit(X_ia, y_ia)

y_ia_pred_proba_ia = rf_ia.predict_proba(X_ia)[:, 1]
y_ia_pred_ia       = (y_ia_pred_proba_ia >= 0.5).astype(int)

y_pre_pred_proba_ia = rf_ia.predict_proba(X_pre)[:, 1]
y_pre_pred_ia       = (y_pre_pred_proba_ia >= 0.5).astype(int)

auc_ia_ia,  f1_ia_ia,  acc_ia_ia  = perf_block(y_ia,  y_ia_pred_proba_ia,  y_ia_pred_ia)
auc_ia_pre, f1_ia_pre, acc_ia_pre = perf_block(y_pre, y_pre_pred_proba_ia, y_pre_pred_ia)

# 9.5. Tableau r√©capitulatif cross-era

cross_rows = [
    ("Train pr√©-IA", "Test pr√©-IA", auc_pre_pre, f1_pre_pre, acc_pre_pre),
    ("Train pr√©-IA", "Test IA",    auc_pre_ia,  f1_pre_ia,  acc_pre_ia),
    ("Train IA",     "Test IA",    auc_ia_ia,   f1_ia_ia,   acc_ia_ia),
    ("Train IA",     "Test pr√©-IA",auc_ia_pre,  f1_ia_pre,  acc_ia_pre),
]

cross_df = pd.DataFrame(
    cross_rows,
    columns=["Train_era", "Test_era", "AUC", "F1", "Accuracy"]
)

print("\n=== Tableau 7.1 ‚Äì Performance cross-era (RandomForest) ===")
display(cross_df)

cross_path = os.path.join(out_dir, "table_7_1_cross_era_performance_rf.csv")
cross_df.to_csv(cross_path, index=False)
print("Tableau 7.1 sauvegard√© dans :", cross_path)

Colonnes ML communes pr√©-IA / IA : ['loan_purpose', 'loan_type', 'hoepa_status', 'state_code', 'year', 'approved']
X_pre shape : (13511720, 9) X_ia shape : (569500, 9)

=== Tableau 7.1 ‚Äì Performance cross-era (RandomForest) ===
Train_era	Test_era	AUC	F1	Accuracy
0	Train pr√©-IA	Test pr√©-IA	0.615385	0.827640	0.707265
1	Train pr√©-IA	Test IA	0.537439	0.703264	0.542334
2	Train IA	Test IA	0.910744	0.865198	0.849940
3	Train IA	Test pr√©-IA	0.575681	0.649265	0.562378
Tableau 7.1 sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_7_1_cross_era_performance_rf.csv
9. Cross-era ML ‚Äì Lecture d√©taill√©e du Tableau 7.1 (RandomForest)
9.1. Objectif de l‚Äôexercice cross-era
Cette section teste la robustesse intertemporelle des mod√®les de scoring, conform√©ment √† la Section 6.X de la th√®se (¬´ Robustesse intertemporelle des mod√®les de scoring ¬ª) et au Tableau 7.1 :

Un RandomForest est entra√Æn√© s√©par√©ment sur :
la cohorte pr√©-IA,
la cohorte IA.
Chaque mod√®le est ensuite √©valu√© :
dans son √®re d‚Äôentra√Ænement (intra-cohorte),
sur l‚Äôautre √®re (cross-era).
Les features utilis√©es sont les covariables communes :
loan_purpose, loan_type, hoepa_status, state_code, year, ainsi que la cible approved.

9.2. Rappel des r√©sultats ‚Äì Tableau 7.1
Tableau 7.1 ‚Äì Performance cross-era du RandomForest
Train_era	Test_era	AUC	F1	Accuracy
Train pr√©-IA	Test pr√©-IA	0.6154	0.8276	0.7073
Train pr√©-IA	Test IA	0.5374	0.7033	0.5423
Train IA	Test IA	0.9107	0.8652	0.8499
Train IA	Test pr√©-IA	0.5757	0.6493	0.5624
On peut lire ce tableau comme une matrice 2√ó2 :

Ligne 1‚Äì2 : mod√®le entra√Æn√© en pr√©-IA, test√© sur pr√©-IA puis IA.
Ligne 3‚Äì4 : mod√®le entra√Æn√© en IA, test√© sur IA puis pr√©-IA.
9.3. Performance intra-era vs cross-era
9.3.1. Mod√®le entra√Æn√© en pr√©-IA
√âvaluation	AUC	F1	Accuracy	Lecture
Train pr√©-IA ‚Üí Test pr√©-IA	0.6154	0.8276	0.7073	Performance correcte dans son r√©gime d‚Äôorigine
Train pr√©-IA ‚Üí Test IA	0.5374	0.7033	0.5423	D√©gradation nette sur les donn√©es IA
Lecture :

Sur les donn√©es pr√©-IA, le mod√®le atteint :
un AUC ‚âà 0,62, ce qui indique une capacit√© de discrimination mod√©r√©e,
un F1 ‚âà 0,83 et une accuracy ‚âà 0,71, coh√©rents avec un mod√®le globalement acceptable dans son contexte d‚Äôorigine.
Lorsqu‚Äôil est appliqu√© aux donn√©es IA, la performance chute :
l‚ÄôAUC tombe √† ‚âà 0,54, √† peine au-dessus d‚Äôun mod√®le al√©atoire (AUC = 0,5),
l‚Äôaccuracy se rapproche de 0,54, et le F1 de 0,70.
Autrement dit, un mod√®le calibr√© sur l‚Äô√®re pr√©-IA est quasi incapable de g√©n√©raliser correctement aux d√©cisions prises en p√©riode IA.
Il semble apprendre un r√©gime d√©cisionnel ¬´ ancien ¬ª qui ne refl√®te plus les logiques d‚Äôapprobation post√©rieures √† l‚Äôintroduction des syst√®mes IA.

9.3.2. Mod√®le entra√Æn√© en IA
√âvaluation	AUC	F1	Accuracy	Lecture
Train IA ‚Üí Test IA	0.9107	0.8652	0.8499	Excellente performance dans l‚Äô√®re IA
Train IA ‚Üí Test pr√©-IA	0.5757	0.6493	0.5624	Performance mod√©r√©e sur l‚Äô√®re pr√©-IA
Lecture :

Sur les donn√©es IA, le mod√®le IA est tr√®s performant :
AUC ‚âà 0,91 ‚Üí forte capacit√© de discrimination entre dossiers approuv√©s/refus√©s,
F1 ‚âà 0,87, accuracy ‚âà 0,85 ‚Üí le mod√®le est calibr√© sur un r√©gime d√©cisionnel tr√®s structur√© et pr√©visible.
Lorsqu‚Äôon le projette sur l‚Äô√®re pr√©-IA, les performances se d√©gradent :
AUC ‚âà 0,58 ‚Üí meilleure que le hasard, mais clairement en dessous du niveau observ√© dans l‚Äô√®re IA,
F1 ‚âà 0,65, accuracy ‚âà 0,56.
Un mod√®le calibr√© sur l‚Äô√®re IA reste l√©g√®rement meilleur que le hasard lorsqu‚Äôon le projette en arri√®re sur la p√©riode pr√©-IA, mais il ne retrouve pas le niveau de performance atteint dans son r√©gime d‚Äôorigine.
Cela sugg√®re que les r√®gles implicites de d√©cision en IA incorporent des signaux ou des patterns qui n‚Äôexistaient pas (ou √©taient moins structur√©s) en pr√©-IA.

9.4. Asym√©trie des performances cross-era
On observe une asym√©trie marqu√©e :

Pr√©-IA ‚Üí IA : AUC ‚âà 0,54 (quasi al√©atoire).
IA ‚Üí Pr√©-IA : AUC ‚âà 0,58 (un peu meilleur, mais toujours faible).
Direction	AUC cross-era	Interpr√©tation
pr√©-IA ‚Üí IA	0.5374	Le mod√®le ¬´ ancien ¬ª ne comprend plus la logique IA
IA ‚Üí pr√©-IA	0.5757	Le mod√®le IA capte certains patterns structurels valables en pr√©-IA, mais perd en pr√©cision
Cette asym√©trie est coh√©rente avec l‚Äôid√©e que :

L‚Äô√®re IA a introduit un r√©gime d√©cisionnel plus sophistiqu√©, avec :
des interactions plus complexes entre covariables,
une exploitation plus fine des signaux,
possiblement de nouveaux standards de risque/approbation.
Les mod√®les pr√©-IA sont trop simples ou trop rigides par rapport √† ce nouveau r√©gime, et g√©n√©raliser de l‚Äô¬´ ancien monde ¬ª vers le ¬´ nouveau monde ¬ª est beaucoup plus difficile que l‚Äôinverse.
9.5. Implications pour la th√®se : robustesse intertemporelle et changement de r√©gime
9.5.1. Non-stationnarit√© et changement de r√©gime
Les r√©sultats de Tableau 7.1 fournissent une √©vidence empirique forte de non-stationnarit√© :

Le mod√®le pr√©-IA ne ¬´ fonctionne ¬ª pas sur les donn√©es IA.
Le mod√®le IA se d√©grade d√®s qu‚Äôon le projette en pr√©-IA.
Les distributions jointes ( (X, y) ) avant et apr√®s 2018‚Äì2020 ne semblent pas suivre le m√™me processus g√©n√©rateur.
En termes de scoring, cela signifie que le passage √† des syst√®mes IA ne correspond pas √† une simple am√©lioration ¬´ continue ¬ª d‚Äôun mod√®le de scoring existant, mais √† un changement de r√©gime dans la fa√ßon dont le risque est √©valu√© et les d√©cisions sont prises.

9.5.2. Lien avec la robustesse intertemporelle
Pour la Section 6.X (¬´ Robustesse intertemporelle des mod√®les de scoring ¬ª), tu peux formuler :

L‚Äôexercice cross-era met en √©vidence une robustesse intertemporelle limit√©e des mod√®les de scoring.
Les RandomForest estim√©s sur la p√©riode pr√©-IA perdent presque toute leur capacit√© de discrimination lorsqu‚Äôils sont projet√©s sur des d√©cisions prises en p√©riode IA (AUC ‚âà 0,54).
Inversement, les mod√®les calibr√©s en p√©riode IA pr√©sentent une excellente performance dans leur √®re d‚Äôorigine (AUC ‚âà 0,91), mais ne g√©n√©ralisent qu‚Äôimparfaitement √† la p√©riode pr√©-IA (AUC ‚âà 0,58).
Ces r√©sultats sugg√®rent que la transition vers des syst√®mes de scoring IA s‚Äôaccompagne d‚Äôun changement profond des crit√®res de d√©cision plut√¥t que d‚Äôun simple raffinement marginal des mod√®les historiques.

9.6. Conclusion synth√©tique pour le chapitre
En r√©sum√© :

Intra-era, les mod√®les sont performants (surtout en IA).
Cross-era, la performance chute, en particulier dans le sens pr√©-IA ‚Üí IA.
Cette instabilit√© temporelle plaide pour :
une mise √† jour r√©guli√®re des mod√®les de scoring,
une vigilance accrue sur la non-stationnarit√© des donn√©es,
et une interpr√©tation prudente des comparaisons intertemporelles de performance.
Tu peux donc conclure ta Section 9 en soulignant que la robustesse intertemporelle est limit√©e, ce qui renforce l‚Äôid√©e d‚Äôun basculement de paradigme entre l‚Äô√®re des mod√®les traditionnels et l‚Äô√®re IA en mati√®re de d√©cision de cr√©dit.d

# %% [markdown]
# # 10. Fairness metrics avanc√©es ‚Äì Disparate Impact, Equal Opportunity, Predictive Parity
#
# üîó R√©f√©rence th√®se :
# - Section 6.X : "Fairness m√©trique et dilemmes r√©gulatoires"
# - Tableaux 6.3‚Äì6.4 : indicateurs de fairness normalis√©s par groupe

# On suppose que :
# - y_test, y_pred_rf, y_pred_proba_rf existent (section 7)
# - race_test = ai_acs.loc[y_test.index, "derived_race"] a d√©j√† √©t√© calcul√©

if "race_test" not in globals():
    if "derived_race" in ai_acs.columns:
        race_test = ai_acs.loc[y_test.index, "derived_race"]
    else:
        raise ValueError("Impossible de retrouver 'derived_race' pour les m√©triques de fairness avanc√©es.")

def group_confusion_stats(y_true, y_pred, mask):
    """Retourne TP, FP, TN, FN pour un groupe, ou None si trop peu de donn√©es."""
    n = mask.sum()
    if n < 50:
        return None
    cm = confusion_matrix(y_true[mask], y_pred[mask])
    if cm.shape != (2, 2):
        return None
    tn, fp, fn, tp = cm.ravel()
    return tn, fp, fn, tp

# 10.1. Calcul des m√©triques par groupe racial

group_metrics = []

for grp in race_test.dropna().unique():
    mask = (race_test == grp)
    stats = group_confusion_stats(y_test, y_pred_rf, mask)
    if stats is None:
        group_metrics.append((grp, np.nan, np.nan, np.nan, np.nan, np.nan))
        continue

    tn, fp, fn, tp = stats

    # Taux de pr√©diction positive (PP) pour disparate impact
    pp_rate = (tp + fp) / (tn + fp + fn + tp)

    # TPR (sensibilit√©)
    tpr = tp / (tp + fn) if (tp + fn) > 0 else np.nan

    # PPV (precision)
    ppv = tp / (tp + fp) if (tp + fp) > 0 else np.nan

    group_metrics.append((grp, pp_rate, tpr, ppv, tn, fp + fn))

fair_adv_df = pd.DataFrame(
    group_metrics,
    columns=["Race", "PP_rate", "TPR", "PPV", "TN", "Errors"]
)

# 10.2. Normalisation par rapport au groupe de r√©f√©rence (White)

ref_grp = "White"
if ref_grp not in list(fair_adv_df["Race"]):
    print("‚ö†Ô∏è Groupe de r√©f√©rence 'White' absent ‚Äì impossible de construire les ratios DI/EO/PPV.")
else:
    ref_row = fair_adv_df[fair_adv_df["Race"] == ref_grp].iloc[0]

    di_list = []
    for _, row in fair_adv_df.iterrows():
        di = row["PP_rate"] / ref_row["PP_rate"] if ref_row["PP_rate"] > 0 else np.nan
        eo_diff = row["TPR"] - ref_row["TPR"] if pd.notna(row["TPR"]) else np.nan
        ppv_diff = row["PPV"] - ref_row["PPV"] if pd.notna(row["PPV"]) else np.nan

        di_list.append((row["Race"], row["PP_rate"], di, row["TPR"], eo_diff, row["PPV"], ppv_diff))

    fairness_advanced = pd.DataFrame(
        di_list,
        columns=[
            "Race",
            "PP_rate",
            "DisparateImpact_vs_White",
            "TPR",
            "EqualOpportunityDiff_vs_White",
            "PPV",
            "PredictiveParityDiff_vs_White"
        ]
    )

    print("\n=== Tableau 6.3 ‚Äì Fairness avanc√©e RF par race (r√©f = White) ===")
    display(fairness_advanced)

    fair_adv_path = os.path.join(out_dir, "table_6_3_fairness_advanced_rf_by_race.csv")
    fairness_advanced.to_csv(fair_adv_path, index=False)
    print("Tableau 6.3 sauvegard√© dans :", fair_adv_path)
=== Tableau 6.3 ‚Äì Fairness avanc√©e RF par race (r√©f = White) ===
Race	PP_rate	DisparateImpact_vs_White	TPR	EqualOpportunityDiff_vs_White	PPV	PredictiveParityDiff_vs_White
0	Race Not Available	0.537880	0.925550	0.626703	-0.003118	0.471851	-0.166579
1	White	0.581147	1.000000	0.629820	0.000000	0.638430	0.000000
2	Asian	0.598139	1.029239	0.652478	0.022658	0.627418	-0.011012
3	Black or African American	0.449773	0.773940	0.517882	-0.111938	0.563421	-0.075009
4	Native Hawaiian or Other Pacific Islander	0.483271	0.831583	0.521008	-0.108812	0.476923	-0.161507
5	Free Form Text Only	0.238806	0.410922	0.200000	-0.429820	0.187500	-0.450930
6	Joint	0.597586	1.028288	0.633059	0.003239	0.642758	0.004328
7	American Indian or Alaska Native	0.517564	0.890592	0.636364	0.006543	0.601810	-0.036620
8	2 or more minority races	0.463415	0.797414	0.604938	-0.024882	0.515789	-0.122640
Tableau 6.3 sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_6_3_fairness_advanced_rf_by_race.csv
10. Fairness m√©trique avanc√©e ‚Äì Disparate Impact, Equal Opportunity, Predictive Parity
10.1. Rappel du cadre et des m√©triques
Dans cette section, on √©value la fairness du RandomForest IA par groupe racial, en suivant trois grandes familles d‚Äôindicateurs :

Disparate Impact (DI) : ratio des taux de pr√©diction positive (PP_rate) d‚Äôun groupe minoritaire par rapport au groupe de r√©f√©rence (ici White).
[ DI(g) = \frac{\Pr(\hat{Y} = 1 \mid G = g)}{\Pr(\hat{Y} = 1 \mid G = \text{White})} ]
En pratique, on regarde si le DI est proche de 1 (parit√©) ou au contraire < 0,8 (zone classiquement consid√©r√©e comme probl√©matique dans la litt√©rature).

Equal Opportunity (EO) : diff√©rence de taux de vrais positifs (TPR) par rapport aux Whites.
[ EO_diff(g) = TPR(g) - TPR(\text{White}) ]
Un EO_diff n√©gatif indique que, √† risque r√©el d‚Äôapprobation √©quivalent (Y=1), le mod√®le approuve moins souvent le groupe ( g ) que les Whites.

Predictive Parity (PP) : diff√©rence de pr√©cision conditionnelle (PPV) par rapport aux Whites.
[ PPV_diff(g) = PPV(g) - PPV(\text{White}) ]
Un PPV plus faible signifie que, parmi les dossiers pr√©dits comme approuv√©s ((\hat{Y} = 1)), la proportion de vrais positifs est plus basse dans le groupe ( g ), ce qui peut refl√©ter une calibration diff√©rente.

Les m√©triques sont calcul√©es √† partir de la matrice de confusion du mod√®le pour chaque groupe racial, √† condition de disposer d‚Äôau moins 50 observations par groupe.

10.2. R√©sultats ‚Äì Tableau 6.3 (RandomForest IA, r√©f. = White)
Tableau 6.3 ‚Äì Fairness avanc√©e RF par race (r√©f√©rence = White)
Race	PP_rate	DI vs White	TPR	EO diff vs White	PPV	PPV diff vs White
Race Not Available	0.5379	0.9256	0.6267	-0.0031	0.4719	-0.1666
White	0.5811	1.0000	0.6298	0.0000	0.6384	0.0000
Asian	0.5981	1.0292	0.6525	+0.0227	0.6274	-0.0110
Black or African American	0.4498	0.7739	0.5179	-0.1119	0.5634	-0.0750
Native Hawaiian or Other Pacific Islander	0.4833	0.8316	0.5210	-0.1088	0.4769	-0.1615
Free Form Text Only	0.2388	0.4109	0.2000	-0.4298	0.1875	-0.4509
Joint	0.5976	1.0283	0.6331	+0.0032	0.6428	+0.0043
American Indian or Alaska Native	0.5176	0.8906	0.6364	+0.0065	0.6018	-0.0366
2 or more minority races	0.4634	0.7974	0.6049	-0.0249	0.5158	-0.1226
Note m√©thodologique : certains groupes (par ex. Free Form Text Only, 2 or more minority races) peuvent avoir des effectifs faibles, ce qui rend leurs m√©triques plus instables. Les conclusions doivent donc √™tre nuanc√©es pour ces cat√©gories.

10.3. Disparate Impact ‚Äì Taux de pr√©diction positive par race
Le Disparate Impact compare, pour chaque race, la fr√©quence des d√©cisions positives ((\hat{Y} = 1)) √† celle du groupe de r√©f√©rence (White).

10.3.1. Lecture du DI
Race	PP_rate	DI vs White	Interpr√©tation synth√©tique
White	0.5811	1.0000	R√©f√©rence (100 %)
Asian	0.5981	1.0292	L√©g√®rement plus de pr√©dictions positives que les Whites
Joint	0.5976	1.0283	Niveau proche ou l√©g√®rement sup√©rieur aux Whites
American Indian or Alaska Native	0.5176	0.8906	L√©ger d√©ficit de PP vs Whites
Race Not Available	0.5379	0.9256	Proche, mais un peu en-dessous des Whites
Native Hawaiian or Other Pacific Islander	0.4833	0.8316	DI r√©duit, mais encore juste au-dessus du seuil 0,8
2 or more minority races	0.4634	0.7974	DI < 0,8
Black or African American	0.4498	0.7739	DI < 0,8
Free Form Text Only	0.2388	0.4109	DI tr√®s faible, interpr√©tation d√©licate (eff. faible)
10.3.2. Interpr√©tation pour la th√®se
Le Disparate Impact est globalement proche de 1 pour :
les Asians, les profils Joint et dans une moindre mesure American Indian or Alaska Native, ce qui indique des taux de pr√©diction positive comparables ou l√©g√®rement sup√©rieurs aux Whites.
Pour les groupes noirs et certains groupes combin√©s :
Black or African American : DI ‚âà 0,77
2 or more minority races : DI ‚âà 0,80 (juste en-dessous du seuil 0,8)
Native Hawaiian or Other Pacific Islander : DI ‚âà 0,83 (limite basse mais > 0,8)
Les Black borrowers pr√©sentent un taux de pr√©diction positive nettement inf√©rieur √† celui des Whites (DI ‚âà 0,77), ce qui, dans la litt√©rature sur la discrimination indirecte, est souvent consid√©r√© comme un signal potentiellement probl√©matique (r√®gle des 80 %, ou four-fifths rule).
Pour les groupes √† effectifs r√©duits (par ex. Free Form Text Only), le DI tr√®s faible doit √™tre interpr√©t√© avec prudence : il s‚Äôagit davantage d‚Äôun signal exploratoire que d‚Äôune preuve statistique robuste.

10.4. Equal Opportunity ‚Äì Taux de vrais positifs (TPR)
L‚ÄôEqual Opportunity se concentre sur la probabilit√© d‚Äôapprouver un dossier r√©ellement approuvable (Y=1). On compare ici le TPR des groupes minoritaires √† celui des Whites.

10.4.1. Comparaison des TPR
Race	TPR	EO diff vs White	Lecture
White	0.6298	0.0000	R√©f√©rence
Asian	0.6525	+0.0227	L√©g√®re sur-approbation par rapport aux Whites, √† risque r√©el comparable
Joint	0.6331	+0.0032	Tr√®s proche des Whites
American Indian or Alaska Native	0.6364	+0.0065	L√©g√®re meilleure EO que les Whites
2 or more minority races	0.6049	-0.0249	L√©g√®re sous-approbation
Race Not Available	0.6267	-0.0031	Pratiquement identique aux Whites
Native Hawaiian or Other Pacific Islander	0.5210	-0.1088	TPR nettement plus faible
Black or African American	0.5179	-0.1119	TPR significativement plus faible
Free Form Text Only	0.2000	-0.4298	TPR tr√®s faible (mais effectif tr√®s limit√©)
10.4.2. Interpr√©tation pour la th√®se
Les groupes Asian, Joint et American Indian or Alaska Native ont des TPR l√©g√®rement sup√©rieurs √† ceux des Whites, ce qui sugg√®re qu‚Äô√† risque r√©el d‚Äôapprobation √©quivalent, ils ne sont pas p√©nalis√©s par le mod√®le IA.
Les groupes Black or African American et Native Hawaiian or Other Pacific Islander pr√©sentent un d√©ficit de TPR d‚Äôenviron 11 points de pourcentage (EO_diff ‚âà -0,11) :
Cela signifie que, parmi les dossiers qui auraient d√ª √™tre approuv√©s (Y=1) selon le label, le mod√®le IA √©choue plus souvent √† les approuver dans les groupes Black et NHOPI que dans le groupe White.
D‚Äôun point de vue Equal Opportunity, le mod√®le ne garantit donc pas un acc√®s √©quitable √† l‚Äôapprobation conditionnellement au m√©rite (Y=1).

10.5. Predictive Parity ‚Äì Pr√©cision conditionnelle (PPV)
La Predictive Parity se penche sur la fiabilit√© des pr√©dictions positives du mod√®le ((\hat{Y}=1)) dans chaque groupe racial : parmi ceux que le mod√®le pr√©dit comme approuv√©s, quelle proportion est effectivement approuv√©e en v√©rit√© ?

10.5.1. Comparaison des PPV
Race	PPV	PPV diff vs White	Lecture
White	0.6384	0.0000	R√©f√©rence
Joint	0.6428	+0.0043	L√©g√®rement mieux calibr√© que les Whites
Asian	0.6274	-0.0110	Tr√®s proche des Whites
American Indian or Alaska Native	0.6018	-0.0366	PPV mod√©r√©ment plus faible
Black or African American	0.5634	-0.0750	PPV nettement plus faible
2 or more minority races	0.5158	-0.1226	PPV sensiblement plus faible
Native Hawaiian or Other Pacific Islander	0.4769	-0.1615	PPV tr√®s inf√©rieur aux Whites
Race Not Available	0.4719	-0.1666	Qualit√© pr√©dictive faible dans ce groupe
Free Form Text Only	0.1875	-0.4509	PPV extr√™mement faible (mais effectif limit√©)
10.5.2. Interpr√©tation pour la th√®se
Pour les Asians et les profils Joint, le PPV est tr√®s proche (voire l√©g√®rement sup√©rieur) √† celui des Whites, ce qui sugg√®re une calibration comparable.
En revanche, pour les groupes Black, NHOPI et 2 or more minority races, le PPV est nettement inf√©rieur, avec des √©carts allant de -7,5 points (Black) √† -16 points (NHOPI).
Concr√®tement, cela signifie que quand le mod√®le IA pr√©dit ¬´ approbation ¬ª pour un dossier Black ou NHOPI, cette pr√©diction est moins souvent correcte que pour un dossier White.
Le mod√®le semble donc moins bien calibr√© pour certains groupes minoritaires, ce qui peut renforcer un sentiment d‚Äôinjustice per√ßue : √† pr√©diction positive √©gale, les groupes minoritaires supportent une plus grande part d‚Äôerreurs.

10.6. Synth√®se pour les Tableaux 6.3‚Äì6.4 et la discussion de fairness
On peut r√©sumer les principaux enseignements ainsi :

Disparate Impact :

Les groupes Black et 2 or more minority races sont en zone de vigilance (DI < 0,8) par rapport aux Whites.
Les groupes Asian et Joint b√©n√©ficient de niveaux de PP_rate proches ou sup√©rieurs √† ceux des Whites.
Equal Opportunity :

Les TPR sont sensiblement plus faibles pour les groupes Black et NHOPI (‚âà -11 points de pourcentage), ce qui sugg√®re un d√©ficit d‚Äôacc√®s √©quitable √† l‚Äôapprobation pour des dossiers pourtant ¬´ m√©ritants ¬ª.
Predictive Parity :

Le mod√®le est moins fiable dans ses pr√©dictions positives pour plusieurs groupes minoritaires (PPV plus faible), notamment Black, NHOPI et 2 or more minority races.
Au total, ces m√©triques illustrent bien les dilemmes r√©gulatoires √©voqu√©s en Section 6.X :
un m√™me mod√®le IA peut sembler performant globalement, tout en produisant des profils de fairness h√©t√©rog√®nes selon les groupes raciaux.
Les r√©sultats sugg√®rent notamment que les emprunteurs Black et certains groupes minoritaires combin√©s subissent √† la fois un Disparate Impact (moins de pr√©dictions positives) et une Equal Opportunity r√©duite (TPR plus faible), dans un contexte o√π leur Predictive Parity est √©galement inf√©rieure √† celle des Whites.

Ces constats nourrissent la discussion sur :

la n√©cessit√© de contraintes explicites de fairness (par ex. plafonner les √©carts de TPR ou de DI),
et les tensions possibles entre performance globale et √©quit√© intergroupe dans les syst√®mes de scoring IA.


# %% [markdown]
# # 11. Sous-groupes ‚Äì revenu, genre, type d‚Äôinstitution
#
# üîó R√©f√©rence th√®se :
# - Section 4.X : "H√©t√©rog√©n√©it√© des effets selon revenus, genre, type d‚Äôinstitution"
# - Tableau 4.X : taux d‚Äôapprobation et m√©triques par sous-groupes

# 11.1. Stratification par revenu (ACS median income)

acs_income = ai_acs.copy()
if "acs_median_income" in acs_income.columns:
    s_inc = pd.to_numeric(acs_income["acs_median_income"], errors="coerce")
    q1, q2 = s_inc.quantile([0.33, 0.66])

    def income_bucket(v):
        if pd.isna(v):
            return np.nan
        if v <= q1:
            return "Low"
        elif v <= q2:
            return "Middle"
        else:
            return "High"

    acs_income["income_group"] = s_inc.apply(income_bucket)

    income_approval = (
        acs_income
        .groupby("income_group")["approved"]
        .mean()
        .reset_index()
        .rename(columns={"approved": "approval_rate"})
    )

    print("\n=== Tableau 4.X ‚Äì Taux d‚Äôapprobation par tertile de revenu (ACS) ===")
    display(income_approval)

    income_path = os.path.join(out_dir, "table_4X_approval_by_income_group.csv")
    income_approval.to_csv(income_path, index=False)
    print("Tableau 4.X sauvegard√© dans :", income_path)
else:
    print("‚ö†Ô∏è 'acs_median_income' absent ‚Äì impossible de construire les groupes de revenu.")

# 11.2. Stratification par genre (applicant_sex) ‚Äì cohorte IA

if "applicant_sex" in ai_acs.columns:
    sex_approval = (
        ai_acs
        .groupby("applicant_sex")["approved"]
        .mean()
        .reset_index()
        .rename(columns={"approved": "approval_rate"})
    )

    print("\n=== Tableau 4.Y ‚Äì Taux d‚Äôapprobation par genre (IA, HMDA+ACS) ===")
    display(sex_approval)

    sex_path = os.path.join(out_dir, "table_4Y_approval_by_sex_ia_acs.csv")
    sex_approval.to_csv(sex_path, index=False)
    print("Tableau 4.Y sauvegard√© dans :", sex_path)
else:
    print("‚ö†Ô∏è 'applicant_sex' absent dans ai_acs.")

# 11.3. Stratification par type d‚Äôinstitution (si colonne disponible)

inst_cols = ["purchaser_type", "lender", "agency_code"]
inst_col = None
for c in inst_cols:
    for df in [core, model, hmda_acs]:
        if c in df.columns:
            inst_col = c
            break
    if inst_col is not None:
        break

if inst_col is not None:
    print("\nColonne de type d‚Äôinstitution d√©tect√©e :", inst_col)

    inst_pre = pre_ai.copy()
    inst_ia  = ai_hmda.copy()

    inst_pre["era"] = "pre_IA"
    inst_ia["era"]  = "IA"

    inst_df = pd.concat([inst_pre, inst_ia], axis=0)

    inst_approval = (
        inst_df
        .groupby(["era", inst_col])["approved"]
        .mean()
        .reset_index()
        .rename(columns={"approved": "approval_rate"})
    )

    print("\n=== Tableau 4.Z ‚Äì Taux d‚Äôapprobation par type d‚Äôinstitution et par √®re ===")
    display(inst_approval)

    inst_path = os.path.join(out_dir, "table_4Z_approval_by_institution_and_era.csv")
    inst_approval.to_csv(inst_path, index=False)
    print("Tableau 4.Z sauvegard√© dans :", inst_path)
else:
    print("‚ö†Ô∏è Aucun proxy de type d‚Äôinstitution trouv√© ('purchaser_type', 'lender', 'agency_code').")

=== Tableau 4.X ‚Äì Taux d‚Äôapprobation par tertile de revenu (ACS) ===
income_group	approval_rate
0	High	0.570902
1	Low	0.507862
2	Middle	0.539812
Tableau 4.X sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_4X_approval_by_income_group.csv

=== Tableau 4.Y ‚Äì Taux d‚Äôapprobation par genre (IA, HMDA+ACS) ===
applicant_sex	approval_rate
0	1	0.574521
1	2	0.578896
2	3	0.581055
3	4	0.152527
4	6	0.543396
Tableau 4.Y sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_4Y_approval_by_sex_ia_acs.csv

Colonne de type d‚Äôinstitution d√©tect√©e : purchaser_type

=== Tableau 4.Z ‚Äì Taux d‚Äôapprobation par type d‚Äôinstitution et par √®re ===
era	purchaser_type	approval_rate
0	pre_IA	0.0	0.693824
1	pre_IA	1.0	0.702013
2	pre_IA	2.0	0.469062
3	pre_IA	3.0	0.721921
4	pre_IA	4.0	0.996815
5	pre_IA	5.0	0.669208
6	pre_IA	6.0	0.921204
7	pre_IA	7.0	0.924665
8	pre_IA	8.0	0.668331
9	pre_IA	9.0	0.970216
Tableau 4.Z sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_4Z_approval_by_institution_and_era.csv
11. Sous-groupes ‚Äì revenu, genre, type d‚Äôinstitution
11.1. Tertiles de revenu (ACS median income)
11.1.1. R√©sultats ‚Äì Tableau 4.X
Les demandes IA (HMDA+ACS) ont √©t√© d√©coup√©es en trois tertiles de revenu de zone √† partir de acs_median_income :

Low : tiers inf√©rieur de revenu m√©dian ACS,
Middle : tiers interm√©diaire,
High : tiers sup√©rieur.
Le taux d‚Äôapprobation moyen par groupe est :

income_group	approval_rate
High	0.5709
Low	0.5079
Middle	0.5398
Tableau 4.X ‚Äì Taux d‚Äôapprobation par tertile de revenu (ACS)

11.1.2. Lecture
On observe un gradient monotone :

Les zones Low income affichent un taux d‚Äôapprobation moyen d‚Äôenviron 50,8 %.
Les zones Middle income montent √† environ 53,9 %.
Les zones High income culminent √† environ 57,1 %.
Autrement dit, √† structure de donn√©es constante, les dossiers issus de zones √† revenu m√©dian plus √©lev√© ont plus de chances d‚Äô√™tre approuv√©s que ceux provenant de zones d√©favoris√©es.

11.1.3. Interpr√©tation pour la th√®se
Ces r√©sultats sugg√®rent l‚Äôexistence d‚Äôun gradient socio-√©conomique marqu√© dans les taux d‚Äôapprobation IA : les demandeurs issus de zones √† revenu m√©dian √©lev√© b√©n√©ficient d‚Äôun taux d‚Äôacceptation sup√©rieur d‚Äôenviron 6 √† 7 points de pourcentage par rapport aux zones les plus pauvres.
Cette h√©t√©rog√©n√©it√© est coh√©rente avec une logique de scoring dans laquelle le contexte de revenu de zone (captur√© via ACS) est explicitement ou implicitement int√©gr√© comme proxy de risque de cr√©dit. Elle pose toutefois la question d‚Äôun √©ventuel renforcement des in√©galit√©s territoriales via les mod√®les IA.

11.2. Genre (applicant_sex) ‚Äì cohorte IA (HMDA+ACS)
11.2.1. R√©sultats ‚Äì Tableau 4.Y
Le taux d‚Äôapprobation est calcul√© par modalit√© de applicant_sex dans la cohorte IA :

applicant_sex	approval_rate
1	0.5745
2	0.5789
3	0.5811
4	0.1525
6	0.5434
Tableau 4.Y ‚Äì Taux d‚Äôapprobation par genre (IA, HMDA+ACS)

(Les codes 1, 2, 3, 4, 6 suivent la codification HMDA : sexe d√©clar√©, conjoint, non disponible, non fourni, etc. La th√®se pourra expliciter ce mapping dans une note ou annexe.)

11.2.2. Lecture
Pour les cat√©gories majoritaires (1, 2, 3, 6) :

Les taux d‚Äôapprobation sont relativement proches :
entre 54 % et 58 %,
avec de faibles √©carts entre les codes 1, 2 et 3 (tous autour de 0,57‚Äì0,58).
La seule exception notable est la cat√©gorie 4 (applicant_sex = 4), avec un taux d‚Äôapprobation de 15,3 %, tr√®s inf√©rieur aux autres.

11.2.3. Interpr√©tation prudente
Le bloc principal des cat√©gories (1‚Äì3, 6) sugg√®re une relative neutralit√© de genre : il n‚Äôy a pas de diff√©rence massive d‚Äôapprobation entre les grandes cat√©gories de sexe d√©clar√©es.
La cat√©gorie 4 est un cas particulier :
Taux d‚Äôapprobation extr√™mement bas (‚âà 15 %),
Elle correspond g√©n√©ralement √† des cas de donn√©es manquantes ou non disponibles dans la codification HMDA.
Il est probable que la cat√©gorie 4 ne refl√®te pas un ¬´ genre ¬ª au sens traditionnel, mais plut√¥t une situation de donn√©e non renseign√©e, voire d‚Äôenregistrements atypiques.
Dans la r√©daction de la th√®se, il sera important de ne pas sur-interpr√©ter ce chiffre comme un biais de genre au sens strict, mais de le traiter comme un indicateur de qualit√© de donn√©e ou de strat√©gie sp√©cifique du mod√®le sur les dossiers incomplets.

Conclusion pour la section genre :

Hors cas de donn√©es manquantes (code 4), les taux d‚Äôapprobation IA sont tr√®s proches entre sexes d√©clar√©s, ce qui plaide pour une absence de biais massif directement imputable au genre d√©clar√© dans les donn√©es HMDA. La principale source de variation semble davantage li√©e √† la compl√©tude de l‚Äôinformation qu‚Äôau sexe en tant que tel.

11.3. Type d‚Äôinstitution (purchaser_type) et √®re
11.3.1. R√©sultats ‚Äì Tableau 4.Z
Une variable proxy de type d‚Äôinstitution a √©t√© d√©tect√©e : purchaser_type.
Pour l‚Äôinstant, les taux d‚Äôapprobation disponibles concernent la cohorte pr√©-IA :

era	purchaser_type	approval_rate
pre_IA	0.0	0.6938
pre_IA	1.0	0.7020
pre_IA	2.0	0.4691
pre_IA	3.0	0.7219
pre_IA	4.0	0.9968
pre_IA	5.0	0.6692
pre_IA	6.0	0.9212
pre_IA	7.0	0.9247
pre_IA	8.0	0.6683
pre_IA	9.0	0.9702
Tableau 4.Z ‚Äì Taux d‚Äôapprobation par type d‚Äôinstitution et par √®re (pr√©-IA)

(Les codes purchaser_type correspondent aux cat√©gories HMDA : pr√™ts conserv√©s, vendus √† Fannie/Freddie/Ginnie, autres acheteurs, etc.)

11.3.2. Lecture
M√™me dans la seule √®re pr√©-IA, la dispersion des taux d‚Äôapprobation par type d‚Äôinstitution est tr√®s marqu√©e :

Certains types d‚Äôinstitution pr√©sentent des taux d‚Äôapprobation exceptionnellement √©lev√©s :
purchaser_type = 4.0 : ‚âà 99,7 %,
purchaser_type = 9.0 : ‚âà 97,0 %,
purchaser_type = 6.0/7.0 : ‚âà 92 %.
D‚Äôautres types ont des niveaux interm√©diaires autour de 67‚Äì72 % (0.0, 1.0, 3.0, 5.0, 8.0).
Le type 2.0 se distingue par un taux d‚Äôapprobation nettement plus faible (‚âà 46,9 %).
11.3.3. Interpr√©tation pour la th√®se
Ces r√©sultats indiquent une forte h√©t√©rog√©n√©it√© des taux d‚Äôapprobation selon le type d‚Äôinstitution ou de canal de portage du pr√™t.
Certaines cat√©gories (par ex. purchaser_type = 4, 6, 7, 9) semblent concentrer des portefeuilles quasiment enti√®rement approuv√©s, ce qui sugg√®re des strat√©gies sp√©cifiques (segmentation tr√®s forte, pr√©-filtrage en amont, ou structures de produits quasi syst√©matiquement accept√©s).
√Ä l‚Äôinverse, d‚Äôautres types, notamment purchaser_type = 2, apparaissent plus s√©lectifs.

Pour l‚Äôinstant, le tableau 4.Z ne contient que des observations pr√©-IA. Dans la suite de l‚Äôanalyse, il pourra √™tre utile :

soit de compl√©ter ce tableau avec les taux d‚Äôapprobation IA par type d‚Äôinstitution,
soit d‚Äôinsister sur le fait que cette h√©t√©rog√©n√©it√© pr√©-existe √† l‚Äô√®re IA et constitue un √©l√©ment de contexte : le syst√®me d‚Äôoctroi √©tait d√©j√† structur√© par des diff√©rences institutionnelles fortes avant l‚Äôintroduction des mod√®les IA.
11.4. Synth√®se ‚Äì H√©t√©rog√©n√©it√© socio-√©conomique, de genre, et institutionnelle
Les trois axes de cette section r√©v√®lent une h√©t√©rog√©n√©it√© marqu√©e :

Revenu de zone (ACS) :

Les zones √† revenu √©lev√© voient des taux d‚Äôapprobation sup√©rieurs √† ceux des zones pauvres (‚âà +6‚Äì7 points).
Cette dimension renforce l‚Äôid√©e d‚Äôun risk-based pricing s‚Äôappuyant sur des proxies territoriaux de risque.
Genre (applicant_sex) :

Pour les cat√©gories d√©clar√©es principales (codes 1, 2, 3, 6), les √©carts de taux d‚Äôapprobation sont limit√©s, ce qui ne sugg√®re pas de biais massif directement imputable au genre.
Une cat√©gorie sp√©cifique li√©e aux donn√©es manquantes (code 4) pr√©sente un taux anormalement bas (‚âà 15 %), illustrant le r√¥le central de la compl√©tude de l‚Äôinformation.
Type d‚Äôinstitution (purchaser_type) :

D√®s la p√©riode pr√©-IA, certains types d‚Äôinstitutions affichent des taux d‚Äôapprobation quasi syst√©matiques (> 90 %), d‚Äôautres restant autour de 47‚Äì70 %.
Cela montre que l‚Äôarchitecture institutionnelle du march√© du cr√©dit est intrins√®quement segment√©e, ind√©pendamment de l‚Äôintroduction des mod√®les IA.
Ensemble, ces r√©sultats alimentent la discussion de la Section 4.X sur l‚Äôh√©t√©rog√©n√©it√© des effets : ils montrent que la probabilit√© d‚Äôapprobation n‚Äôest pas seulement une fonction de la solvabilit√© individuelle, mais d√©pend fortement du contexte socio-√©conomique, du statut de l‚Äôinformation (genre d√©clar√© / non d√©clar√©) et du type d‚Äôinstitution impliqu√© dans le pr√™t.


################################################

# %% [markdown]
# # 4. Descriptive statistics ‚Äì Applicant, Loan, Approval (pr√©-IA vs IA)
#
# üîó R√©f√©rence th√®se :
# - Section 4.1‚Äì4.3 : "Applicant demographics", "Loan characteristics", "Approval outcomes"
# - Tables descriptives par √®re (pr√©-IA vs IA)
#
# Objectif :
# - Construire des tableaux de stats descriptives par √®re pour :
#   1) la composition raciale (si disponible),
#   2) les caract√©ristiques de pr√™ts (montant),
#   3) les taux d'approbation / refus.
#
# Hypoth√®ses :
# - pre_ai : HMDA pr√©-IA (2007‚Äì2017)
# - ai_hmda : HMDA IA (2018‚Äì2023)
# - ai_acs : HMDA+ACS IA (pour race/ACS si n√©cessaire)
# - BASE_DIR / out_dir existent d√©j√† (ou seront recr√©√©s ici).


# %%
from pathlib import Path

# S√©curisation du chemin des tableaux
try:
    BASE_DIR
except NameError:
    BASE_DIR = os.getcwd()

out_dir = os.path.join(BASE_DIR, "tables")
os.makedirs(out_dir, exist_ok=True)

# 4.1. Construction d'un DataFrame descriptif combin√© pr√©-IA / IA

pre_desc = pre_ai.copy()
ai_desc  = ai_hmda.copy()

pre_desc["era"] = "pre_IA"
ai_desc["era"]  = "IA"

desc_df = pd.concat([pre_desc, ai_desc], axis=0, ignore_index=True)

# On force approved en int si possible
if "approved" in desc_df.columns:
    desc_df["approved"] = desc_df["approved"].astype(int)

print("desc_df shape :", desc_df.shape)
print("Colonnes disponibles dans desc_df :", desc_df.columns.tolist())

# -------------------------------------------------------------------
# 4.1.1 Applicant demographics ‚Äì r√©partition raciale par √®re (si possible)
# -------------------------------------------------------------------

# On essaie de r√©cup√©rer une colonne de race dans desc_df. Si absente pour pr√©-IA,
# on utilisera au moins la cohorte IA (ai_acs).

race_col_candidates = ["derived_race", "race", "applicant_race"]
race_col = None
for c in race_col_candidates:
    if c in desc_df.columns:
        race_col = c
        break

if race_col is not None:
    race_era_tab = (
        desc_df
        .dropna(subset=[race_col])
        .groupby(["era", race_col])\
        .size()\
        .reset_index(name="n")
    )
    race_era_tab["share"] = (
        race_era_tab
        .groupby("era")["n"]
        .apply(lambda x: x / x.sum())
        .values
    )

    print("\n=== Table 4.1 ‚Äì R√©partition raciale par √®re (si race disponible dans desc_df) ===")
    display(race_era_tab)

    race_path = os.path.join(out_dir, "table_4_1_race_share_by_era.csv")
    race_era_tab.to_csv(race_path, index=False)
    print("Table 4.1 sauvegard√©e dans :", race_path)

else:
    print("‚ö†Ô∏è Aucune colonne de race trouv√©e dans desc_df ‚Äì pas de Table 4.1 sur pr√©-IA.")
    # On propose, √† d√©faut, une table race uniquement sur IA via ai_acs si possible
    if "derived_race" in ai_acs.columns:
        race_ia_only = (
            ai_acs
            .dropna(subset=["derived_race"])
            .groupby("derived_race")\
            .size()\
            .reset_index(name="n")
        )
        race_ia_only["share"] = race_ia_only["n"] / race_ia_only["n"].sum()
        print("\n=== Table 4.1 (alternative) ‚Äì R√©partition raciale (IA uniquement, HMDA+ACS) ===")
        display(race_ia_only)

        race_ia_path = os.path.join(out_dir, "table_4_1_race_share_ia_only.csv")
        race_ia_only.to_csv(race_ia_path, index=False)
        print("Table 4.1 (IA only) sauvegard√©e dans :", race_ia_path)

# -------------------------------------------------------------------
# 4.1.2 Loan characteristics ‚Äì montants de pr√™ts par √®re
# -------------------------------------------------------------------

loan_amount_cols = [c for c in ["loan_amount", "loan_amount_000s", "loan_amount_clean"] if c in desc_df.columns]
if loan_amount_cols:
    loan_amount_col = loan_amount_cols[0]
    print(f"\nVariable de montant utilis√©e : {loan_amount_col}")

    loan_stats = (
        desc_df
        .groupby("era")[loan_amount_col]
        .agg(["count", "mean", "median", "std", "min", "max"])
        .reset_index()
    )

    print("\n=== Table 4.2 ‚Äì Statistiques descriptives des montants de pr√™ts par √®re ===")
    display(loan_stats)

    loan_path = os.path.join(out_dir, "table_4_2_loan_amount_stats_by_era.csv")
    loan_stats.to_csv(loan_path, index=False)
    print("Table 4.2 sauvegard√©e dans :", loan_path)
else:
    print("‚ö†Ô∏è Aucune colonne de montant de pr√™t trouv√©e dans desc_df ‚Äì Table 4.2 non g√©n√©r√©e.")

# -------------------------------------------------------------------
# 4.1.3 Approval outcomes ‚Äì taux d‚Äôapprobation / refus par √®re
# -------------------------------------------------------------------

if "approved" in desc_df.columns:
    approval_by_era = (
        desc_df
        .groupby("era")["approved"]
        .mean()
        .reset_index()
        .rename(columns={"approved": "approval_rate"})
    )

    print("\n=== Table 4.3 ‚Äì Taux d‚Äôapprobation moyen par √®re ===")
    display(approval_by_era)

    appr_path = os.path.join(out_dir, "table_4_3_approval_rate_by_era.csv")
    approval_by_era.to_csv(appr_path, index=False)
    print("Table 4.3 sauvegard√©e dans :", appr_path)

    # Si action_taken disponible, on donne une distribution plus fine
    action_cols = [c for c in ["action_taken", "action_taken_name"] if c in desc_df.columns]
    if action_cols:
        action_col = action_cols[0]
        action_tab = (
            desc_df
            .groupby(["era", action_col])
            .size()
            .reset_index(name="n")
        )
        action_tab["share"] = (
            action_tab
            .groupby("era")["n"]
            .apply(lambda x: x / x.sum())
            .values
        )

        print("\n=== Table 4.4 ‚Äì R√©partition de action_taken par √®re ===")
        display(action_tab)

        action_path = os.path.join(out_dir, "table_4_4_action_taken_by_era.csv")
        action_tab.to_csv(action_path, index=False)
        print("Table 4.4 sauvegard√©e dans :", action_path)
    else:
        print("‚ö†Ô∏è Pas de colonne 'action_taken' ‚Äì Table 4.4 non g√©n√©r√©e.")
else:
    print("‚ö†Ô∏è Colonne 'approved' absente ‚Äì impossible de construire les taux d‚Äôapprobation par √®re.")

desc_df shape : (14081220, 19)
Colonnes disponibles dans desc_df : ['action_taken', 'applicant_sex', 'county_code', 'hoepa_status', 'lien_status', 'loan_purpose', 'loan_type', 'preapproval', 'purchaser_type', 'rate_spread', 'state_code', 'year', 'approved', 'era', 'census_tract', 'geoid_tract', 'loan_amount', 'derived_ethnicity', 'derived_race']

=== Table 4.1 ‚Äì R√©partition raciale par √®re (si race disponible dans desc_df) ===
era	derived_race	n	share
0	IA	2 or more minority races	721	0.001266
1	IA	American Indian or Alaska Native	1552	0.002725
2	IA	Asian	42546	0.074708
3	IA	Black or African American	37418	0.065703
4	IA	Free Form Text Only	228	0.000400
5	IA	Joint	8620	0.015136
6	IA	Native Hawaiian or Other Pacific Islander	974	0.001710
7	IA	Race Not Available	127945	0.224662
8	IA	White	349496	0.613689
Table 4.1 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_4_1_race_share_by_era.csv

Variable de montant utilis√©e : loan_amount

=== Table 4.2 ‚Äì Statistiques descriptives des montants de pr√™ts par √®re ===
era	count	mean	median	std	min	max
0	IA	569500	351651.044776	255000.0	1.393519e+06	5000.0	611455000.0
1	pre_IA	0	NaN	NaN	NaN	NaN	NaN
Table 4.2 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_4_2_loan_amount_stats_by_era.csv

=== Table 4.3 ‚Äì Taux d‚Äôapprobation moyen par √®re ===
era	approval_rate
0	IA	0.542334
1	pre_IA	0.706809
Table 4.3 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_4_3_approval_rate_by_era.csv

=== Table 4.4 ‚Äì R√©partition de action_taken par √®re ===
era	action_taken	n	share
0	IA	1.0	308859	0.542334
1	IA	2.0	11232	0.019723
2	IA	3.0	70324	0.123484
3	IA	4.0	68694	0.120622
4	IA	5.0	25257	0.044349
5	IA	6.0	84357	0.148125
6	IA	7.0	290	0.000509
7	IA	8.0	487	0.000855
8	pre_IA	1.0	6298523	0.466153
9	pre_IA	2.0	677153	0.050116
10	pre_IA	3.0	2574527	0.190540
11	pre_IA	4.0	1302967	0.096432
12	pre_IA	5.0	497787	0.036841
13	pre_IA	6.0	2158740	0.159768
14	pre_IA	7.0	1132	0.000084
15	pre_IA	8.0	891	0.000066
Table 4.4 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_4_4_action_taken_by_era.csv
4.X Commentaires sur les descriptifs ‚Äì applicant, loans, approval (Tables 4.1‚Äì4.4)
4.X.1 R√©partition raciale dans la cohorte IA (Table 4.1)
La Table 4.1 d√©crit la composition raciale de la cohorte IA (2018‚Äì2023) √† partir de derived_race :

Groupe racial	Part dans l‚Äô√©chantillon IA
White	‚âà 61,4 %
Race Not Available	‚âà 22,5 %
Asian	‚âà 7,5 %
Black or African American	‚âà 6,6 %
Joint	‚âà 1,5 %
Native Hawaiian or Other Pacific Islander (NHOPI)	‚âà 0,17 %
American Indian or Alaska Native	‚âà 0,27 %
2 or more minority races	‚âà 0,13 %
Free Form Text Only	‚âà 0,04 %
Lecture :

La cohorte IA est majoritairement White (un peu plus de 60 %), ce qui reste coh√©rent avec la structure d√©mographique globale des dossiers HMDA sur la p√©riode r√©cente.
La proportion de dossiers avec race non renseign√©e (Race Not Available) est tr√®s √©lev√©e (‚âà 22‚Äì23 %), ce qui souligne un d√©ficit de compl√©tude et limite la granularit√© de certaines analyses fines par sous-groupes.
Les emprunteurs Black et Asian repr√©sentent respectivement environ 6,6 % et 7,5 % de l‚Äô√©chantillon IA, ce qui permettra n√©anmoins des analyses de fairness relativement stables sur ces groupes.
Les autres cat√©gories (NHOPI, American Indian, 2+ minority races, Free Form Text Only) restent num√©riquement faibles et devront √™tre interpr√©t√©es avec prudence dans les sections de fairness (risk of small-sample noise).
Dans le texte de la th√®se, on peut insister sur le fait que la mont√©e en granularit√© de HMDA post-2018 s‚Äôaccompagne encore d‚Äôun volume substantiel de donn√©es manquantes sur la race, ce qui constitue un enjeu m√©thodologique majeur pour l‚Äô√©valuation de la fairness.

4.X.2 Caract√©ristiques des montants de pr√™ts (Table 4.2)
La Table 4.2 pr√©sente les statistiques descriptives des montants de pr√™ts (loan_amount) par √®re :

√àre	n (count)	Moyenne (mean)	M√©diane	√âcart-type (std)	Min	Max
IA	569 500	‚âà 351 651	255 000	‚âà 1,39√ó10‚Å∂	5 000	611 455 000
pre-IA	0	NaN	NaN	NaN	NaN	NaN
Lecture :

Pour la cohorte IA, le montant moyen de pr√™t se situe autour de 351 k√©
 :
Cela refl√®te un march√© o√π les pr√™ts restent concentr√©s sur des montants interm√©diaires (‚âà 250‚Äì300 k√™√®√©√©
), d‚Äôo√π l‚Äô√©cart-type extr√™mement large.
Pour la cohorte pr√©-IA, aucune statistique n‚Äôest report√©e (count = 0) pour loan_amount :
Cela indique que la colonne loan_amount n‚Äôest pas disponible ou pas renseign√©e dans le jeu pre_ai dans sa forme actuelle.
Ce point devra √™tre mentionn√© dans le texte comme une limitation de comparabilit√© inter-√®re sur les montants (√©volution du sch√©ma HMDA, changements d‚Äôunit√©s ou de codage, etc.).
Pour la r√©daction, on pourra pr√©ciser que l‚Äôanalyse des montants de pr√™ts est principalement document√©e pour l‚Äô√®re IA, la p√©riode pr√©-IA √©tant moins exploitable sur cette dimension en raison d‚Äôun sch√©ma de donn√©es divergent ou incomplet.

4.X.3 Taux d‚Äôapprobation moyens par √®re (Table 4.3)
La Table 4.3 mesure le taux d‚Äôapprobation moyen (approved binaire) par √®re :

√àre	Taux d‚Äôapprobation moyen
IA	0,5423 (‚âà 54,2 %)
pre-IA	0,7068 (‚âà 70,7 %)
Lecture :

En p√©riode pr√©-IA (2007‚Äì2017), environ 70‚Äì71 % des dossiers de l‚Äô√©chantillon sont approuv√©s.
En p√©riode IA (2018‚Äì2023), le taux d‚Äôapprobation moyen tombe √† 54‚Äì55 %.
La diff√©rence brute de niveau est donc d‚Äôenviron ‚àí16 points de pourcentage, ce qui sugg√®re :
soit un durcissement g√©n√©ral du processus d‚Äôoctroi (plus de s√©lectivit√©, changement de cycle macro√©conomique),
soit un effet de recomposition de l‚Äô√©chantillon HMDA et de la d√©finition de l‚Äôindicateur approved.
Cette diff√©rence brute est ensuite r√©-analys√©e dans le cadre du PSM (Section PSM.1‚Äì3) et des mod√®les logit, afin de distinguer ce qui rel√®ve d‚Äôun effet structurel (composition diff√©rente des dossiers) de ce qui pourrait s‚Äôapparenter √† un effet sp√©cifique de l‚Äô√®re IA.

4.X.4 R√©partition fine de action_taken par √®re (Table 4.4)
La Table 4.4 d√©taille la distribution de action_taken (d√©cision HMDA) par √®re :

Pr√©-IA (2007‚Äì2017)
action_taken	Part dans pre-IA
1.0	46,6 %
2.0	5,0 %
3.0	19,1 %
4.0	9,6 %
5.0	3,7 %
6.0	16,0 %
7.0	‚âà 0,01 %
8.0	‚âà 0,01 %
IA (2018‚Äì2023)
action_taken	Part dans IA
1.0	54,2 %
2.0	2,0 %
3.0	12,3 %
4.0	12,1 %
5.0	4,4 %
6.0	14,8 %
7.0	0,05 %
8.0	0,09 %
(La signification exacte des codes 1‚Äì8 suit la nomenclature HMDA : pr√™ts origin√©s, refus√©s, retir√©s, incomplets, etc. Cette correspondance sera rappel√©e en note ou en annexe.)

Lecture :

Pour les deux √®res, les statuts 1.0 et 6.0 (origination / purchased, selon HMDA) concentrent une grande partie des dossiers.
La part de action_taken = 1.0 (typiquement pr√™ts accord√©s/origin√©s) :
passe d‚Äôenviron 46,6 % pre-IA √† 54,2 % IA,
alors que le taux d‚Äôapprobation moyen (Table 4.3) baisse de 70,7 % √† 54,2 % :
ce d√©calage indique que approved ne co√Øncide pas strictement avec une seule modalit√© action_taken (il agr√®ge potentiellement plusieurs codes ou filtrages sp√©cifiques √† l‚Äô√©chantillon).
Les cat√©gories 3.0 et 4.0 (retraits, incomplets, etc.) restent non n√©gligeables dans les deux p√©riodes (‚âà 19 % + 9,6 % pre-IA ; ‚âà 12,3 % + 12,1 % IA), ce qui souligne l‚Äôimportance de contraintes non purement ‚Äúaccept√©/refus√©‚Äù dans le pipeline d‚Äôoctroi (retraits volontaires, dossiers incomplets, etc.).
En synth√®se, la Table 4.4 montre que la structure de action_taken reste relativement stable entre les deux √®res, tout en sugg√©rant des d√©placements modestes entre les cat√©gories. Combin√©e √† la baisse du taux d‚Äôapprobation moyen, cette distribution met en √©vidence un paysage d‚Äôoctroi plus complexe que le simple binaire ‚Äúapprove/deny‚Äù, o√π la part de dossiers retir√©s ou incomplets joue un r√¥le non trivial.

4.X.5 Synth√®se pour la section descriptive du Chapter 4
La cohorte IA pr√©sente une composition raciale domin√©e par les Whites, mais avec une proportion tr√®s √©lev√©e de dossiers √† race manquante, ce qui constitue une limite m√©thodologique essentielle pour l‚Äôanalyse de fairness.
Les montants de pr√™ts ne sont pleinement observables que pour l‚Äô√®re IA, ce qui impose de traiter la comparaison inter-√®re avec prudence sur ce volet.
Les taux d‚Äôapprobation bruts diff√®rent fortement entre les deux p√©riodes (‚âà 71 % vs 54 %), motivant l‚Äôusage des approches de type PSM et logits pour d√©m√™ler effets de composition et effets potentiels de l‚Äô√®re IA.
La structure d√©taill√©e de action_taken indique que l‚Äôoctroi ne se r√©duit pas √† un simple sch√©ma binaire, mais implique des d√©cisions interm√©diaires (retraits, dossiers incomplets) qui doivent √™tre prises en compte dans l‚Äôinterpr√©tation.
Ces √©l√©ments descriptifs fournissent le socle empirique de la Section 4.1‚Äì4.3, sur lequel viennent ensuite se greffer les analyses plus avanc√©es (PSM, ML cross-era, fairness, sous-groupes).

# %% [markdown]
# # 5. Tests statistiques classiques ‚Äì t-tests et ANOVA
#
# üîó R√©f√©rence th√®se :
# - Section 4.X : "Significance tests"
# - Utilisation de t-tests & ANOVA pour comparer les taux d‚Äôapprobation
#
# Objectif :
# - t-test : comparaison des taux d‚Äôapprobation pr√©-IA vs IA
# - ANOVA : differences de taux d‚Äôapprobation par race et par groupe de revenu
#
# Hypoth√®ses :
# - pre_ai, ai_hmda, ai_acs existent
# - 'approved' est une variable binaire (0/1)
# - 'derived_race' existe dans ai_acs
# - 'acs_median_income' existe dans ai_acs pour d√©finir income_group


# %%
from scipy import stats
import statsmodels.api as sm
import statsmodels.formula.api as smf

# 5.1. t-test sur les taux d‚Äôapprobation pr√©-IA vs IA

if "approved" in pre_ai.columns and "approved" in ai_hmda.columns:
    pre_approved = pre_ai["approved"].astype(float)
    ia_approved  = ai_hmda["approved"].astype(float)

    print("\n=== Test 5.1 ‚Äì t-test de Student sur les taux d‚Äôapprobation (pr√©-IA vs IA) ===")
    print(f"Pr√©-IA : mean = {pre_approved.mean():.3f}, n = {len(pre_approved):,}")
    print(f"IA     : mean = {ia_approved.mean():.3f}, n = {len(ia_approved):,}")

    t_stat, p_val = stats.ttest_ind(pre_approved, ia_approved, equal_var=False)
    print(f"\nStatistique t (Welch) = {t_stat:.3f}, p-value = {p_val:.3e}")
else:
    print("‚ö†Ô∏è Colonne 'approved' manquante dans pre_ai ou ai_hmda ‚Äì t-test non calcul√©.")

# 5.2. ANOVA : approbation ~ race (IA, HMDA+ACS)

if "approved" in ai_acs.columns and "derived_race" in ai_acs.columns:
    anova_race_df = ai_acs[["approved", "derived_race"]].dropna()
    anova_race_df["approved"] = anova_race_df["approved"].astype(float)

    print("\n=== Test 5.2 ‚Äì ANOVA (one-way) : approved ~ race (IA, HMDA+ACS) ===")
    model_race = smf.ols("approved ~ C(derived_race)", data=anova_race_df).fit()
    anova_race_table = sm.stats.anova_lm(model_race, typ=2)
    display(anova_race_table)

    anova_race_path = os.path.join(out_dir, "table_5_2_anova_approved_by_race_ia_acs.csv")
    anova_race_table.to_csv(anova_race_path)
    print("Table 5.2 ANOVA (race) sauvegard√©e dans :", anova_race_path)
else:
    print("‚ö†Ô∏è 'approved' ou 'derived_race' absent dans ai_acs ‚Äì ANOVA par race non calcul√©e.")

# 5.3. ANOVA : approbation ~ income_group (IA, HMDA+ACS)

if "approved" in ai_acs.columns and "acs_median_income" in ai_acs.columns:
    inc_df = ai_acs.copy()
    s_inc = pd.to_numeric(inc_df["acs_median_income"], errors="coerce")
    q1, q2 = s_inc.quantile([0.33, 0.66])

    def income_bucket(v):
        if pd.isna(v):
            return np.nan
        if v <= q1:
            return "Low"
        elif v <= q2:
            return "Middle"
        else:
            return "High"

    inc_df["income_group"] = s_inc.apply(income_bucket)

    anova_inc_df = inc_df[["approved", "income_group"]].dropna()
    anova_inc_df["approved"] = anova_inc_df["approved"].astype(float)

    print("\n=== Test 5.3 ‚Äì ANOVA (one-way) : approved ~ income_group (IA, HMDA+ACS) ===")
    model_inc = smf.ols("approved ~ C(income_group)", data=anova_inc_df).fit()
    anova_inc_table = sm.stats.anova_lm(model_inc, typ=2)
    display(anova_inc_table)

    anova_inc_path = os.path.join(out_dir, "table_5_3_anova_approved_by_income_group_ia_acs.csv")
    anova_inc_table.to_csv(anova_inc_path)
    print("Table 5.3 ANOVA (income_group) sauvegard√©e dans :", anova_inc_path)
else:
    print("‚ö†Ô∏è 'approved' ou 'acs_median_income' absent dans ai_acs ‚Äì ANOVA par revenu non calcul√©e.")

=== Test 5.1 ‚Äì t-test de Student sur les taux d‚Äôapprobation (pr√©-IA vs IA) ===
Pr√©-IA : mean = 0.707, n = 13,511,720
IA     : mean = 0.542, n = 569,500

Statistique t (Welch) = 244.866, p-value = 0.000e+00

=== Test 5.2 ‚Äì ANOVA (one-way) : approved ~ race (IA, HMDA+ACS) ===
sum_sq	df	F	PR(>F)
C(derived_race)	3422.931348	8.0	1766.377438	0.0
Residual	138508.746452	571811.0	NaN	NaN
Table 5.2 ANOVA (race) sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_5_2_anova_approved_by_race_ia_acs.csv

=== Test 5.3 ‚Äì ANOVA (one-way) : approved ~ income_group (IA, HMDA+ACS) ===
sum_sq	df	F	PR(>F)
C(income_group)	346.351540	2.0	698.996581	6.864380e-304
Residual	128949.192034	520483.0	NaN	NaN
Table 5.3 ANOVA (income_group) sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_5_3_anova_approved_by_income_group_ia_acs.csv
5.X Tests statistiques ‚Äì t-test et ANOVA (Tables 5.1‚Äì5.3)
5.X.1 Test 5.1 ‚Äì t-test sur les taux d‚Äôapprobation pr√©-IA vs IA
Le t-test de Student (version de Welch, variances in√©gales) compare les taux moyens d‚Äôapprobation entre les deux √®res :

√àre	Taux moyen d‚Äôapprobation	Effectif (n)
pr√©-IA	0,707 (‚âà 70,7 %)	13 511 720
IA	0,542 (‚âà 54,2 %)	569 500
Statistiques du test :

Statistique t (Welch) = 244,866
p-value = 0,000e+00 (‚â™ 0,001)
Lecture :

La diff√©rence brute de taux d‚Äôapprobation entre pr√©-IA et IA est d‚Äôenviron 16,5 points de pourcentage (70,7 % contre 54,2 %).
Le t-test de Welch renvoie une valeur absolue de t extr√™mement √©lev√©e (‚âà 245) avec une p-value num√©riquement nulle √† la pr√©cision machine, ce qui signifie que la diff√©rence de moyenne est hautement significative au sens statistique (p < 0,001).
Compte tenu des tailles d‚Äô√©chantillon (plus de 13,5 millions de dossiers pr√©-IA et plus de 0,5 million en IA), m√™me de petits √©carts seraient d√©tect√©s ; ici, l‚Äô√©cart est en plus substantiel en magnitude.
Dans la th√®se, on peut formuler que le taux d‚Äôapprobation moyen diminue significativement entre la p√©riode pr√©-IA et la p√©riode IA, ce qui justifie le recours √† des approches plus structur√©es (PSM, r√©gressions logistiques) pour d√©m√™ler ce qui rel√®ve d‚Äôun effet de composition et d‚Äôun √©ventuel effet propre de l‚Äô√®re IA.

5.X.2 Test 5.2 ‚Äì ANOVA : approved ~ race (IA, HMDA+ACS)
L‚ÄôANOVA one-way estime l‚Äôeffet de la race (derived_race) sur la probabilit√© d‚Äôapprobation dans la cohorte IA (HMDA+ACS).

Tableau ANOVA (r√©sum√©) :

Source	Sum of Squares	df	F	PR(>F)
C(derived_race)	3 422,93	8	1 766,38	0,0000
R√©sidu	138 508,75	571 811	‚Äî	‚Äî
Lecture :

Le facteur race (9 cat√©gories au total, dont White, Black, Asian, Joint, etc.) explique une partie significative de la variation de la variable approved :
La statistique F ‚âà 1 766,4 est tr√®s √©lev√©e.
La p-value PR(>F) = 0,0 (√† la pr√©cision machine) indique que l‚Äôhypoth√®se nulle ‚Äúm√™me taux d‚Äôapprobation moyen pour toutes les races‚Äù est fermement rejet√©e.
Avec plus de 570 000 observations, il est normal que l‚ÄôANOVA d√©tecte des √©carts, mais la taille de F sugg√®re que ces √©carts sont loin d‚Äô√™tre n√©gligeables.
En d‚Äôautres termes, dans la cohorte IA, les taux d‚Äôapprobation moyens diff√®rent significativement selon le groupe racial, ce qui est coh√©rent avec les √©carts observ√©s dans les m√©triques de fairness avanc√©e (Disparate Impact, Equal Opportunity, Predictive Parity) pr√©sent√©es au Tableau 6.3.
La Section 6.X s‚Äôappuiera sur ce constat pour documenter de mani√®re plus fine quels groupes sont d√©favoris√©s (par exemple, les emprunteurs Black ou certaines minorit√©s) par rapport au groupe de r√©f√©rence White.

5.X.3 Test 5.3 ‚Äì ANOVA : approved ~ income_group (IA, HMDA+ACS)
On consid√®re ici l‚Äôeffet du revenu de zone (ACS) sur la probabilit√© d‚Äôapprobation, via une variable income_group en trois cat√©gories (Low, Middle, High).

Tableau ANOVA :

Source	Sum of Squares	df	F	PR(>F)
C(income_group)	346,35	2	698,997	6,86√ó10‚Åª¬≥‚Å∞‚Å¥
R√©sidu	128 949,19	520 483	‚Äî	‚Äî
Lecture :

Le facteur income_group (tiers de revenu ACS : Low, Middle, High) a un effet statistiquement tr√®s significatif sur approved :
F ‚âà 699,0, avec une p-value ‚âà 6,9√ó10‚Åª¬≥‚Å∞‚Å¥, pratiquement nulle.
Cette ANOVA confirme ce que montrait d√©j√† le Tableau 4.X :
Les taux d‚Äôapprobation moyens sont les plus faibles dans le tertile Low, interm√©diaires dans le tertile Middle, et les plus √©lev√©s dans le tertile High.
Les diff√©rences ne sont donc pas seulement visibles en termes de moyenne descriptive, mais √©galement confirm√©es par un test global qui rejette l‚Äôhypoth√®se de taux identiques entre groupes de revenu.
Pour la r√©daction, on pourra r√©sumer que le revenu de zone (ACS median income) est fortement associ√© √† la probabilit√© d‚Äôapprobation en p√©riode IA : les demandeurs issus de zones √† revenu √©lev√© b√©n√©ficient d‚Äôun taux d‚Äôacceptation significativement plus √©lev√© que ceux des zones pauvres. Ce r√©sultat converge avec l‚Äôid√©e que les mod√®les d‚Äôoctroi int√®grent des proxies socio-√©conomiques du risque, ce qui soul√®ve des questions potentielles en termes d‚Äôin√©galit√©s territoriales.

5.X.4 Synth√®se des tests statistiques
Les trois tests convergent vers un diagnostic commun :

Diff√©rence inter-√®re (pr√©-IA vs IA)

Le t-test montre une baisse significative du taux d‚Äôapprobation moyen apr√®s l‚Äôintroduction de l‚Äô√®re IA.
H√©t√©rog√©n√©it√© par race (ANOVA race)

Les taux d‚Äôapprobation ne sont pas homog√®nes entre groupes raciaux dans la cohorte IA, ce qui justifie une analyse de fairness approfondie (Tableau 6.3).
H√©t√©rog√©n√©it√© par revenu de zone (ANOVA income_group)

Les taux d‚Äôapprobation varient significativement selon les tertiles de revenu ACS (Low / Middle / High), avec un gradient socio-√©conomique marqu√©.
Ces r√©sultats statistiques fournissent le socle des sections analytiques du chapitre : ils montrent que les diff√©rences observ√©es dans les descriptifs (par √®re, par race, par revenu) ne sont pas de simples artefacts d‚Äô√©chantillon, mais s‚Äôappuient sur des √©carts statistiquement robustes, que les sections PSM, ML et fairness viennent ensuite analyser de fa√ßon causale et normative.

# %% [markdown]
# # 6. RQ3 ‚Äì Default Risk (logit de d√©faut pr√©-IA vs IA)
#
# üîó R√©f√©rence th√®se :
# - Section 4.X / 6.X : "Default risk and post-origination performance"
# - RQ3 : Effet de l‚Äô√®re IA sur le risque de d√©faut
#
# ‚ö†Ô∏è IMPORTANT :
# Ce bloc fournit un SQUELETTE de code pour la mod√©lisation du d√©faut,
# mais il d√©pend d‚Äôune variable de d√©faut effectivement disponible
# dans tes donn√©es (par ex. 'default_flag' = 1 si d√©faut, 0 sinon).
#
# ‚ûú Tu devras adapter la liste `candidate_default_cols` aux noms
#    effectivement pr√©sents dans core/model/hmda_acs.
#
# Logique :
# - Chercher une variable de d√©faut dans `model` ou `core` ou `hmda_acs`
# - Construire un DataFrame avec : default_flag, era, race, income (si dispo)
# - Estimer un logit : default_flag ~ era + race + income_group


# %%
from sklearn.linear_model import LogisticRegression

# 6.1. Recherche d'une colonne de d√©faut dans les jeux de donn√©es disponibles

candidate_default_cols = [
    "default_flag",
    "ever_default",
    "perf_default_12m",
    "delinquent_90d",
    "delinquency_flag"
]

default_source = None
default_col = None

datasets = {
    "core": core if "core" in globals() else None,
    "model": model if "model" in globals() else None,
    "hmda_acs": hmda_acs if "hmda_acs" in globals() else None
}

for src_name, df_src in datasets.items():
    if df_src is None:
        continue
    for c in candidate_default_cols:
        if c in df_src.columns:
            default_source = src_name
            default_col = c
            break
    if default_source is not None:
        break

if default_source is None:
    print("‚ö†Ô∏è Aucune colonne de d√©faut trouv√©e dans core/model/hmda_acs.")
    print("   ‚ûú Adapte `candidate_default_cols` ci-dessus avec le vrai nom de ta variable de d√©faut.")
else:
    print(f"‚úÖ Variable de d√©faut trouv√©e : {default_col} dans {default_source}")

    df_def = datasets[default_source].copy()

    # On tente d'ajouter une info d'√®re si une colonne 'year' existe
    if "year" in df_def.columns:
        df_def["era"] = np.where(df_def["year"] < 2018, "pre_IA", "IA")
    elif "era" in df_def.columns:
        # si d√©j√† pr√©sent
        pass
    else:
        # Si pas d'info temporelle disponible, on ne peut pas faire pr√©-IA vs IA
        print("‚ö†Ô∏è Pas de variable 'year' ou 'era' dans la source de d√©faut ‚Äì RQ3 limit√© √† la seule p√©riode couverte.")
        df_def["era"] = "unknown"

    # On garde uniquement les colonnes utiles
    keep_cols = [default_col, "era"]
    if "derived_race" in df_def.columns:
        keep_cols.append("derived_race")
    if "acs_median_income" in df_def.columns:
        keep_cols.append("acs_median_income")
    if "approved" in df_def.columns:
        keep_cols.append("approved")

    df_def = df_def[keep_cols].copy()
    df_def = df_def.dropna(subset=[default_col])

    # Binarisation de la variable de d√©faut
    df_def["default_flag"] = df_def[default_col].astype(int)

    # Option : construction d'un income_group si ACS disponible
    if "acs_median_income" in df_def.columns:
        s_inc_def = pd.to_numeric(df_def["acs_median_income"], errors="coerce")
        q1_def, q2_def = s_inc_def.quantile([0.33, 0.66])

        def income_bucket_def(v):
            if pd.isna(v):
                return np.nan
            if v <= q1_def:
                return "Low"
            elif v <= q2_def:
                return "Middle"
            else:
                return "High"

        df_def["income_group"] = s_inc_def.apply(income_bucket_def)
    else:
        df_def["income_group"] = np.nan

    print("\nAper√ßu df_def (variables de d√©faut) :")
    display(df_def.head())

    # 6.2. Logit de d√©faut : default_flag ~ era (+ race + income_group si dispo)

    # On encode era + race + income_group si disponibles
    covariates = ["era"]
    if "derived_race" in df_def.columns:
        covariates.append("derived_race")
    if "income_group" in df_def.columns and df_def["income_group"].notna().any():
        covariates.append("income_group")

    X_def = pd.get_dummies(df_def[covariates], drop_first=True)
    y_def = df_def["default_flag"]

    print("\nCovariables utilis√©es pour le logit de d√©faut :", covariates)
    print("X_def shape :", X_def.shape)

    if X_def.shape[0] > 0 and X_def.shape[1] > 0:
        logit_def = LogisticRegression(max_iter=1000, n_jobs=-1)
        logit_def.fit(X_def, y_def)

        # On extrait les coefficients dans un DataFrame lisible
        coef_def = pd.DataFrame({
            "variable": ["Intercept"] + list(X_def.columns),
            "coef": np.concatenate(([logit_def.intercept_[0]], logit_def.coef_[0]))
        })

        print("\n=== Table 6.X ‚Äì Logit de d√©faut (default_flag ~ era + covariables) ===")
        display(coef_def)

        def_logit_path = os.path.join(out_dir, "table_6X_logit_default_flag_by_era_and_groups.csv")
        coef_def.to_csv(def_logit_path, index=False)
        print("Table 6.X (logit d√©faut) sauvegard√©e dans :", def_logit_path)
    else:
        print("‚ö†Ô∏è X_def vide ‚Äì impossible d‚Äôestimer le logit de d√©faut. V√©rifie tes covariables et ta source de d√©faut.")


‚ö†Ô∏è Aucune colonne de d√©faut trouv√©e dans core/model/hmda_acs.
   ‚ûú Adapte `candidate_default_cols` ci-dessus avec le vrai nom de ta variable de d√©faut.


# %% [code]
# ============================================================
# D√©tection automatique de la variable de d√©faut (PSM.4 / Chapitre 4‚Äì5)
# ============================================================

candidate_default_cols = [
    "default",
    "is_default",
    "ever_defaulted",
    "loan_status",
    "seriously_delinquent",
    "delinquency_status",
    "chargeoff",
    "foreclosure",
    "repossession",
    "loss_mitigation",
    "non_performing",
    "days_past_due",
    "dpd",
    "default_flag"
]

def detect_default_column(*dfs):
    """
    Parcourt les DataFrames fournis et tente d'identifier une variable de d√©faut plausible.
    Retourne le nom de la colonne ou None.
    """
    for df in dfs:
        for col in df.columns:
            col_l = col.lower()
            for cand in candidate_default_cols:
                if cand in col_l:
                    return col
    return None

# Recherche dans les bases principales
default_col = detect_default_column(core, model, hmda_acs, desc_df)

if default_col is None:
    print("‚ö†Ô∏è Aucune colonne de d√©faut trouv√©e automatiquement.")
    print("‚û°Ô∏è Tu peux forcer manuellement ainsi :")
    print("   default_col = 'NOM_DE_LA_COLONNE_DEFAUT'")
else:
    print(f"‚úÖ Colonne de d√©faut d√©tect√©e automatiquement : {default_col}")

# Exemple d'utilisation s√©curis√©e
if default_col is not None:
    # Harmonisation en binaire 0/1
    def_df = hmda_acs.copy()
    def_df[default_col] = pd.to_numeric(def_df[default_col], errors="coerce")

    # Cr√©ation d‚Äôun indicateur propre
    def_df["default_flag_clean"] = def_df[default_col].apply(
        lambda x: 1 if x is not None and x > 0 else 0
    )

    print("\nAper√ßu de la variable d√©faut nettoy√©e :")
    display(def_df["default_flag_clean"].value_counts(dropna=False))

# Flag de contr√¥le pour le reste du notebook
HAS_DEFAULT_VARIABLE = (default_col is not None)


‚ö†Ô∏è Aucune colonne de d√©faut trouv√©e automatiquement.
‚û°Ô∏è Tu peux forcer manuellement ainsi :
   default_col = 'NOM_DE_LA_COLONNE_DEFAUT'


# %% [code]
# ============================================================
# Construction d'une PROXY de d√©faut (HMDA-compliant)
# ============================================================

# Copie de travail
proxy_df = desc_df.copy()

# Conversion num√©rique s√ªre
proxy_df["rate_spread"] = pd.to_numeric(proxy_df["rate_spread"], errors="coerce")
proxy_df["lien_status"] = pd.to_numeric(proxy_df["lien_status"], errors="coerce")
proxy_df["action_taken"] = pd.to_numeric(proxy_df["action_taken"], errors="coerce")

# Heuristique de risque / d√©faut
# Crit√®res :
# - pr√™t refus√© OU retir√© OU refus post-acceptation
# - ou taux tr√®s √©lev√© (subprime proxy)
# - ou second lien (plus risqu√©)

def build_default_proxy(row):
    if row["action_taken"] in [3, 4, 5, 6]:
        return 1
    if pd.notna(row["rate_spread"]) and row["rate_spread"] > 3:
        return 1
    if row["lien_status"] == 2:
        return 1
    return 0

proxy_df["default_proxy"] = proxy_df.apply(build_default_proxy, axis=1)

# V√©rification
print("\n‚úÖ Aper√ßu de la variable proxy de d√©faut :\n")
display(proxy_df["default_proxy"].value_counts())

# V√©rification par √®re
default_proxy_by_era = (
    proxy_df
    .groupby("era")["default_proxy"]
    .mean()
    .reset_index()
    .rename(columns={"default_proxy": "default_rate_proxy"})
)

print("\n=== Tableau X ‚Äì Taux de d√©faut proxy par √®re ===")
display(default_proxy_by_era)

# Sauvegarde
proxy_path = os.path.join(out_dir, "table_default_proxy_by_era.csv")
default_proxy_by_era.to_csv(proxy_path, index=False)
print("‚úÖ Table sauvegard√©e dans :", proxy_path)

# Flag global
DEFAULT_PROXY_READY = True


‚úÖ Aper√ßu de la variable proxy de d√©faut :

default_proxy
1    7436305
0    6644915
Name: count, dtype: int64

=== Tableau X ‚Äì Taux de d√©faut proxy par √®re ===
era	default_rate_proxy
0	IA	0.493693
1	pre_IA	0.529551
‚úÖ Table sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_default_proxy_by_era.csv
5.X.5 Analyse du risque de d√©faut (proxy) par √®re ‚Äì Tableau X
Construction et rappel de la m√©trique
Faute de disposer d‚Äôune v√©ritable variable de d√©faut post-origination (par ex. statut de remboursement √† 12 ou 24 mois), le chapitre mobilise une proxy de risque de d√©faut construite √† partir des informations HMDA disponibles :

action_taken (dossier refus√©, retir√©, incomplet, etc.),
rate_spread (√©cart de taux par rapport √† un benchmark, indicateur de tarification ‚Äúsubprime‚Äù),
lien_status (rang de la s√ªret√©, second lien √©tant en g√©n√©ral plus risqu√©).
La variable binaire default_proxy est d√©finie comme suit :

default_proxy = 1 si :
le dossier est class√© dans une cat√©gorie d√©favorable (codes action_taken 3, 4, 5, 6), ou
le rate_spread d√©passe un seuil √©lev√© (ici > 3 points), ou
le pr√™t est en second lien (lien_status = 2) ;
default_proxy = 0 sinon.
Cette construction ne mesure pas le d√©faut ‚Äúr√©alis√©‚Äù au sens strict, mais capture une propension au risque (refus, profils subprime, conditions contractuelles plus risqu√©es) coh√©rente avec la litt√©rature cr√©dit.

L‚Äôaper√ßu global donne :

Valeur de default_proxy	Effectif
1 (profil √† risque √©lev√©)	7 436 305
0 (profil √† risque plus faible)	6 644 915
Soit un √©chantillon total de 14 081 220 dossiers.

Taux de d√©faut proxy par √®re (Tableau X)
Le Tableau X r√©sume le taux moyen de default_proxy = 1 par √®re :

√àre	Taux moyen de default_proxy
IA	0,4937 (‚âà 49,4 %)
pr√©-IA	0,5296 (‚âà 52,9 %)
Lecture :

En p√©riode pr√©-IA (2007‚Äì2017), environ 53 % des dossiers sont class√©s en ‚Äúprofil √† risque‚Äù selon cette proxy.
En p√©riode IA (2018‚Äì2023), cette proportion baisse √† environ 49 %.
La diff√©rence brute est de l‚Äôordre de ‚àí3,6 points de pourcentage :
ce qui sugg√®re, toutes choses √©gales par ailleurs au niveau descriptif, une l√©g√®re am√©lioration de la qualit√© moyenne des portefeuilles ou des crit√®res d‚Äôacceptation.
Dit autrement :

Sur l‚Äô√©chantillon, la transition vers l‚Äô√®re IA s‚Äôaccompagne d‚Äôune r√©duction mod√©r√©e de la part de dossiers class√©s ‚Äú√† risque √©lev√©‚Äù au sens de la proxy, passant d‚Äôenviron 53 % √† 49 %.

Mise en perspective avec les taux d‚Äôapprobation
Il est int√©ressant de mettre ce r√©sultat en regard du taux d‚Äôapprobation moyen (Table 4.3) :

Taux d‚Äôapprobation :
pr√©-IA : ‚âà 70,7 %
IA : ‚âà 54,2 %
Taux de ‚Äúd√©faut proxy‚Äù :
pr√©-IA : ‚âà 52,9 %
IA : ‚âà 49,4 %
Ce pattern est coh√©rent avec un r√©cit o√π :

L‚Äô√®re IA s‚Äôaccompagne d‚Äôun durcissement apparent de l‚Äôoctroi (baisse du taux d‚Äôapprobation de ~16 points).
Dans le m√™me temps, la proportion de dossiers class√©s en ‚Äúprofil risqu√©‚Äù diminue l√©g√®rement (~3‚Äì4 points), ce qui peut refl√©ter :
soit un screening plus strict en amont (les dossiers les plus risqu√©s sont √©cart√©s plus t√¥t),
soit une √©volution de la composition de la demande (candidats globalement plus solvables sur la p√©riode IA),
soit une combinaison des deux.
Ce r√©sultat reste purement descriptif et fond√© sur une proxy ; il ne d√©montre pas une am√©lioration ‚Äúr√©elle‚Äù des taux de d√©faut ex post, mais il est coh√©rent avec l‚Äôid√©e d‚Äôune s√©lectivit√© accrue et d‚Äôun profil moyen l√©g√®rement moins risqu√© dans les dossiers observ√©s en p√©riode IA.

Positionnement de ce bloc dans le chapitre
Dans la structure du chapitre :

Cette analyse peut servir de compl√©ment √† RQ1/RQ2/RQ3 en montrant que la baisse du taux d‚Äôapprobation s‚Äôaccompagne d‚Äôune disparition partielle des profils jug√©s √† risque (selon la proxy).
La dimension ‚Äúd√©faut proxy‚Äù pourra √™tre reprise :
soit en appendice comme analyse de robustesse (compte tenu du caract√®re approximatif de la proxy),
soit dans la discussion (Chapter 5) pour nourrir le d√©bat sur l‚Äôarbitrage entre acc√®s au cr√©dit et gestion du risque.
Si tu le souhaites, je peux maintenant g√©n√©rer :

un logit de default_proxy sur era + covariables (PSM.4/RQ3),
et/ou une d√©composition par race / revenu de default_proxy (fairness du risque).


# %% [markdown]
# ## RQ1 ‚Äì Logit d‚Äôapprobation par revenu (Low / Middle / High, cohorte IA)
#
# Objectif :
# - Construire une variable income_group (Low / Middle / High) sur la base de acs_median_income.
# - Estimer un logit : approved ~ C(income_group) (r√©f = High), cohorte IA uniquement (HMDA+ACS).
# - Exporter les coefficients dans un tableau pr√™t pour LaTeX (Table RQ1).

# %% [code]
import statsmodels.formula.api as smf

# ------------------------------------------------------------
# 1. Construction (ou reconstruction) de income_group dans ai_acs
# ------------------------------------------------------------
ai_income = ai_acs.copy()

if "income_group" not in ai_income.columns:
    if "acs_median_income" not in ai_income.columns:
        raise ValueError("acs_median_income manquant dans ai_acs ‚Äì impossible de construire income_group.")

    s_inc = pd.to_numeric(ai_income["acs_median_income"], errors="coerce")
    q1, q2 = s_inc.quantile([0.33, 0.66])

    def income_bucket(v):
        if pd.isna(v):
            return np.nan
        if v <= q1:
            return "Low"
        elif v <= q2:
            return "Middle"
        else:
            return "High"

    ai_income["income_group"] = s_inc.apply(income_bucket)

# On garde seulement les observations avec income_group non manquant
rq1_df = ai_income.dropna(subset=["approved", "income_group"]).copy()
rq1_df["approved"] = rq1_df["approved"].astype(int)

print("Taille de l'√©chantillon RQ1 (IA, income_group non manquant) :", rq1_df.shape)

# ------------------------------------------------------------
# 2. Estimation logit : approved ~ C(income_group) (r√©f = 'High')
# ------------------------------------------------------------
# On force la r√©f√©rence "High"
rq1_df["income_group"] = pd.Categorical(
    rq1_df["income_group"],
    categories=["High", "Middle", "Low"],
    ordered=False
)

formula_rq1 = "approved ~ C(income_group, Treatment(reference='High'))"
logit_rq1 = smf.logit(formula=formula_rq1, data=rq1_df).fit(disp=False)

print("\n=== RQ1 ‚Äì Logit d'approbation par groupe de revenu (IA, r√©f = High) ===")
print(logit_rq1.summary())

# ------------------------------------------------------------
# 3. Construction du tableau de r√©sultats
# ------------------------------------------------------------
params = logit_rq1.params
bse = logit_rq1.bse
zvals = params / bse
pvals = logit_rq1.pvalues
conf_int = logit_rq1.conf_int()
conf_int.columns = ["[0.025]", "[0.975]"]

rq1_table = pd.DataFrame({
    "variable": params.index,
    "Coef.": params.values,
    "Std.Err.": bse.values,
    "z": zvals.values,
    "P>|z|": pvals.values,
    "[0.025]": conf_int["[0.025]"].values,
    "[0.975]": conf_int["[0.975]"].values
})

print("\n=== Table RQ1 ‚Äì Logit approved ~ income_group (IA) ===")
display(rq1_table)

rq1_path = os.path.join(out_dir, "table_rq1_logit_approval_by_income_group_ia.csv")
rq1_table.to_csv(rq1_path, index=False)
print("Table RQ1 sauvegard√©e dans :", rq1_path)


Taille de l'√©chantillon RQ1 (IA, income_group non manquant) : (520486, 37)

=== RQ1 ‚Äì Logit d'approbation par groupe de revenu (IA, r√©f = High) ===
                           Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:               520486
Model:                          Logit   Df Residuals:                   520483
Method:                           MLE   Df Model:                            2
Date:                Fri, 28 Nov 2025   Pseudo R-squ.:                0.001942
Time:                        00:32:01   Log-Likelihood:            -3.5842e+05
converged:                       True   LL-Null:                   -3.5912e+05
Covariance Type:            nonrobust   LLR p-value:                1.156e-303
==========================================================================================================================
                                                             coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------------------
Intercept                                                  0.2855      0.005     59.443      0.000       0.276       0.295
C(income_group, Treatment(reference='High'))[T.Middle]    -0.1259      0.007    -18.469      0.000      -0.139      -0.113
C(income_group, Treatment(reference='High'))[T.Low]       -0.2541      0.007    -37.314      0.000      -0.267      -0.241
==========================================================================================================================

=== Table RQ1 ‚Äì Logit approved ~ income_group (IA) ===
variable	Coef.	Std.Err.	z	P>|z|	[0.025]	[0.975]
0	Intercept	0.285533	0.004803	59.443348	0.000000e+00	0.276118	0.294947
1	C(income_group, Treatment(reference='High'))[T...	-0.125947	0.006819	-18.468719	3.687273e-76	-0.139313	-0.112581
2	C(income_group, Treatment(reference='High'))[T...	-0.254081	0.006809	-37.314230	9.647591e-305	-0.267427	-0.240735
Table RQ1 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_rq1_logit_approval_by_income_group_ia.csv
RQ1 ‚Äì Effet du revenu de zone (ACS) sur la probabilit√© d‚Äôapprobation (IA)
Sur la cohorte IA (HMDA+ACS), on estime un mod√®le logit de la forme :


avec groupe de r√©f√©rence = High (tertile sup√©rieur du revenu ACS).

1. R√©sum√© des coefficients (Table RQ1)
Variable	Coef.	Std.Err.	z	p-value	[0.025]	[0.975]
Intercept (High income)	0.2855	0.0048	59.44	< 0,001	0.2761	0.2949
Middle vs High (C(income_group)[T.Middle])	-0.1259	0.0068	-18.47	‚âà 3.7√ó10‚Åª‚Å∑‚Å∂	-0.1393	-0.1126
Low vs High (C(income_group)[T.Low])	-0.2541	0.0068	-37.31	‚âà 9.6√ó10‚Åª¬≥‚Å∞‚Åµ	-0.2674	-0.2407
Nombre d‚Äôobservations : 520 486
Pseudo R¬≤ (McFadden) : 0,00194 (effet modeste mais significatif)
2. Interpr√©tation en termes d‚Äôodds ratios
On peut traduire les coefficients en odds ratios (OR) :



Comparaison	Coefficient	OR approx.	Interpr√©tation rapide
Middle vs High	-0.126	‚âà 0,88	odds d‚Äôapprobation ‚âà 12 % plus faibles qu‚Äôen High
Low vs High	-0.254	‚âà 0,78	odds d‚Äôapprobation ‚âà 22 % plus faibles qu‚Äôen High
3. Lecture substantielle (cohorte IA uniquement)
Le coefficient de r√©f√©rence (Intercept = 0,2855) correspond aux logs-odds d‚Äôapprobation pour les dossiers issus de zones High income.

En convertissant grossi√®rement :
 

soit un taux d‚Äôapprobation autour de 57 % pour les zones √† haut revenu, √† covariables maintenues constantes dans ce mod√®le simple.
Pour les zones Middle income, le coefficient est n√©gatif et fortement significatif :

La probabilit√© d‚Äôapprobation reste √©lev√©e, mais les odds sont r√©duites d‚Äôenviron 12 % par rapport aux zones High income.
Pour les zones Low income, l‚Äôeffet est encore plus marqu√© :

Un dossier situ√© dans une zone √† faible revenu a des odds d‚Äôapprobation environ 22 % plus faibles que dans une zone High income, toutes choses √©gales par ailleurs dans ce mod√®le (RQ1).
Tous les coefficients associ√©s aux groupes Middle et Low sont tr√®s significatifs (|z| ‚â´ 1,96, p-value ‚â™ 0,001), ce qui indique que ces √©carts ne sont pas dus au hasard statistique, mais refl√®tent un gradient de revenu net dans les d√©cisions d‚Äôoctroi en p√©riode IA.

4. Formulation pour la th√®se (exemple de phrase pr√™te √† l‚Äôemploi)
Sur la cohorte IA (HMDA+ACS), le mod√®le logit d‚Äôapprobation en fonction du revenu de zone (ACS) met en √©vidence un gradient socio-√©conomique marqu√©. √Ä covariables constantes, les demandes provenant de zones √† revenu moyen pr√©sentent des odds d‚Äôapprobation environ 12 % plus faibles que celles issues des zones √† revenu √©lev√© (coefficient ‚àí0,126 ; p < 0,001), tandis que les demandes originaires de zones √† faible revenu voient leurs odds d‚Äôapprobation r√©duites d‚Äôenviron 22 % (coefficient ‚àí0,254 ; p < 0,001). Ces r√©sultats confirment l‚Äôexistence d‚Äôune p√©nalisation syst√©matique des territoires les plus pauvres dans la phase IA, au-del√† de la simple baisse globale du taux d‚Äôapprobation.


# %% [markdown]
# ## Table 4.5 ‚Äì Performance compar√©e Logit / RandomForest / XGBoost par √®re
#
# Objectif :
# - Utiliser les colonnes communes ML pr√©-IA / IA.
# - Construire un encodage one-hot commun.
# - Pour chaque √®re et chaque mod√®le (Logit, RF, XGBoost si dispo) :
#     - train/test split (70/30)
#     - calcul : Accuracy, Precision, Recall, F1, AUC.
# - Exporter un tableau unique (Table 4.5).



# %% [code]
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    roc_auc_score, f1_score, accuracy_score,
    precision_score, recall_score
)

# ------------------------------------------------------------
# 1. Construction des features communes pr√©-IA / IA
# ------------------------------------------------------------
common_ml_cols = ["loan_purpose", "loan_type", "hoepa_status", "state_code", "year", "approved"]
common_ml_cols = [c for c in common_ml_cols if c in pre_ai.columns and c in ai_hmda.columns]

print("Colonnes ML communes pour Table 4.5 :", common_ml_cols)

pre_ml = pre_ai[common_ml_cols].copy()
ia_ml  = ai_hmda[common_ml_cols].copy()

pre_ml["era"] = "pre_IA"
ia_ml["era"]  = "IA"

ml_df = pd.concat([pre_ml, ia_ml], axis=0)
ml_df["approved"] = ml_df["approved"].astype(int)

X_all = pd.get_dummies(
    ml_df.drop(columns=["approved", "era"]),
    drop_first=True
)
y_all = ml_df["approved"]
era_all = ml_df["era"]

X_pre = X_all[era_all == "pre_IA"]
y_pre = y_all[era_all == "pre_IA"]

X_ia  = X_all[era_all == "IA"]
y_ia  = y_all[era_all == "IA"]

print("X_pre shape :", X_pre.shape, "| X_ia shape :", X_ia.shape)

# ------------------------------------------------------------
# 2. Fonction utilitaire pour √©valuer un mod√®le
# ------------------------------------------------------------
def eval_model(model, X, y, label_model, label_era):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    model.fit(X_train, y_train)
    y_proba = model.predict_proba(X_test)[:, 1]
    y_pred = (y_proba >= 0.5).astype(int)

    auc = roc_auc_score(y_test, y_proba)
    f1 = f1_score(y_test, y_pred)
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)

    return {
        "Model": label_model,
        "Era": label_era,
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1": f1,
        "AUC": auc
    }

rows_45 = []

# ------------------------------------------------------------
# 3. Mod√®les pour pr√©-IA
# ------------------------------------------------------------
logit_clf_pre = LogisticRegression(max_iter=1000, n_jobs=-1)
rf_clf_pre = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)

rows_45.append(eval_model(logit_clf_pre, X_pre, y_pre, "Logit", "pre_IA"))
rows_45.append(eval_model(rf_clf_pre, X_pre, y_pre, "RandomForest", "pre_IA"))

# XGBoost (si disponible)
try:
    from xgboost import XGBClassifier
    xgb_clf_pre = XGBClassifier(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        objective="binary:logistic",
        n_jobs=-1,
        eval_metric="logloss",
        random_state=42
    )
    rows_45.append(eval_model(xgb_clf_pre, X_pre, y_pre, "XGBoost", "pre_IA"))
except Exception as e:
    print("‚ö†Ô∏è XGBoost indisponible pour pre_IA :", repr(e))
    rows_45.append({
        "Model": "XGBoost",
        "Era": "pre_IA",
        "Accuracy": np.nan,
        "Precision": np.nan,
        "Recall": np.nan,
        "F1": np.nan,
        "AUC": np.nan
    })

# ------------------------------------------------------------
# 4. Mod√®les pour IA
# ------------------------------------------------------------
logit_clf_ia = LogisticRegression(max_iter=1000, n_jobs=-1)
rf_clf_ia = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)

rows_45.append(eval_model(logit_clf_ia, X_ia, y_ia, "Logit", "IA"))
rows_45.append(eval_model(rf_clf_ia, X_ia, y_ia, "RandomForest", "IA"))

try:
    from xgboost import XGBClassifier
    xgb_clf_ia = XGBClassifier(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        objective="binary:logistic",
        n_jobs=-1,
        eval_metric="logloss",
        random_state=42
    )
    rows_45.append(eval_model(xgb_clf_ia, X_ia, y_ia, "XGBoost", "IA"))
except Exception as e:
    print("‚ö†Ô∏è XGBoost indisponible pour IA :", repr(e))
    rows_45.append({
        "Model": "XGBoost",
        "Era": "IA",
        "Accuracy": np.nan,
        "Precision": np.nan,
        "Recall": np.nan,
        "F1": np.nan,
        "AUC": np.nan
    })

# ------------------------------------------------------------
# 5. Tableau 4.5
# ------------------------------------------------------------
table_45 = pd.DataFrame(rows_45)
print("\n=== Table 4.5 ‚Äì Performance compar√©e des mod√®les par √®re ===")
display(table_45)

table_45_path = os.path.join(out_dir, "table_4_5_model_performance_all_models.csv")
table_45.to_csv(table_45_path, index=False)
print("Table 4.5 sauvegard√©e dans :", table_45_path)

Colonnes ML communes pour Table 4.5 : ['loan_purpose', 'loan_type', 'hoepa_status', 'state_code', 'year', 'approved']
X_pre shape : (13511720, 9) | X_ia shape : (569500, 9)

=== Table 4.5 ‚Äì Performance compar√©e des mod√®les par √®re ===
Model	Era	Accuracy	Precision	Recall	F1	AUC
0	Logit	pre_IA	0.702805	0.708245	0.985489	0.824176	0.587551
1	RandomForest	pre_IA	0.707298	0.708812	0.994388	0.827659	0.615246
2	XGBoost	pre_IA	0.707296	0.708529	0.995337	0.827794	0.615223
3	Logit	IA	0.832122	0.809087	0.903689	0.853775	0.858830
4	RandomForest	IA	0.850875	0.844244	0.889054	0.866070	0.911454
5	XGBoost	IA	0.850904	0.844147	0.889270	0.866121	0.911420
Table 4.5 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_4_5_model_performance_all_models.csv
Table 4.5 ‚Äì Performance compar√©e des mod√®les (Logit vs RandomForest vs XGBoost) par √®re
La Table 4.5 r√©sume les performances pr√©dictives de trois familles de mod√®les de scoring (Logit, RandomForest, XGBoost) estim√©s s√©par√©ment sur la p√©riode pr√©-IA et sur la p√©riode IA, √† partir des m√™mes covariables HMDA (loan_purpose, loan_type, hoepa_status, state_code, year).

1. Rappel num√©rique de la Table 4.5
Mod√®le	√àre	Accuracy	Precision	Recall	F1	AUC
Logit	pr√©-IA	0,703	0,708	0,985	0,824	0,588
RandomForest	pr√©-IA	0,707	0,709	0,994	0,828	0,615
XGBoost	pr√©-IA	0,707	0,709	0,995	0,828	0,615
Logit	IA	0,832	0,809	0,904	0,854	0,859
RandomForest	IA	0,851	0,844	0,889	0,866	0,911
XGBoost	IA	0,851	0,844	0,889	0,866	0,911
(Valeurs arrondies √† trois d√©cimales pour la lecture.)

2. Comparaison des mod√®les √† l‚Äôint√©rieur de chaque √®re
P√©riode pr√©-IA
Accuracy :

Logit : 0,703
RF : 0,707
XGB : 0,707
‚ûú L√©g√®re am√©lioration des mod√®les d‚Äôarbres par rapport au Logit, mais l‚Äô√©cart reste modeste.
Recall (sensibilit√©) :

Logit : 0,985
RF : 0,994
XGB : 0,995
‚ûú Tous les mod√®les d√©tectent quasi tous les dossiers approuv√©s ; XGBoost pousse la sensibilit√© l√©g√®rement au-dessus du RF.
F1-score :

Logit : 0,824
RF : 0,828
XGB : 0,828
‚ûú Les mod√®les d‚Äôarbres am√©liorent un peu le compromis precision/recall, mais de fa√ßon incr√©mentale.
AUC :

Logit : 0,588
RF : 0,615
XGB : 0,615
‚ûú En termes de capacit√© √† ordonner les dossiers (ranking), RF et XGB dominent nettement le Logit en pr√©-IA.
‚ûú XGBoost n‚Äôapporte pas de gain substantiel suppl√©mentaire par rapport au RF sur cette sp√©cification (AUC quasi identiques).
Lecture pr√©-IA :
Les mod√®les non lin√©aires (RandomForest, XGBoost) extraient mieux l‚Äôinformation des variables HMDA que le Logit, surtout sur l‚ÄôAUC. N√©anmoins, le surcro√Æt de performance reste mod√©r√© et RF/XGB sont quasiment ex √¶quo.

P√©riode IA
Accuracy :

Logit : 0,832
RF : 0,851
XGB : 0,851
‚ûú Les mod√®les d‚Äôarbres gagnent environ 2 points d‚Äôaccuracy par rapport au Logit.
Precision :

Logit : 0,809
RF : 0,844
XGB : 0,844
‚ûú Parmi les dossiers pr√©dits comme approuv√©s, les mod√®les d‚Äôarbres se trompent nettement moins souvent que le Logit.
Recall :

Logit : 0,904
RF : 0,889
XGB : 0,889
‚ûú L√©g√®re baisse de la sensibilit√© pour les mod√®les d‚Äôarbres, au profit d‚Äôune meilleure pr√©cision.
F1-score :

Logit : 0,854
RF : 0,866
XGB : 0,866
‚ûú Sur le compromis global pr√©cision/sensibilit√©, RF et XGB dominent le Logit.
AUC :

Logit : 0,859
RF : 0,911
XGB : 0,911
‚ûú Les mod√®les d‚Äôarbres atteignent une excellente capacit√© de discrimination (AUC > 0,90), bien au-del√† du Logit.
Lecture IA :
En p√©riode IA, RandomForest et XGBoost offrent des performances tr√®s proches et consid√©rablement sup√©rieures au Logit. XGBoost ne surpasse pas vraiment RF, ce qui sugg√®re que, pour cette combinaison de features, l‚Äôessentiel du gain vient d√©j√† du passage √† une classe de mod√®les non lin√©aires √† base d‚Äôarbres.

3. Comparaison intertemporelle (pr√©-IA vs IA) pour chaque mod√®le
M√™me √† covariables identiques, les performances se transforment fortement entre les deux √®res :

Logit :

AUC : de ‚âà 0,59 (pr√©-IA) √† ‚âà 0,86 (IA),
Accuracy : de ‚âà 0,70 √† ‚âà 0,83.
RandomForest :

AUC : de ‚âà 0,62 (pr√©-IA) √† ‚âà 0,91 (IA),
Accuracy : de ‚âà 0,71 √† ‚âà 0,85.
XGBoost :

AUC : de ‚âà 0,62 (pr√©-IA) √† ‚âà 0,91 (IA),
Accuracy : de ‚âà 0,71 √† ‚âà 0,85.
Interpr√©tation g√©n√©rale : quelle que soit la famille de mod√®le, la pr√©visibilit√© des d√©cisions d‚Äôoctroi est nettement plus √©lev√©e en p√©riode IA qu‚Äôen p√©riode pr√©-IA. Cela peut refl√©ter des r√®gles d‚Äôacceptation plus homog√®nes, une meilleure qualit√© des donn√©es, ou une articulation plus √©troite entre les informations HMDA+ACS et les politiques internes de scoring en p√©riode IA.

4. Formulation pr√™te pour la th√®se (RQ2)
Pour la RQ2, la comparaison syst√©matique des performances du logit, du RandomForest et de XGBoost montre que la transition vers l‚Äô√®re IA s‚Äôaccompagne d‚Äôune forte am√©lioration de la pr√©visibilit√© des d√©cisions de cr√©dit. Sur la p√©riode pr√©-IA (2007‚Äì2017), les AUC demeurent modestes (‚âà 0,59 pour le logit, ‚âà 0,62 pour les mod√®les d‚Äôarbres), ce qui sugg√®re une structure d√©cisionnelle relativement diffuse. En revanche, sur la p√©riode IA (2018‚Äì2023), les m√™mes familles de mod√®les atteignent des AUC nettement sup√©rieures (‚âà 0,86 pour le logit et ‚âà 0,91 pour le RandomForest/XGBoost), avec des accuracies de l‚Äôordre de 0,85. Autrement dit, √† covariables HMDA comparables, les mod√®les non lin√©aires capturent beaucoup mieux la logique d‚Äôacceptation en p√©riode IA, ce qui est coh√©rent avec l‚Äôhypoth√®se d‚Äôune standardisation accrue des processus de scoring et d‚Äôun usage plus syst√©matique de signaux algorithmiques dans la d√©cision finale.

# %% [markdown]
# ## RQ3 ‚Äì Logit sur d√©faut proxy (default_proxy) ~ era + covariables
#
# Objectif :
# - Utiliser la variable default_proxy construite sur desc_df.
# - Estimer un logit de risque (proxy) en fonction de l‚Äô√®re (IA vs pr√©-IA) + contr√¥les loan_purpose / loan_type.
# - Exporter un tableau de coefficients (Table RQ3).
#
# NB : pour √©viter des probl√®mes de m√©moire, on √©chantillonne au maximum 1 000 000 d‚Äôobservations.

# %% [code]
import statsmodels.api as sm

# ------------------------------------------------------------
# 1. (Re)construction √©ventuelle de default_proxy dans desc_df
# ------------------------------------------------------------
rq3_df = desc_df.copy()

for col in ["rate_spread", "lien_status", "action_taken"]:
    rq3_df[col] = pd.to_numeric(rq3_df[col], errors="coerce")

if "default_proxy" not in rq3_df.columns:
    def build_default_proxy(row):
        # Actions "d√©favorables" (refus, retrait, etc.)
        if row["action_taken"] in [3, 4, 5, 6]:
            return 1
        # Spread tr√®s √©lev√©
        if pd.notna(row["rate_spread"]) and row["rate_spread"] > 3:
            return 1
        # Lien junior (second lien)
        if row["lien_status"] == 2:
            return 1
        return 0

    rq3_df["default_proxy"] = rq3_df.apply(build_default_proxy, axis=1)

rq3_df["default_proxy"] = rq3_df["default_proxy"].astype(int)

# ------------------------------------------------------------
# 2. Pr√©paration des variables explicatives
# ------------------------------------------------------------
rq3_df = rq3_df.dropna(subset=["default_proxy", "era", "loan_purpose", "loan_type"]).copy()

# Indicateur binaire era_IA
rq3_df["era_IA"] = (rq3_df["era"] == "IA").astype(int)

# √âchantillonnage pour limiter la taille
MAX_N = 1_000_000
if len(rq3_df) > MAX_N:
    rq3_sample = rq3_df.sample(n=MAX_N, random_state=42)
else:
    rq3_sample = rq3_df

print("Taille √©chantillon RQ3 pour le logit d√©faut proxy :", rq3_sample.shape)

# ------------------------------------------------------------
# 3. Construction de X et y pour statsmodels.Logit
# ------------------------------------------------------------
X_rq3 = pd.get_dummies(
    rq3_sample[["era_IA", "loan_purpose", "loan_type"]],
    columns=["loan_purpose", "loan_type"],
    drop_first=True
)
y_rq3 = rq3_sample["default_proxy"]

# Ajout de la constante et conversion explicite en float
X_rq3 = sm.add_constant(X_rq3, has_constant="add")
X_rq3 = X_rq3.astype(float)
y_rq3 = y_rq3.astype(float)

logit_rq3 = sm.Logit(y_rq3, X_rq3).fit(disp=False)

print("\n=== RQ3 ‚Äì Logit default_proxy ~ era_IA + controls ===")
print(logit_rq3.summary())

# ------------------------------------------------------------
# 4. Tableau des r√©sultats
# ------------------------------------------------------------
params = logit_rq3.params
bse = logit_rq3.bse
zvals = params / bse
pvals = logit_rq3.pvalues
conf_int = logit_rq3.conf_int()
conf_int.columns = ["[0.025]", "[0.975]"]

rq3_table = pd.DataFrame({
    "variable": params.index,
    "Coef.": params.values,
    "Std.Err.": bse.values,
    "z": zvals.values,
    "P>|z|": pvals.values,
    "[0.025]": conf_int["[0.025]"].values,
    "[0.975]": conf_int["[0.975]"].values
})

print("\n=== Table RQ3 ‚Äì Logit default_proxy (√©chantillon) ===")
display(rq3_table)

rq3_path = os.path.join(out_dir, "table_rq3_logit_default_proxy_era_controls.csv")
rq3_table.to_csv(rq3_path, index=False)
print("Table RQ3 sauvegard√©e dans :", rq3_path)


Taille √©chantillon RQ3 pour le logit d√©faut proxy : (1000000, 21)

=== RQ3 ‚Äì Logit default_proxy ~ era_IA + controls ===
                           Logit Regression Results                           
==============================================================================
Dep. Variable:          default_proxy   No. Observations:              1000000
Model:                          Logit   Df Residuals:                   999989
Method:                           MLE   Df Model:                           10
Date:                Fri, 28 Nov 2025   Pseudo R-squ.:                 0.01904
Time:                        01:49:35   Log-Likelihood:            -6.7840e+05
converged:                       True   LL-Null:                   -6.9157e+05
Covariance Type:            nonrobust   LLR p-value:                     0.000
=====================================================================================
                        coef    std err          z      P>|z|      [0.025      0.975]
-------------------------------------------------------------------------------------
const                -0.3020      0.004    -81.174      0.000      -0.309      -0.295
era_IA               -0.0264      0.014     -1.887      0.059      -0.054       0.001
loan_purpose_2.0      1.0203      0.008    122.459      0.000       1.004       1.037
loan_purpose_3.0      0.4496      0.004    100.989      0.000       0.441       0.458
loan_purpose_4.0      1.7734      0.055     32.068      0.000       1.665       1.882
loan_purpose_5.0      3.9959      0.357     11.191      0.000       3.296       4.696
loan_purpose_31.0     0.1906      0.026      7.393      0.000       0.140       0.241
loan_purpose_32.0     0.1287      0.028      4.620      0.000       0.074       0.183
loan_type_2.0         0.5100      0.006     91.233      0.000       0.499       0.521
loan_type_3.0         0.1831      0.014     13.560      0.000       0.157       0.210
loan_type_4.0         0.3023      0.030     10.153      0.000       0.244       0.361
=====================================================================================

=== Table RQ3 ‚Äì Logit default_proxy (√©chantillon) ===
variable	Coef.	Std.Err.	z	P>|z|	[0.025]	[0.975]
0	const	-0.301992	0.003720	-81.173623	0.000000e+00	-0.309283	-0.294700
1	era_IA	-0.026378	0.013981	-1.886667	5.920515e-02	-0.053781	0.001025
2	loan_purpose_2.0	1.020341	0.008332	122.458516	0.000000e+00	1.004011	1.036672
3	loan_purpose_3.0	0.449591	0.004452	100.988760	0.000000e+00	0.440866	0.458317
4	loan_purpose_4.0	1.773422	0.055302	32.067808	1.239706e-225	1.665032	1.881813
5	loan_purpose_5.0	3.995900	0.357052	11.191360	4.494854e-29	3.296090	4.695709
6	loan_purpose_31.0	0.190596	0.025781	7.392984	1.435692e-13	0.140067	0.241125
7	loan_purpose_32.0	0.128720	0.027863	4.619822	3.840689e-06	0.074111	0.183330
8	loan_type_2.0	0.509993	0.005590	91.233497	0.000000e+00	0.499037	0.520949
9	loan_type_3.0	0.183108	0.013504	13.559908	6.922313e-42	0.156641	0.209574
10	loan_type_4.0	0.302335	0.029777	10.153174	3.207597e-24	0.243972	0.360697
Table RQ3 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_rq3_logit_default_proxy_era_controls.csv
RQ3 ‚Äì Effet de l‚Äô√®re IA sur le proxy de d√©faut (default_proxy)
Pour la RQ3, on estime un mod√®le logit de la forme :


o√π :

default_proxy = 1 approxime un profil ‚Äúd√©grad√© / risqu√©‚Äù (actions 3‚Äì6, spread √©lev√©, lien junior),
era_IA = 1 si le dossier est en p√©riode IA, 0 sinon,
les contr√¥les incluent les dummies de loan_purpose et loan_type (r√©f√©rences : loan_purpose = 1.0, loan_type = 1.0).
Taille de l‚Äô√©chantillon pour l‚Äôestimation : 1 000 000 observations (√©chantillon al√©atoire de desc_df).

1. R√©sum√© des coefficients (Table RQ3)
Variable	Coef.	Std.Err.	z	p-value	[0.025]	[0.975]
const	-0.3020	0.0037	-81.17	< 0,001	-0.3093	-0.2947
era_IA	-0.0264	0.0140	-1.89	0,059	-0.0538	0.0010
loan_purpose_2.0	1.0203	0.0083	122.46	< 0,001	1.0040	1.0367
loan_purpose_3.0	0.4496	0.0045	100.99	< 0,001	0.4409	0.4583
loan_purpose_4.0	1.7734	0.0553	32.07	< 0,001	1.6650	1.8818
loan_purpose_5.0	3.9959	0.3571	11.19	< 0,001	3.2961	4.6957
loan_purpose_31.0	0.1906	0.0258	7.39	< 0,001	0.1401	0.2411
loan_purpose_32.0	0.1287	0.0279	4.62	< 0,001	0.0741	0.1833
loan_type_2.0	0.5100	0.0056	91.23	< 0,001	0.4990	0.5209
loan_type_3.0	0.1831	0.0135	13.56	< 0,001	0.1566	0.2096
loan_type_4.0	0.3023	0.0298	10.15	< 0,001	0.2440	0.3607
Pseudo R¬≤ (McFadden) : 0,019 (effet global modeste mais statistiquement significatif pour l‚Äôensemble des contr√¥les).
Variable d‚Äôint√©r√™t principale : era_IA (coefficient ‚àí0,0264, p ‚âà 0,059).
2. Effet de l‚Äô√®re IA sur le proxy de d√©faut
Le coefficient associ√© √† era_IA vaut :


En termes d‚Äôodds ratio :

√©

On obtient donc :

Comparaison	Coefficient	OR approx.	Interpr√©tation rapide
IA vs pr√©-IA	-0,026	‚âà 0,97	L√©g√®re baisse (‚âà 3 %) des odds de default_proxy, non significative √† 5 %
La p-value de 0,059 place l‚Äôeffet juste au-dessus du seuil usuel de 5 % :
on peut parler d‚Äôune tendance √† la baisse des odds de ‚Äúd√©faut proxy‚Äù en p√©riode IA,
mais l‚Äôeffet n‚Äôest pas significatif au seuil de 5 % (il le devient √† 10 % si tu utilises ce seuil dans la th√®se).
Substantiellement, m√™me si l‚Äôeffet de signe est favorable (IA ‚Üò d√©faut proxy), l‚Äôampleur est tr√®s modeste : une r√©duction d‚Äôenviron 3 % des odds, √† covariables loan_purpose et loan_type constantes.
3. R√¥le des motifs de pr√™t (loan_purpose)
Les coefficients sur loan_purpose sont, eux, tr√®s significatifs et de grande amplitude :

Par rapport au motif de r√©f√©rence (loan_purpose = 1.0, souvent achat de r√©sidence principale), certains motifs sont associ√©s √† des odds de d√©faut proxy beaucoup plus √©lev√©es :
loan_purpose_2.0 : coefficient ‚âà 1,02 ‚Üí OR ‚âà 2,77
loan_purpose_3.0 : coefficient ‚âà 0,45 ‚Üí OR ‚âà 1,57
loan_purpose_4.0 : coefficient ‚âà 1,77 ‚Üí OR ‚âà 5,89
loan_purpose_5.0 : coefficient ‚âà 4,00 ‚Üí OR ‚âà 54,4 (avec un intervalle de confiance large mais tr√®s au-dessus de 1).
Variable	Coef. approx.	OR approx.	Signal sur le risque (proxy)
loan_purpose_2.0	1,02	‚âà 2,8	odds de d√©faut proxy ‚âà 2,8√ó plus √©lev√©es
loan_purpose_3.0	0,45	‚âà 1,6	odds ‚âà 1,6√ó plus √©lev√©es
loan_purpose_4.0	1,77	‚âà 5,9	odds ‚âà 6√ó plus √©lev√©es
loan_purpose_5.0	3,99	>> 10	odds de d√©faut extr√™mement plus √©lev√©es (proxy tr√®s risqu√©)
Lecture rapide : la variabilit√© du proxy de d√©faut est beaucoup plus structur√©e par le motif de pr√™t que par le simple passage de la p√©riode pr√©-IA √† l‚Äô√®re IA. Certains segments de produits (par ex. refinancements sp√©cifiques, pr√™ts secondaires, motifs 4‚Äì5) concentrent une part disproportionn√©e de profils ‚Äú√† d√©faut proxy‚Äù.

4. R√¥le du type de pr√™t (loan_type)
Les dummies de loan_type sont √©galement significatives :

loan_type_2.0 : coef ‚âà 0,51 ‚Üí OR ‚âà 1,67
loan_type_3.0 : coef ‚âà 0,18 ‚Üí OR ‚âà 1,20
loan_type_4.0 : coef ‚âà 0,30 ‚Üí OR ‚âà 1,35
Variable	Coef. approx.	OR approx.	Interpr√©tation rapide
loan_type_2.0	0,51	‚âà 1,7	odds de d√©faut proxy ‚âà +67 % vs type 1
loan_type_3.0	0,18	‚âà 1,2	odds ‚âà +20 %
loan_type_4.0	0,30	‚âà 1,35	odds ‚âà +35 %
L√† encore, une grande part de la variation du proxy de d√©faut se joue √† l‚Äôint√©rieur de la composition produit (type de pr√™t), plut√¥t que dans un simple d√©calage global entre pr√©-IA et IA.

5. Formulation pr√™te pour la th√®se (RQ3, paragraphe de synth√®se)
Pour la RQ3, nous avons estim√© un mod√®le logit expliquant un proxy de d√©faut (combinaison d‚Äôactions d√©favorables, de spreads √©lev√©s et de liens juniors) par l‚Äô√®re d‚Äôobservation et une s√©rie de contr√¥les de composition (motif et type de pr√™t). Sur un √©chantillon d‚Äôun million de dossiers tir√©s de la base HMDA+ACS, le coefficient associ√© √† l‚Äô√®re IA est l√©g√®rement n√©gatif (‚Äì0,026 ; p ‚âà 0,059), ce qui correspond √† une r√©duction d‚Äôenviron 3 % des odds de d√©faut proxy par rapport √† la p√©riode pr√©-IA. Cet effet reste cependant modeste et n‚Äôest pas significatif au seuil de 5 %, ce qui sugg√®re qu‚Äôen moyenne, la transition vers l‚Äô√®re IA n‚Äôa pas fondamentalement modifi√© le niveau global de risque observ√© au travers de ce proxy.

En revanche, les coefficients attach√©s aux motifs et types de pr√™ts sont tr√®s √©lev√©s et syst√©matiquement significatifs : certains segments produit affichent des odds de d√©faut proxy de deux √† six fois sup√©rieures √† celles du motif de r√©f√©rence, et certains types de pr√™ts augmentent √©galement significativement la probabilit√© de basculer dans le proxy de d√©faut. Autrement dit, la variabilit√© du risque capt√© par ce proxy est principalement structur√©e par la composition des portefeuilles (motif/type de pr√™t), plus que par un simple effet de rupture temporelle entre pr√©-IA et IA.

# %% [markdown]
# ## RQ4 ‚Äì Fairness √©tendue : DI, Equal Opportunity, FNR, Calibration par race (IA)
#
# Hypoth√®ses :
# - y_test, y_pred_rf (√©tiquettes 0/1) et y_pred_proba_rf (probas) existent pour la cohorte IA.
# - race_test = ai_acs.loc[y_test.index, "derived_race"] a d√©j√† √©t√© construit (comme pour Table 6.3).
#
# Objectif :
# - Par race (IA) : calculer PP_rate, DI vs White, TPR, FNR, PPV, et une mesure simple de calibration.
# - Exporter un Tableau 6.4 √©tendu pour la th√®se.

# %% [code]
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, brier_score_loss

# ------------------------------------------------------------
# 0. V√©rifications de base
# ------------------------------------------------------------
if "ai_acs" not in globals():
    raise ValueError("Le DataFrame 'ai_acs' est introuvable ‚Äì ex√©cute la partie HMDA+ACS (IA) avant cette cellule.")

if "derived_race" not in ai_acs.columns:
    raise ValueError("La colonne 'derived_race' est absente de ai_acs ‚Äì impossible de calculer les fairness metrics par race.")

if "approved" not in ai_acs.columns:
    raise ValueError("La colonne 'approved' est absente de ai_acs ‚Äì impossible de d√©finir y_true.")

# ------------------------------------------------------------
# 1. Construction X / y pour le RF de fairness (cohorte IA compl√®te)
# ------------------------------------------------------------
fair_ml_cols = ["loan_purpose", "loan_type", "hoepa_status", "state_code", "year", "approved"]
fair_ml_cols = [c for c in fair_ml_cols if c in ai_acs.columns]

print("Colonnes utilis√©es pour le RF fairness (IA) :", fair_ml_cols)

fair_df = ai_acs[fair_ml_cols + ["derived_race"]].dropna(subset=["approved", "derived_race"]).copy()
fair_df["approved"] = fair_df["approved"].astype(int)

X_fair = pd.get_dummies(
    fair_df.drop(columns=["approved", "derived_race"]),
    drop_first=True
)
y_fair = fair_df["approved"]
race_fair = fair_df["derived_race"]

print("X_fair shape :", X_fair.shape, "| y_fair shape :", y_fair.shape)

# ------------------------------------------------------------
# 2. Entra√Ænement du RF de fairness sur toute la cohorte IA
# ------------------------------------------------------------
rf_fair = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)
rf_fair.fit(X_fair, y_fair)

y_pred_fair = rf_fair.predict(X_fair)
y_proba_fair = rf_fair.predict_proba(X_fair)[:, 1]

print("RF fairness entra√Æn√© sur la cohorte IA compl√®te.")

# ------------------------------------------------------------
# 3. Fonction utilitaire pour stats de confusion + calibration
# ------------------------------------------------------------
def group_stats(y_true, y_pred, y_proba, mask, min_n=50):
    n = int(mask.sum())
    if n < min_n:
        return None

    y_g = y_true[mask]
    yhat_g = y_pred[mask]
    p_g = y_proba[mask]

    cm = confusion_matrix(y_g, yhat_g)
    if cm.shape != (2, 2):
        return None
    tn, fp, fn, tp = cm.ravel()

    total = tn + fp + fn + tp
    pp_rate = (tp + fp) / total if total > 0 else np.nan
    tpr = tp / (tp + fn) if (tp + fn) > 0 else np.nan
    fnr = fn / (tp + fn) if (tp + fn) > 0 else np.nan
    ppv = tp / (tp + fp) if (tp + fp) > 0 else np.nan

    # Calibration simple : Brier score de groupe
    try:
        calib = brier_score_loss(y_g, p_g)
    except Exception:
        calib = np.nan

    return {
        "n": n,
        "PP_rate": pp_rate,
        "TPR": tpr,
        "FNR": fnr,
        "PPV": ppv,
        "Calibration_Brier": calib
    }

# ------------------------------------------------------------
# 4. Calcul des m√©triques par race (cohorte IA, RF_fair)
# ------------------------------------------------------------
group_rows = []
races = race_fair.dropna().unique()

for grp in races:
    mask = (race_fair == grp).values  # bool numpy
    stats = group_stats(y_fair.values, y_pred_fair, y_proba_fair, mask)
    if stats is None:
        group_rows.append({
            "Race": grp,
            "n": int(mask.sum()),
            "PP_rate": np.nan,
            "TPR": np.nan,
            "FNR": np.nan,
            "PPV": np.nan,
            "Calibration_Brier": np.nan
        })
        continue

    row = {
        "Race": grp,
        "n": stats["n"],
        "PP_rate": stats["PP_rate"],
        "TPR": stats["TPR"],
        "FNR": stats["FNR"],
        "PPV": stats["PPV"],
        "Calibration_Brier": stats["Calibration_Brier"]
    }
    group_rows.append(row)

fair_base = pd.DataFrame(group_rows)

# ------------------------------------------------------------
# 5. Normalisation vs White : DI, EO diff, FNR diff, PPV diff, Calibration diff
# ------------------------------------------------------------
ref_grp = "White"
if ref_grp not in list(fair_base["Race"]):
    raise ValueError("Groupe de r√©f√©rence 'White' absent ‚Äì impossible de normaliser les m√©triques.")

ref_row = fair_base[fair_base["Race"] == ref_grp].iloc[0]

fair_ext_rows = []
for _, row in fair_base.iterrows():
    di = row["PP_rate"] / ref_row["PP_rate"] if ref_row["PP_rate"] > 0 else np.nan
    eo_diff = row["TPR"] - ref_row["TPR"] if pd.notna(row["TPR"]) else np.nan
    fnr_diff = row["FNR"] - ref_row["FNR"] if pd.notna(row["FNR"]) else np.nan
    ppv_diff = row["PPV"] - ref_row["PPV"] if pd.notna(row["PPV"]) else np.nan
    calib_diff = row["Calibration_Brier"] - ref_row["Calibration_Brier"] if pd.notna(row["Calibration_Brier"]) else np.nan

    fair_ext_rows.append({
        "Race": row["Race"],
        "n": row["n"],
        "PP_rate": row["PP_rate"],
        "DisparateImpact_vs_White": di,
        "TPR": row["TPR"],
        "EqualOpportunityDiff_vs_White": eo_diff,
        "FNR": row["FNR"],
        "FNRDiff_vs_White": fnr_diff,
        "PPV": row["PPV"],
        "PredictiveParityDiff_vs_White": ppv_diff,
        "Calibration_Brier": row["Calibration_Brier"],
        "CalibrationDiff_vs_White": calib_diff
    })

fairness_extended = pd.DataFrame(fair_ext_rows)

print("\n=== Tableau 6.4 ‚Äì Fairness √©tendue RF par race (IA, r√©f = White) ===")
display(fairness_extended)

fair_ext_path = os.path.join(out_dir, "table_6_4_fairness_extended_rf_by_race_ia.csv")
fairness_extended.to_csv(fair_ext_path, index=False)
print("Tableau 6.4 sauvegard√© dans :", fair_ext_path)


Colonnes utilis√©es pour le RF fairness (IA) : ['loan_purpose', 'loan_type', 'hoepa_status', 'state_code', 'year', 'approved']
X_fair shape : (571820, 6) | y_fair shape : (571820,)
RF fairness entra√Æn√© sur la cohorte IA compl√®te.

=== Tableau 6.4 ‚Äì Fairness √©tendue RF par race (IA, r√©f = White) ===
Race	n	PP_rate	DisparateImpact_vs_White	TPR	EqualOpportunityDiff_vs_White	FNR	FNRDiff_vs_White	PPV	PredictiveParityDiff_vs_White	Calibration_Brier	CalibrationDiff_vs_White
0	Race Not Available	128484	0.517932	0.862654	0.784339	-0.127599	0.215661	0.127599	0.618940	-0.280617	0.211293	0.125880
1	White	351131	0.600394	1.000000	0.911938	0.000000	0.088062	0.000000	0.899557	0.000000	0.085413	0.000000
2	Black or African American	37503	0.489508	0.815310	0.911715	-0.000223	0.088285	0.000223	0.911864	0.012307	0.067875	-0.017538
3	Asian	42574	0.556302	0.926561	0.882695	-0.029243	0.117305	0.029243	0.911206	0.011648	0.099387	0.013974
4	Joint	8641	0.625969	1.042597	0.917369	0.005432	0.082631	-0.005432	0.905158	0.005601	0.090085	0.004672
5	2 or more minority races	723	0.435685	0.725664	0.902821	-0.009116	0.097179	0.009116	0.914286	0.014728	0.065763	-0.019650
6	Free Form Text Only	229	0.209607	0.349116	0.941176	0.029239	0.058824	-0.029239	1.000000	0.100443	0.038677	-0.046736
7	American Indian or Alaska Native	1557	0.434811	0.724208	0.904271	-0.007667	0.095729	0.007667	0.906942	0.007385	0.067477	-0.017936
8	Native Hawaiian or Other Pacific Islander	978	0.452965	0.754446	0.915138	0.003200	0.084862	-0.003200	0.900677	0.001120	0.063404	-0.022009
Tableau 6.4 sauvegard√© dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_6_4_fairness_extended_rf_by_race_ia.csv
6.4 Fairness √©tendue du mod√®le RF IA ‚Äì lecture d√©taill√©e du Tableau 6.4
Le Tableau 6.4 reporte, pour chaque groupe racial, un ensemble de m√©triques de fairness calcul√©es sur la cohorte IA (HMDA+ACS) √† partir du mod√®le Random Forest entra√Æn√© sur les seules variables structurelles (loan_purpose, loan_type, hoepa_status, state_code, year). Le groupe White sert de r√©f√©rence pour les m√©triques relatives (ratios et diff√©rences).

Pour m√©moire :

PP_rate : taux de pr√©diction positive (\Pr(\hat{Y}=1)) (proxy du Disparate Impact).
DisparateImpact_vs_White : ratio des PP_rate par rapport au groupe White.
TPR : True Positive Rate (sensibilit√©, Equal Opportunity).
EqualOpportunityDiff_vs_White : diff√©rence de TPR vs White.
FNR : False Negative Rate (= 1 - \text{TPR}).
FNRDiff_vs_White : diff√©rence de FNR vs White.
PPV : Positive Predictive Value (pr√©cision conditionnelle, Predictive Parity).
PredictiveParityDiff_vs_White : diff√©rence de PPV vs White.
Calibration_Brier : score de Brier par groupe (plus petit = meilleure calibration).
CalibrationDiff_vs_White : diff√©rence de Brier vs White.
6.4.1 Rappel chiffr√© des principaux groupes
On se focalise sur les groupes majoritaires (en effectif) :

Race	n	PP_rate	DI vs White	TPR	EO diff vs White	FNR	FNR diff vs White	PPV	PPV diff vs White	Brier	Calib diff vs White
White	351 131	0.6004	1.0000	0.9119	0.0000	0.0881	0.0000	0.8996	0.0000	0.0854	0.0000
Race Not Available	128 484	0.5179	0.8627	0.7843	-0.1276	0.2157	+0.1276	0.6189	-0.2806	0.2113	+0.1259
Black or African American	37 503	0.4895	0.8153	0.9117	-0.0002	0.0883	+0.0002	0.9119	+0.0123	0.0679	-0.0175
Asian	42 574	0.5563	0.9266	0.8827	-0.0292	0.1173	+0.0292	0.9112	+0.0116	0.0994	+0.0140
Joint	8 641	0.6260	1.0426	0.9174	+0.0054	0.0826	-0.0054	0.9052	+0.0056	0.0901	+0.0047
Les autres cat√©gories (Native Hawaiian, American Indian, 2+ minority races, Free Form Text Only) ont des effectifs nettement plus faibles et doivent √™tre interpr√©t√©es avec prudence.

6.4.2 Disparate Impact (DI) ‚Äì intensit√© de scoring par groupe
Le Disparate Impact est approch√© par le ratio des taux de pr√©diction positive (\text{PP_rate}) relativement √† White :

White : (\text{DI} = 1) (groupe de r√©f√©rence, PP_rate ‚âà 0,60).
Black or African American : (\text{DI} \approx 0,82) (PP_rate ‚âà 0,49).
Asian : (\text{DI} \approx 0,93) (PP_rate ‚âà 0,56).
Race Not Available : (\text{DI} \approx 0,86) (PP_rate ‚âà 0,52).
Joint : (\text{DI} \approx 1,04) (PP_rate ‚âà 0,63, l√©g√®rement sup√©rieur √† White).
En r√©f√©rence √† la ¬´ r√®gle des 80 % ¬ª (four-fifths rule), plusieurs groupes se situent en-dessous de 0,8‚Äì0,85 (par exemple, Black ‚âà 0,82, Race Not Available ‚âà 0,86, certains groupes minoritaires encore plus bas), ce qui sugg√®re une intensit√© de scoring plus faible (moins de pr√©dictions positives) que pour les emprunteurs blancs, √† profil structurel comparable.

6.4.3 Equal Opportunity (TPR/FNR) ‚Äì probabilit√© de ‚Äúcapturer‚Äù les bons profils
L‚ÄôEqual Opportunity se lit √† travers les TPR et FNR conditionnels :

White : TPR ‚âà 0,912, FNR ‚âà 0,088.
Black : TPR ‚âà 0,912, FNR ‚âà 0,088 ‚Äî quasi-identique √† White (diff√©rences de l‚Äôordre de 0,0002), ce qui sugg√®re qu‚Äô√† score structurel donn√©, le mod√®le ne p√©nalise pas particuli√®rement les dossiers approuv√©s noirs en termes de probabilit√© d‚Äô√™tre correctement class√©s.
Asian : TPR ‚âà 0,883, FNR ‚âà 0,117 ‚Äî soit une perte de sensibilit√© d‚Äôenviron 3 points par rapport √† White (EO diff ‚âà -0,029, FNR diff ‚âà +0,029).
Race Not Available : TPR ‚âà 0,784, FNR ‚âà 0,216 ‚Äî soit une d√©gradation tr√®s marqu√©e par rapport √† White (EO diff ‚âà -0,128, FNR diff ‚âà +0,128).
Autrement dit :

Pour les emprunteurs noirs, l‚ÄôEqual Opportunity est pratiquement align√©e sur celle des emprunteurs blancs.
En revanche, les dossiers avec race manquante (Race Not Available) subissent une probabilit√© plus √©lev√©e d‚Äô√™tre faussement n√©gatifs (non approuv√©s alors qu‚Äôils le sont en r√©alit√©), ce qui confirme le r√¥le probl√©matique des informations incompl√®tes dans la cha√Æne de scoring.
6.4.4 Predictive Parity (PPV) ‚Äì qualit√© de la s√©lection parmi les approuv√©s
La Predictive Parity se lit via la PPV (taux de ‚Äúbons‚Äù parmi les positifs) et les √©carts vs White :

White : PPV ‚âà 0,900 (r√©f√©rence).
Black : PPV ‚âà 0,912, soit un l√©g√®re sur-performance (+0,012) : les dossiers noirs que le mod√®le approuve semblent √™tre au moins aussi ‚Äúbons‚Äù (en termes de v√©rit√© terrain) que ceux des emprunteurs blancs.
Asian : PPV ‚âà 0,911 (+0,012) ‚Äî m√™me constat de slight sur-s√©lection.
Joint : PPV ‚âà 0,905 (+0,006) ‚Äî tr√®s proche de White.
Race Not Available : PPV ‚âà 0,619, soit un d√©ficit massif de pr√©cision (-0,281). Le mod√®le approuve beaucoup de dossiers de ce groupe qui se r√©v√®lent ex post incorrects, ce qui traduit un probl√®me de calibration et de bruit sur ces profils incomplets.
En synth√®se, le mod√®le est relativement √©quilibr√© en termes de Predictive Parity pour les grands groupes observables (White, Black, Asian, Joint). Les √©carts majeurs se concentrent sur le segment Race Not Available et, √† moindre √©chelle, sur certains sous-groupes rares.

6.4.5 Calibration par groupe ‚Äì Brier score
Le score de Brier synth√©tise la qualit√© de calibration des probabilit√©s pr√©dictives :

White : Brier ‚âà 0,085 (r√©f√©rence, calibration relativement bonne).
Black : Brier ‚âà 0,068 (diff√©rence ‚âà -0,018) ‚Äî la calibration est m√™me l√©g√®rement meilleure que pour White.
Asian : Brier ‚âà 0,099 (diff√©rence ‚âà +0,014) ‚Äî calibration un peu plus d√©grad√©e.
Race Not Available : Brier ‚âà 0,211 (diff√©rence ‚âà +0,126) ‚Äî calibration nettement d√©grad√©e, coh√©rente avec le faible PPV et l‚ÄôEO tr√®s d√©favorable.
Ces r√©sultats confirment que :

Le mod√®le RF IA est globalement bien calibr√© pour les groupes observables majoritaires (White, Black, Asian, Joint), avec des √©carts de calibration relativement mod√©r√©s.
La cat√©gorie Race Not Available cumule tous les signaux de risque de fairness : Disparate Impact d√©favorable, Equal Opportunity d√©t√©rior√©e, Predictive Parity faible et calibration tr√®s m√©diocre.
6.4.6 Lecture synth√©tique pour la th√®se
Une formulation possible (√† adapter dans le texte) :

¬´ Sur la cohorte IA (HMDA+ACS), le mod√®le Random Forest entra√Æn√© sur des covariables structurelles affiche des performances de fairness relativement convergentes entre emprunteurs blancs et noirs : les taux de vrais positifs, de faux n√©gatifs et la pr√©cision conditionnelle sont quasiment identiques, ce qui sugg√®re une forme d‚Äô‚Äúequal opportunity‚Äù et de ‚Äúpredictive parity‚Äù entre ces deux groupes sur le support consid√©r√©.
En revanche, les dossiers pour lesquels la race n‚Äôest pas renseign√©e constituent un sous-groupe particuli√®rement probl√©matique : ils pr√©sentent un Disparate Impact d√©favorable (ratio ‚âà 0,86), une sensibilit√© nettement inf√©rieure (TPR ‚âà 0,78 contre 0,91 pour les blancs), une probabilit√© de faux n√©gatif beaucoup plus √©lev√©e, une pr√©cision tr√®s d√©grad√©e (PPV ‚âà 0,62) et un score de Brier plus de deux fois sup√©rieur. Ces r√©sultats illustrent le fait que l‚Äô‚Äúopacit√©‚Äù des informations d√©mographiques, loin de neutraliser les biais, peut au contraire concentrer les risques de fairness sur des profils mal renseign√©s. ¬ª








