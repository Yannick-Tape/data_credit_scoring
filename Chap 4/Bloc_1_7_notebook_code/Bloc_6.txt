Voici le bloc 6 : "# %% [markdown]
# # 5. Tests statistiques classiques ‚Äì t-tests et ANOVA
#
# üîó R√©f√©rence th√®se :
# - Section 4.X : "Significance tests"
# - Utilisation de t-tests & ANOVA pour comparer les taux d‚Äôapprobation
#
# Objectif :
# - t-test : comparaison des taux d‚Äôapprobation pr√©-IA vs IA
# - ANOVA : differences de taux d‚Äôapprobation par race et par groupe de revenu
#
# Hypoth√®ses :
# - pre_ai, ai_hmda, ai_acs existent
# - 'approved' est une variable binaire (0/1)
# - 'derived_race' existe dans ai_acs
# - 'acs_median_income' existe dans ai_acs pour d√©finir income_group


# %%
from scipy import stats
import statsmodels.api as sm
import statsmodels.formula.api as smf

# 5.1. t-test sur les taux d‚Äôapprobation pr√©-IA vs IA

if "approved" in pre_ai.columns and "approved" in ai_hmda.columns:
    pre_approved = pre_ai["approved"].astype(float)
    ia_approved  = ai_hmda["approved"].astype(float)

    print("\n=== Test 5.1 ‚Äì t-test de Student sur les taux d‚Äôapprobation (pr√©-IA vs IA) ===")
    print(f"Pr√©-IA : mean = {pre_approved.mean():.3f}, n = {len(pre_approved):,}")
    print(f"IA     : mean = {ia_approved.mean():.3f}, n = {len(ia_approved):,}")

    t_stat, p_val = stats.ttest_ind(pre_approved, ia_approved, equal_var=False)
    print(f"\nStatistique t (Welch) = {t_stat:.3f}, p-value = {p_val:.3e}")
else:
    print("‚ö†Ô∏è Colonne 'approved' manquante dans pre_ai ou ai_hmda ‚Äì t-test non calcul√©.")

# 5.2. ANOVA : approbation ~ race (IA, HMDA+ACS)

if "approved" in ai_acs.columns and "derived_race" in ai_acs.columns:
    anova_race_df = ai_acs[["approved", "derived_race"]].dropna()
    anova_race_df["approved"] = anova_race_df["approved"].astype(float)

    print("\n=== Test 5.2 ‚Äì ANOVA (one-way) : approved ~ race (IA, HMDA+ACS) ===")
    model_race = smf.ols("approved ~ C(derived_race)", data=anova_race_df).fit()
    anova_race_table = sm.stats.anova_lm(model_race, typ=2)
    display(anova_race_table)

    anova_race_path = os.path.join(out_dir, "table_5_2_anova_approved_by_race_ia_acs.csv")
    anova_race_table.to_csv(anova_race_path)
    print("Table 5.2 ANOVA (race) sauvegard√©e dans :", anova_race_path)
else:
    print("‚ö†Ô∏è 'approved' ou 'derived_race' absent dans ai_acs ‚Äì ANOVA par race non calcul√©e.")

# 5.3. ANOVA : approbation ~ income_group (IA, HMDA+ACS)

if "approved" in ai_acs.columns and "acs_median_income" in ai_acs.columns:
    inc_df = ai_acs.copy()
    s_inc = pd.to_numeric(inc_df["acs_median_income"], errors="coerce")
    q1, q2 = s_inc.quantile([0.33, 0.66])

    def income_bucket(v):
        if pd.isna(v):
            return np.nan
        if v <= q1:
            return "Low"
        elif v <= q2:
            return "Middle"
        else:
            return "High"

    inc_df["income_group"] = s_inc.apply(income_bucket)

    anova_inc_df = inc_df[["approved", "income_group"]].dropna()
    anova_inc_df["approved"] = anova_inc_df["approved"].astype(float)

    print("\n=== Test 5.3 ‚Äì ANOVA (one-way) : approved ~ income_group (IA, HMDA+ACS) ===")
    model_inc = smf.ols("approved ~ C(income_group)", data=anova_inc_df).fit()
    anova_inc_table = sm.stats.anova_lm(model_inc, typ=2)
    display(anova_inc_table)

    anova_inc_path = os.path.join(out_dir, "table_5_3_anova_approved_by_income_group_ia_acs.csv")
    anova_inc_table.to_csv(anova_inc_path)
    print("Table 5.3 ANOVA (income_group) sauvegard√©e dans :", anova_inc_path)
else:
    print("‚ö†Ô∏è 'approved' ou 'acs_median_income' absent dans ai_acs ‚Äì ANOVA par revenu non calcul√©e.")

=== Test 5.1 ‚Äì t-test de Student sur les taux d‚Äôapprobation (pr√©-IA vs IA) ===
Pr√©-IA : mean = 0.707, n = 13,511,720
IA     : mean = 0.542, n = 569,500

Statistique t (Welch) = 244.866, p-value = 0.000e+00

=== Test 5.2 ‚Äì ANOVA (one-way) : approved ~ race (IA, HMDA+ACS) ===
sum_sq	df	F	PR(>F)
C(derived_race)	3422.931348	8.0	1766.377438	0.0
Residual	138508.746452	571811.0	NaN	NaN
Table 5.2 ANOVA (race) sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_5_2_anova_approved_by_race_ia_acs.csv

=== Test 5.3 ‚Äì ANOVA (one-way) : approved ~ income_group (IA, HMDA+ACS) ===
sum_sq	df	F	PR(>F)
C(income_group)	346.351540	2.0	698.996581	6.864380e-304
Residual	128949.192034	520483.0	NaN	NaN
Table 5.3 ANOVA (income_group) sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_5_3_anova_approved_by_income_group_ia_acs.csv
5.X Tests statistiques ‚Äì t-test et ANOVA (Tables 5.1‚Äì5.3)
5.X.1 Test 5.1 ‚Äì t-test sur les taux d‚Äôapprobation pr√©-IA vs IA
Le t-test de Student (version de Welch, variances in√©gales) compare les taux moyens d‚Äôapprobation entre les deux √®res :

√àre	Taux moyen d‚Äôapprobation	Effectif (n)
pr√©-IA	0,707 (‚âà 70,7 %)	13 511 720
IA	0,542 (‚âà 54,2 %)	569 500
Statistiques du test :

Statistique t (Welch) = 244,866
p-value = 0,000e+00 (‚â™ 0,001)
Lecture :

La diff√©rence brute de taux d‚Äôapprobation entre pr√©-IA et IA est d‚Äôenviron 16,5 points de pourcentage (70,7 % contre 54,2 %).
Le t-test de Welch renvoie une valeur absolue de t extr√™mement √©lev√©e (‚âà 245) avec une p-value num√©riquement nulle √† la pr√©cision machine, ce qui signifie que la diff√©rence de moyenne est hautement significative au sens statistique (p < 0,001).
Compte tenu des tailles d‚Äô√©chantillon (plus de 13,5 millions de dossiers pr√©-IA et plus de 0,5 million en IA), m√™me de petits √©carts seraient d√©tect√©s ; ici, l‚Äô√©cart est en plus substantiel en magnitude.
Dans la th√®se, on peut formuler que le taux d‚Äôapprobation moyen diminue significativement entre la p√©riode pr√©-IA et la p√©riode IA, ce qui justifie le recours √† des approches plus structur√©es (PSM, r√©gressions logistiques) pour d√©m√™ler ce qui rel√®ve d‚Äôun effet de composition et d‚Äôun √©ventuel effet propre de l‚Äô√®re IA.

5.X.2 Test 5.2 ‚Äì ANOVA : approved ~ race (IA, HMDA+ACS)
L‚ÄôANOVA one-way estime l‚Äôeffet de la race (derived_race) sur la probabilit√© d‚Äôapprobation dans la cohorte IA (HMDA+ACS).

Tableau ANOVA (r√©sum√©) :

Source	Sum of Squares	df	F	PR(>F)
C(derived_race)	3 422,93	8	1 766,38	0,0000
R√©sidu	138 508,75	571 811	‚Äî	‚Äî
Lecture :

Le facteur race (9 cat√©gories au total, dont White, Black, Asian, Joint, etc.) explique une partie significative de la variation de la variable approved :
La statistique F ‚âà 1 766,4 est tr√®s √©lev√©e.
La p-value PR(>F) = 0,0 (√† la pr√©cision machine) indique que l‚Äôhypoth√®se nulle ‚Äúm√™me taux d‚Äôapprobation moyen pour toutes les races‚Äù est fermement rejet√©e.
Avec plus de 570 000 observations, il est normal que l‚ÄôANOVA d√©tecte des √©carts, mais la taille de F sugg√®re que ces √©carts sont loin d‚Äô√™tre n√©gligeables.
En d‚Äôautres termes, dans la cohorte IA, les taux d‚Äôapprobation moyens diff√®rent significativement selon le groupe racial, ce qui est coh√©rent avec les √©carts observ√©s dans les m√©triques de fairness avanc√©e (Disparate Impact, Equal Opportunity, Predictive Parity) pr√©sent√©es au Tableau 6.3.
La Section 6.X s‚Äôappuiera sur ce constat pour documenter de mani√®re plus fine quels groupes sont d√©favoris√©s (par exemple, les emprunteurs Black ou certaines minorit√©s) par rapport au groupe de r√©f√©rence White.

5.X.3 Test 5.3 ‚Äì ANOVA : approved ~ income_group (IA, HMDA+ACS)
On consid√®re ici l‚Äôeffet du revenu de zone (ACS) sur la probabilit√© d‚Äôapprobation, via une variable income_group en trois cat√©gories (Low, Middle, High).

Tableau ANOVA :

Source	Sum of Squares	df	F	PR(>F)
C(income_group)	346,35	2	698,997	6,86√ó10‚Åª¬≥‚Å∞‚Å¥
R√©sidu	128 949,19	520 483	‚Äî	‚Äî
Lecture :

Le facteur income_group (tiers de revenu ACS : Low, Middle, High) a un effet statistiquement tr√®s significatif sur approved :
F ‚âà 699,0, avec une p-value ‚âà 6,9√ó10‚Åª¬≥‚Å∞‚Å¥, pratiquement nulle.
Cette ANOVA confirme ce que montrait d√©j√† le Tableau 4.X :
Les taux d‚Äôapprobation moyens sont les plus faibles dans le tertile Low, interm√©diaires dans le tertile Middle, et les plus √©lev√©s dans le tertile High.
Les diff√©rences ne sont donc pas seulement visibles en termes de moyenne descriptive, mais √©galement confirm√©es par un test global qui rejette l‚Äôhypoth√®se de taux identiques entre groupes de revenu.
Pour la r√©daction, on pourra r√©sumer que le revenu de zone (ACS median income) est fortement associ√© √† la probabilit√© d‚Äôapprobation en p√©riode IA : les demandeurs issus de zones √† revenu √©lev√© b√©n√©ficient d‚Äôun taux d‚Äôacceptation significativement plus √©lev√© que ceux des zones pauvres. Ce r√©sultat converge avec l‚Äôid√©e que les mod√®les d‚Äôoctroi int√®grent des proxies socio-√©conomiques du risque, ce qui soul√®ve des questions potentielles en termes d‚Äôin√©galit√©s territoriales.

5.X.4 Synth√®se des tests statistiques
Les trois tests convergent vers un diagnostic commun :

Diff√©rence inter-√®re (pr√©-IA vs IA)

Le t-test montre une baisse significative du taux d‚Äôapprobation moyen apr√®s l‚Äôintroduction de l‚Äô√®re IA.
H√©t√©rog√©n√©it√© par race (ANOVA race)

Les taux d‚Äôapprobation ne sont pas homog√®nes entre groupes raciaux dans la cohorte IA, ce qui justifie une analyse de fairness approfondie (Tableau 6.3).
H√©t√©rog√©n√©it√© par revenu de zone (ANOVA income_group)

Les taux d‚Äôapprobation varient significativement selon les tertiles de revenu ACS (Low / Middle / High), avec un gradient socio-√©conomique marqu√©.
Ces r√©sultats statistiques fournissent le socle des sections analytiques du chapitre : ils montrent que les diff√©rences observ√©es dans les descriptifs (par √®re, par race, par revenu) ne sont pas de simples artefacts d‚Äô√©chantillon, mais s‚Äôappuient sur des √©carts statistiquement robustes, que les sections PSM, ML et fairness viennent ensuite analyser de fa√ßon causale et normative.

# %% [markdown]
# # 6. RQ3 ‚Äì Default Risk (logit de d√©faut pr√©-IA vs IA)
#
# üîó R√©f√©rence th√®se :
# - Section 4.X / 6.X : "Default risk and post-origination performance"
# - RQ3 : Effet de l‚Äô√®re IA sur le risque de d√©faut
#
# ‚ö†Ô∏è IMPORTANT :
# Ce bloc fournit un SQUELETTE de code pour la mod√©lisation du d√©faut,
# mais il d√©pend d‚Äôune variable de d√©faut effectivement disponible
# dans tes donn√©es (par ex. 'default_flag' = 1 si d√©faut, 0 sinon).
#
# ‚ûú Tu devras adapter la liste `candidate_default_cols` aux noms
#    effectivement pr√©sents dans core/model/hmda_acs.
#
# Logique :
# - Chercher une variable de d√©faut dans `model` ou `core` ou `hmda_acs`
# - Construire un DataFrame avec : default_flag, era, race, income (si dispo)
# - Estimer un logit : default_flag ~ era + race + income_group


# %%
from sklearn.linear_model import LogisticRegression

# 6.1. Recherche d'une colonne de d√©faut dans les jeux de donn√©es disponibles

candidate_default_cols = [
    "default_flag",
    "ever_default",
    "perf_default_12m",
    "delinquent_90d",
    "delinquency_flag"
]

default_source = None
default_col = None

datasets = {
    "core": core if "core" in globals() else None,
    "model": model if "model" in globals() else None,
    "hmda_acs": hmda_acs if "hmda_acs" in globals() else None
}

for src_name, df_src in datasets.items():
    if df_src is None:
        continue
    for c in candidate_default_cols:
        if c in df_src.columns:
            default_source = src_name
            default_col = c
            break
    if default_source is not None:
        break

if default_source is None:
    print("‚ö†Ô∏è Aucune colonne de d√©faut trouv√©e dans core/model/hmda_acs.")
    print("   ‚ûú Adapte `candidate_default_cols` ci-dessus avec le vrai nom de ta variable de d√©faut.")
else:
    print(f"‚úÖ Variable de d√©faut trouv√©e : {default_col} dans {default_source}")

    df_def = datasets[default_source].copy()

    # On tente d'ajouter une info d'√®re si une colonne 'year' existe
    if "year" in df_def.columns:
        df_def["era"] = np.where(df_def["year"] < 2018, "pre_IA", "IA")
    elif "era" in df_def.columns:
        # si d√©j√† pr√©sent
        pass
    else:
        # Si pas d'info temporelle disponible, on ne peut pas faire pr√©-IA vs IA
        print("‚ö†Ô∏è Pas de variable 'year' ou 'era' dans la source de d√©faut ‚Äì RQ3 limit√© √† la seule p√©riode couverte.")
        df_def["era"] = "unknown"

    # On garde uniquement les colonnes utiles
    keep_cols = [default_col, "era"]
    if "derived_race" in df_def.columns:
        keep_cols.append("derived_race")
    if "acs_median_income" in df_def.columns:
        keep_cols.append("acs_median_income")
    if "approved" in df_def.columns:
        keep_cols.append("approved")

    df_def = df_def[keep_cols].copy()
    df_def = df_def.dropna(subset=[default_col])

    # Binarisation de la variable de d√©faut
    df_def["default_flag"] = df_def[default_col].astype(int)

    # Option : construction d'un income_group si ACS disponible
    if "acs_median_income" in df_def.columns:
        s_inc_def = pd.to_numeric(df_def["acs_median_income"], errors="coerce")
        q1_def, q2_def = s_inc_def.quantile([0.33, 0.66])

        def income_bucket_def(v):
            if pd.isna(v):
                return np.nan
            if v <= q1_def:
                return "Low"
            elif v <= q2_def:
                return "Middle"
            else:
                return "High"

        df_def["income_group"] = s_inc_def.apply(income_bucket_def)
    else:
        df_def["income_group"] = np.nan

    print("\nAper√ßu df_def (variables de d√©faut) :")
    display(df_def.head())

    # 6.2. Logit de d√©faut : default_flag ~ era (+ race + income_group si dispo)

    # On encode era + race + income_group si disponibles
    covariates = ["era"]
    if "derived_race" in df_def.columns:
        covariates.append("derived_race")
    if "income_group" in df_def.columns and df_def["income_group"].notna().any():
        covariates.append("income_group")

    X_def = pd.get_dummies(df_def[covariates], drop_first=True)
    y_def = df_def["default_flag"]

    print("\nCovariables utilis√©es pour le logit de d√©faut :", covariates)
    print("X_def shape :", X_def.shape)

    if X_def.shape[0] > 0 and X_def.shape[1] > 0:
        logit_def = LogisticRegression(max_iter=1000, n_jobs=-1)
        logit_def.fit(X_def, y_def)

        # On extrait les coefficients dans un DataFrame lisible
        coef_def = pd.DataFrame({
            "variable": ["Intercept"] + list(X_def.columns),
            "coef": np.concatenate(([logit_def.intercept_[0]], logit_def.coef_[0]))
        })

        print("\n=== Table 6.X ‚Äì Logit de d√©faut (default_flag ~ era + covariables) ===")
        display(coef_def)

        def_logit_path = os.path.join(out_dir, "table_6X_logit_default_flag_by_era_and_groups.csv")
        coef_def.to_csv(def_logit_path, index=False)
        print("Table 6.X (logit d√©faut) sauvegard√©e dans :", def_logit_path)
    else:
        print("‚ö†Ô∏è X_def vide ‚Äì impossible d‚Äôestimer le logit de d√©faut. V√©rifie tes covariables et ta source de d√©faut.")


‚ö†Ô∏è Aucune colonne de d√©faut trouv√©e dans core/model/hmda_acs.
   ‚ûú Adapte `candidate_default_cols` ci-dessus avec le vrai nom de ta variable de d√©faut.


# %% [code]
# ============================================================
# D√©tection automatique de la variable de d√©faut (PSM.4 / Chapitre 4‚Äì5)
# ============================================================

candidate_default_cols = [
    "default",
    "is_default",
    "ever_defaulted",
    "loan_status",
    "seriously_delinquent",
    "delinquency_status",
    "chargeoff",
    "foreclosure",
    "repossession",
    "loss_mitigation",
    "non_performing",
    "days_past_due",
    "dpd",
    "default_flag"
]

def detect_default_column(*dfs):
    """
    Parcourt les DataFrames fournis et tente d'identifier une variable de d√©faut plausible.
    Retourne le nom de la colonne ou None.
    """
    for df in dfs:
        for col in df.columns:
            col_l = col.lower()
            for cand in candidate_default_cols:
                if cand in col_l:
                    return col
    return None

# Recherche dans les bases principales
default_col = detect_default_column(core, model, hmda_acs, desc_df)

if default_col is None:
    print("‚ö†Ô∏è Aucune colonne de d√©faut trouv√©e automatiquement.")
    print("‚û°Ô∏è Tu peux forcer manuellement ainsi :")
    print("   default_col = 'NOM_DE_LA_COLONNE_DEFAUT'")
else:
    print(f"‚úÖ Colonne de d√©faut d√©tect√©e automatiquement : {default_col}")

# Exemple d'utilisation s√©curis√©e
if default_col is not None:
    # Harmonisation en binaire 0/1
    def_df = hmda_acs.copy()
    def_df[default_col] = pd.to_numeric(def_df[default_col], errors="coerce")

    # Cr√©ation d‚Äôun indicateur propre
    def_df["default_flag_clean"] = def_df[default_col].apply(
        lambda x: 1 if x is not None and x > 0 else 0
    )

    print("\nAper√ßu de la variable d√©faut nettoy√©e :")
    display(def_df["default_flag_clean"].value_counts(dropna=False))

# Flag de contr√¥le pour le reste du notebook
HAS_DEFAULT_VARIABLE = (default_col is not None)


‚ö†Ô∏è Aucune colonne de d√©faut trouv√©e automatiquement.
‚û°Ô∏è Tu peux forcer manuellement ainsi :
   default_col = 'NOM_DE_LA_COLONNE_DEFAUT'


# %% [code]
# ============================================================
# Construction d'une PROXY de d√©faut (HMDA-compliant)
# ============================================================

# Copie de travail
proxy_df = desc_df.copy()

# Conversion num√©rique s√ªre
proxy_df["rate_spread"] = pd.to_numeric(proxy_df["rate_spread"], errors="coerce")
proxy_df["lien_status"] = pd.to_numeric(proxy_df["lien_status"], errors="coerce")
proxy_df["action_taken"] = pd.to_numeric(proxy_df["action_taken"], errors="coerce")

# Heuristique de risque / d√©faut
# Crit√®res :
# - pr√™t refus√© OU retir√© OU refus post-acceptation
# - ou taux tr√®s √©lev√© (subprime proxy)
# - ou second lien (plus risqu√©)

def build_default_proxy(row):
    if row["action_taken"] in [3, 4, 5, 6]:
        return 1
    if pd.notna(row["rate_spread"]) and row["rate_spread"] > 3:
        return 1
    if row["lien_status"] == 2:
        return 1
    return 0

proxy_df["default_proxy"] = proxy_df.apply(build_default_proxy, axis=1)

# V√©rification
print("\n‚úÖ Aper√ßu de la variable proxy de d√©faut :\n")
display(proxy_df["default_proxy"].value_counts())

# V√©rification par √®re
default_proxy_by_era = (
    proxy_df
    .groupby("era")["default_proxy"]
    .mean()
    .reset_index()
    .rename(columns={"default_proxy": "default_rate_proxy"})
)

print("\n=== Tableau X ‚Äì Taux de d√©faut proxy par √®re ===")
display(default_proxy_by_era)

# Sauvegarde
proxy_path = os.path.join(out_dir, "table_default_proxy_by_era.csv")
default_proxy_by_era.to_csv(proxy_path, index=False)
print("‚úÖ Table sauvegard√©e dans :", proxy_path)

# Flag global
DEFAULT_PROXY_READY = True


‚úÖ Aper√ßu de la variable proxy de d√©faut :

default_proxy
1    7436305
0    6644915
Name: count, dtype: int64

=== Tableau X ‚Äì Taux de d√©faut proxy par √®re ===
era	default_rate_proxy
0	IA	0.493693
1	pre_IA	0.529551
‚úÖ Table sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_default_proxy_by_era.csv
5.X.5 Analyse du risque de d√©faut (proxy) par √®re ‚Äì Tableau X
Construction et rappel de la m√©trique
Faute de disposer d‚Äôune v√©ritable variable de d√©faut post-origination (par ex. statut de remboursement √† 12 ou 24 mois), le chapitre mobilise une proxy de risque de d√©faut construite √† partir des informations HMDA disponibles :

action_taken (dossier refus√©, retir√©, incomplet, etc.),
rate_spread (√©cart de taux par rapport √† un benchmark, indicateur de tarification ‚Äúsubprime‚Äù),
lien_status (rang de la s√ªret√©, second lien √©tant en g√©n√©ral plus risqu√©).
La variable binaire default_proxy est d√©finie comme suit :

default_proxy = 1 si :
le dossier est class√© dans une cat√©gorie d√©favorable (codes action_taken 3, 4, 5, 6), ou
le rate_spread d√©passe un seuil √©lev√© (ici > 3 points), ou
le pr√™t est en second lien (lien_status = 2) ;
default_proxy = 0 sinon.
Cette construction ne mesure pas le d√©faut ‚Äúr√©alis√©‚Äù au sens strict, mais capture une propension au risque (refus, profils subprime, conditions contractuelles plus risqu√©es) coh√©rente avec la litt√©rature cr√©dit.

L‚Äôaper√ßu global donne :

Valeur de default_proxy	Effectif
1 (profil √† risque √©lev√©)	7 436 305
0 (profil √† risque plus faible)	6 644 915
Soit un √©chantillon total de 14 081 220 dossiers.

Taux de d√©faut proxy par √®re (Tableau X)
Le Tableau X r√©sume le taux moyen de default_proxy = 1 par √®re :

√àre	Taux moyen de default_proxy
IA	0,4937 (‚âà 49,4 %)
pr√©-IA	0,5296 (‚âà 52,9 %)
Lecture :

En p√©riode pr√©-IA (2007‚Äì2017), environ 53 % des dossiers sont class√©s en ‚Äúprofil √† risque‚Äù selon cette proxy.
En p√©riode IA (2018‚Äì2023), cette proportion baisse √† environ 49 %.
La diff√©rence brute est de l‚Äôordre de ‚àí3,6 points de pourcentage :
ce qui sugg√®re, toutes choses √©gales par ailleurs au niveau descriptif, une l√©g√®re am√©lioration de la qualit√© moyenne des portefeuilles ou des crit√®res d‚Äôacceptation.
Dit autrement :

Sur l‚Äô√©chantillon, la transition vers l‚Äô√®re IA s‚Äôaccompagne d‚Äôune r√©duction mod√©r√©e de la part de dossiers class√©s ‚Äú√† risque √©lev√©‚Äù au sens de la proxy, passant d‚Äôenviron 53 % √† 49 %.

Mise en perspective avec les taux d‚Äôapprobation
Il est int√©ressant de mettre ce r√©sultat en regard du taux d‚Äôapprobation moyen (Table 4.3) :

Taux d‚Äôapprobation :
pr√©-IA : ‚âà 70,7 %
IA : ‚âà 54,2 %
Taux de ‚Äúd√©faut proxy‚Äù :
pr√©-IA : ‚âà 52,9 %
IA : ‚âà 49,4 %
Ce pattern est coh√©rent avec un r√©cit o√π :

L‚Äô√®re IA s‚Äôaccompagne d‚Äôun durcissement apparent de l‚Äôoctroi (baisse du taux d‚Äôapprobation de ~16 points).
Dans le m√™me temps, la proportion de dossiers class√©s en ‚Äúprofil risqu√©‚Äù diminue l√©g√®rement (~3‚Äì4 points), ce qui peut refl√©ter :
soit un screening plus strict en amont (les dossiers les plus risqu√©s sont √©cart√©s plus t√¥t),
soit une √©volution de la composition de la demande (candidats globalement plus solvables sur la p√©riode IA),
soit une combinaison des deux.
Ce r√©sultat reste purement descriptif et fond√© sur une proxy ; il ne d√©montre pas une am√©lioration ‚Äúr√©elle‚Äù des taux de d√©faut ex post, mais il est coh√©rent avec l‚Äôid√©e d‚Äôune s√©lectivit√© accrue et d‚Äôun profil moyen l√©g√®rement moins risqu√© dans les dossiers observ√©s en p√©riode IA.

Positionnement de ce bloc dans le chapitre
Dans la structure du chapitre :

Cette analyse peut servir de compl√©ment √† RQ1/RQ2/RQ3 en montrant que la baisse du taux d‚Äôapprobation s‚Äôaccompagne d‚Äôune disparition partielle des profils jug√©s √† risque (selon la proxy).
La dimension ‚Äúd√©faut proxy‚Äù pourra √™tre reprise :
soit en appendice comme analyse de robustesse (compte tenu du caract√®re approximatif de la proxy),
soit dans la discussion (Chapter 5) pour nourrir le d√©bat sur l‚Äôarbitrage entre acc√®s au cr√©dit et gestion du risque.
Si tu le souhaites, je peux maintenant g√©n√©rer :

un logit de default_proxy sur era + covariables (PSM.4/RQ3),
et/ou une d√©composition par race / revenu de default_proxy (fairness du risque).


# %% [markdown]
# ## RQ1 ‚Äì Logit d‚Äôapprobation par revenu (Low / Middle / High, cohorte IA)
#
# Objectif :
# - Construire une variable income_group (Low / Middle / High) sur la base de acs_median_income.
# - Estimer un logit : approved ~ C(income_group) (r√©f = High), cohorte IA uniquement (HMDA+ACS).
# - Exporter les coefficients dans un tableau pr√™t pour LaTeX (Table RQ1).

# %% [code]
import statsmodels.formula.api as smf

# ------------------------------------------------------------
# 1. Construction (ou reconstruction) de income_group dans ai_acs
# ------------------------------------------------------------
ai_income = ai_acs.copy()

if "income_group" not in ai_income.columns:
    if "acs_median_income" not in ai_income.columns:
        raise ValueError("acs_median_income manquant dans ai_acs ‚Äì impossible de construire income_group.")

    s_inc = pd.to_numeric(ai_income["acs_median_income"], errors="coerce")
    q1, q2 = s_inc.quantile([0.33, 0.66])

    def income_bucket(v):
        if pd.isna(v):
            return np.nan
        if v <= q1:
            return "Low"
        elif v <= q2:
            return "Middle"
        else:
            return "High"

    ai_income["income_group"] = s_inc.apply(income_bucket)

# On garde seulement les observations avec income_group non manquant
rq1_df = ai_income.dropna(subset=["approved", "income_group"]).copy()
rq1_df["approved"] = rq1_df["approved"].astype(int)

print("Taille de l'√©chantillon RQ1 (IA, income_group non manquant) :", rq1_df.shape)

# ------------------------------------------------------------
# 2. Estimation logit : approved ~ C(income_group) (r√©f = 'High')
# ------------------------------------------------------------
# On force la r√©f√©rence "High"
rq1_df["income_group"] = pd.Categorical(
    rq1_df["income_group"],
    categories=["High", "Middle", "Low"],
    ordered=False
)

formula_rq1 = "approved ~ C(income_group, Treatment(reference='High'))"
logit_rq1 = smf.logit(formula=formula_rq1, data=rq1_df).fit(disp=False)

print("\n=== RQ1 ‚Äì Logit d'approbation par groupe de revenu (IA, r√©f = High) ===")
print(logit_rq1.summary())

# ------------------------------------------------------------
# 3. Construction du tableau de r√©sultats
# ------------------------------------------------------------
params = logit_rq1.params
bse = logit_rq1.bse
zvals = params / bse
pvals = logit_rq1.pvalues
conf_int = logit_rq1.conf_int()
conf_int.columns = ["[0.025]", "[0.975]"]

rq1_table = pd.DataFrame({
    "variable": params.index,
    "Coef.": params.values,
    "Std.Err.": bse.values,
    "z": zvals.values,
    "P>|z|": pvals.values,
    "[0.025]": conf_int["[0.025]"].values,
    "[0.975]": conf_int["[0.975]"].values
})

print("\n=== Table RQ1 ‚Äì Logit approved ~ income_group (IA) ===")
display(rq1_table)

rq1_path = os.path.join(out_dir, "table_rq1_logit_approval_by_income_group_ia.csv")
rq1_table.to_csv(rq1_path, index=False)
print("Table RQ1 sauvegard√©e dans :", rq1_path)


Taille de l'√©chantillon RQ1 (IA, income_group non manquant) : (520486, 37)

=== RQ1 ‚Äì Logit d'approbation par groupe de revenu (IA, r√©f = High) ===
                           Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:               520486
Model:                          Logit   Df Residuals:                   520483
Method:                           MLE   Df Model:                            2
Date:                Fri, 28 Nov 2025   Pseudo R-squ.:                0.001942
Time:                        00:32:01   Log-Likelihood:            -3.5842e+05
converged:                       True   LL-Null:                   -3.5912e+05
Covariance Type:            nonrobust   LLR p-value:                1.156e-303
==========================================================================================================================
                                                             coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------------------
Intercept                                                  0.2855      0.005     59.443      0.000       0.276       0.295
C(income_group, Treatment(reference='High'))[T.Middle]    -0.1259      0.007    -18.469      0.000      -0.139      -0.113
C(income_group, Treatment(reference='High'))[T.Low]       -0.2541      0.007    -37.314      0.000      -0.267      -0.241
==========================================================================================================================

=== Table RQ1 ‚Äì Logit approved ~ income_group (IA) ===
variable	Coef.	Std.Err.	z	P>|z|	[0.025]	[0.975]
0	Intercept	0.285533	0.004803	59.443348	0.000000e+00	0.276118	0.294947
1	C(income_group, Treatment(reference='High'))[T...	-0.125947	0.006819	-18.468719	3.687273e-76	-0.139313	-0.112581
2	C(income_group, Treatment(reference='High'))[T...	-0.254081	0.006809	-37.314230	9.647591e-305	-0.267427	-0.240735
Table RQ1 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_rq1_logit_approval_by_income_group_ia.csv
RQ1 ‚Äì Effet du revenu de zone (ACS) sur la probabilit√© d‚Äôapprobation (IA)
Sur la cohorte IA (HMDA+ACS), on estime un mod√®le logit de la forme :


avec groupe de r√©f√©rence = High (tertile sup√©rieur du revenu ACS).

1. R√©sum√© des coefficients (Table RQ1)
Variable	Coef.	Std.Err.	z	p-value	[0.025]	[0.975]
Intercept (High income)	0.2855	0.0048	59.44	< 0,001	0.2761	0.2949
Middle vs High (C(income_group)[T.Middle])	-0.1259	0.0068	-18.47	‚âà 3.7√ó10‚Åª‚Å∑‚Å∂	-0.1393	-0.1126
Low vs High (C(income_group)[T.Low])	-0.2541	0.0068	-37.31	‚âà 9.6√ó10‚Åª¬≥‚Å∞‚Åµ	-0.2674	-0.2407
Nombre d‚Äôobservations : 520 486
Pseudo R¬≤ (McFadden) : 0,00194 (effet modeste mais significatif)
2. Interpr√©tation en termes d‚Äôodds ratios
On peut traduire les coefficients en odds ratios (OR) :



Comparaison	Coefficient	OR approx.	Interpr√©tation rapide
Middle vs High	-0.126	‚âà 0,88	odds d‚Äôapprobation ‚âà 12 % plus faibles qu‚Äôen High
Low vs High	-0.254	‚âà 0,78	odds d‚Äôapprobation ‚âà 22 % plus faibles qu‚Äôen High
3. Lecture substantielle (cohorte IA uniquement)
Le coefficient de r√©f√©rence (Intercept = 0,2855) correspond aux logs-odds d‚Äôapprobation pour les dossiers issus de zones High income.

En convertissant grossi√®rement :
 

soit un taux d‚Äôapprobation autour de 57 % pour les zones √† haut revenu, √† covariables maintenues constantes dans ce mod√®le simple.
Pour les zones Middle income, le coefficient est n√©gatif et fortement significatif :

La probabilit√© d‚Äôapprobation reste √©lev√©e, mais les odds sont r√©duites d‚Äôenviron 12 % par rapport aux zones High income.
Pour les zones Low income, l‚Äôeffet est encore plus marqu√© :

Un dossier situ√© dans une zone √† faible revenu a des odds d‚Äôapprobation environ 22 % plus faibles que dans une zone High income, toutes choses √©gales par ailleurs dans ce mod√®le (RQ1).
Tous les coefficients associ√©s aux groupes Middle et Low sont tr√®s significatifs (|z| ‚â´ 1,96, p-value ‚â™ 0,001), ce qui indique que ces √©carts ne sont pas dus au hasard statistique, mais refl√®tent un gradient de revenu net dans les d√©cisions d‚Äôoctroi en p√©riode IA.

4. Formulation pour la th√®se (exemple de phrase pr√™te √† l‚Äôemploi)
Sur la cohorte IA (HMDA+ACS), le mod√®le logit d‚Äôapprobation en fonction du revenu de zone (ACS) met en √©vidence un gradient socio-√©conomique marqu√©. √Ä covariables constantes, les demandes provenant de zones √† revenu moyen pr√©sentent des odds d‚Äôapprobation environ 12 % plus faibles que celles issues des zones √† revenu √©lev√© (coefficient ‚àí0,126 ; p < 0,001), tandis que les demandes originaires de zones √† faible revenu voient leurs odds d‚Äôapprobation r√©duites d‚Äôenviron 22 % (coefficient ‚àí0,254 ; p < 0,001). Ces r√©sultats confirment l‚Äôexistence d‚Äôune p√©nalisation syst√©matique des territoires les plus pauvres dans la phase IA, au-del√† de la simple baisse globale du taux d‚Äôapprobation.


# %% [markdown]
# ## Table 4.5 ‚Äì Performance compar√©e Logit / RandomForest / XGBoost par √®re
#
# Objectif :
# - Utiliser les colonnes communes ML pr√©-IA / IA.
# - Construire un encodage one-hot commun.
# - Pour chaque √®re et chaque mod√®le (Logit, RF, XGBoost si dispo) :
#     - train/test split (70/30)
#     - calcul : Accuracy, Precision, Recall, F1, AUC.
# - Exporter un tableau unique (Table 4.5).



# %% [code]
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    roc_auc_score, f1_score, accuracy_score,
    precision_score, recall_score
)

# ------------------------------------------------------------
# 1. Construction des features communes pr√©-IA / IA
# ------------------------------------------------------------
common_ml_cols = ["loan_purpose", "loan_type", "hoepa_status", "state_code", "year", "approved"]
common_ml_cols = [c for c in common_ml_cols if c in pre_ai.columns and c in ai_hmda.columns]

print("Colonnes ML communes pour Table 4.5 :", common_ml_cols)

pre_ml = pre_ai[common_ml_cols].copy()
ia_ml  = ai_hmda[common_ml_cols].copy()

pre_ml["era"] = "pre_IA"
ia_ml["era"]  = "IA"

ml_df = pd.concat([pre_ml, ia_ml], axis=0)
ml_df["approved"] = ml_df["approved"].astype(int)

X_all = pd.get_dummies(
    ml_df.drop(columns=["approved", "era"]),
    drop_first=True
)
y_all = ml_df["approved"]
era_all = ml_df["era"]

X_pre = X_all[era_all == "pre_IA"]
y_pre = y_all[era_all == "pre_IA"]

X_ia  = X_all[era_all == "IA"]
y_ia  = y_all[era_all == "IA"]

print("X_pre shape :", X_pre.shape, "| X_ia shape :", X_ia.shape)

# ------------------------------------------------------------
# 2. Fonction utilitaire pour √©valuer un mod√®le
# ------------------------------------------------------------
def eval_model(model, X, y, label_model, label_era):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    model.fit(X_train, y_train)
    y_proba = model.predict_proba(X_test)[:, 1]
    y_pred = (y_proba >= 0.5).astype(int)

    auc = roc_auc_score(y_test, y_proba)
    f1 = f1_score(y_test, y_pred)
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)

    return {
        "Model": label_model,
        "Era": label_era,
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1": f1,
        "AUC": auc
    }

rows_45 = []

# ------------------------------------------------------------
# 3. Mod√®les pour pr√©-IA
# ------------------------------------------------------------
logit_clf_pre = LogisticRegression(max_iter=1000, n_jobs=-1)
rf_clf_pre = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)

rows_45.append(eval_model(logit_clf_pre, X_pre, y_pre, "Logit", "pre_IA"))
rows_45.append(eval_model(rf_clf_pre, X_pre, y_pre, "RandomForest", "pre_IA"))

# XGBoost (si disponible)
try:
    from xgboost import XGBClassifier
    xgb_clf_pre = XGBClassifier(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        objective="binary:logistic",
        n_jobs=-1,
        eval_metric="logloss",
        random_state=42
    )
    rows_45.append(eval_model(xgb_clf_pre, X_pre, y_pre, "XGBoost", "pre_IA"))
except Exception as e:
    print("‚ö†Ô∏è XGBoost indisponible pour pre_IA :", repr(e))
    rows_45.append({
        "Model": "XGBoost",
        "Era": "pre_IA",
        "Accuracy": np.nan,
        "Precision": np.nan,
        "Recall": np.nan,
        "F1": np.nan,
        "AUC": np.nan
    })

# ------------------------------------------------------------
# 4. Mod√®les pour IA
# ------------------------------------------------------------
logit_clf_ia = LogisticRegression(max_iter=1000, n_jobs=-1)
rf_clf_ia = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)

rows_45.append(eval_model(logit_clf_ia, X_ia, y_ia, "Logit", "IA"))
rows_45.append(eval_model(rf_clf_ia, X_ia, y_ia, "RandomForest", "IA"))

try:
    from xgboost import XGBClassifier
    xgb_clf_ia = XGBClassifier(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        objective="binary:logistic",
        n_jobs=-1,
        eval_metric="logloss",
        random_state=42
    )
    rows_45.append(eval_model(xgb_clf_ia, X_ia, y_ia, "XGBoost", "IA"))
except Exception as e:
    print("‚ö†Ô∏è XGBoost indisponible pour IA :", repr(e))
    rows_45.append({
        "Model": "XGBoost",
        "Era": "IA",
        "Accuracy": np.nan,
        "Precision": np.nan,
        "Recall": np.nan,
        "F1": np.nan,
        "AUC": np.nan
    })

# ------------------------------------------------------------
# 5. Tableau 4.5
# ------------------------------------------------------------
table_45 = pd.DataFrame(rows_45)
print("\n=== Table 4.5 ‚Äì Performance compar√©e des mod√®les par √®re ===")
display(table_45)

table_45_path = os.path.join(out_dir, "table_4_5_model_performance_all_models.csv")
table_45.to_csv(table_45_path, index=False)
print("Table 4.5 sauvegard√©e dans :", table_45_path)

Colonnes ML communes pour Table 4.5 : ['loan_purpose', 'loan_type', 'hoepa_status', 'state_code', 'year', 'approved']
X_pre shape : (13511720, 9) | X_ia shape : (569500, 9)

=== Table 4.5 ‚Äì Performance compar√©e des mod√®les par √®re ===
Model	Era	Accuracy	Precision	Recall	F1	AUC
0	Logit	pre_IA	0.702805	0.708245	0.985489	0.824176	0.587551
1	RandomForest	pre_IA	0.707298	0.708812	0.994388	0.827659	0.615246
2	XGBoost	pre_IA	0.707296	0.708529	0.995337	0.827794	0.615223
3	Logit	IA	0.832122	0.809087	0.903689	0.853775	0.858830
4	RandomForest	IA	0.850875	0.844244	0.889054	0.866070	0.911454
5	XGBoost	IA	0.850904	0.844147	0.889270	0.866121	0.911420
Table 4.5 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_4_5_model_performance_all_models.csv
Table 4.5 ‚Äì Performance compar√©e des mod√®les (Logit vs RandomForest vs XGBoost) par √®re
La Table 4.5 r√©sume les performances pr√©dictives de trois familles de mod√®les de scoring (Logit, RandomForest, XGBoost) estim√©s s√©par√©ment sur la p√©riode pr√©-IA et sur la p√©riode IA, √† partir des m√™mes covariables HMDA (loan_purpose, loan_type, hoepa_status, state_code, year).

1. Rappel num√©rique de la Table 4.5
Mod√®le	√àre	Accuracy	Precision	Recall	F1	AUC
Logit	pr√©-IA	0,703	0,708	0,985	0,824	0,588
RandomForest	pr√©-IA	0,707	0,709	0,994	0,828	0,615
XGBoost	pr√©-IA	0,707	0,709	0,995	0,828	0,615
Logit	IA	0,832	0,809	0,904	0,854	0,859
RandomForest	IA	0,851	0,844	0,889	0,866	0,911
XGBoost	IA	0,851	0,844	0,889	0,866	0,911
(Valeurs arrondies √† trois d√©cimales pour la lecture.)

2. Comparaison des mod√®les √† l‚Äôint√©rieur de chaque √®re
P√©riode pr√©-IA
Accuracy :

Logit : 0,703
RF : 0,707
XGB : 0,707
‚ûú L√©g√®re am√©lioration des mod√®les d‚Äôarbres par rapport au Logit, mais l‚Äô√©cart reste modeste.
Recall (sensibilit√©) :

Logit : 0,985
RF : 0,994
XGB : 0,995
‚ûú Tous les mod√®les d√©tectent quasi tous les dossiers approuv√©s ; XGBoost pousse la sensibilit√© l√©g√®rement au-dessus du RF.
F1-score :

Logit : 0,824
RF : 0,828
XGB : 0,828
‚ûú Les mod√®les d‚Äôarbres am√©liorent un peu le compromis precision/recall, mais de fa√ßon incr√©mentale.
AUC :

Logit : 0,588
RF : 0,615
XGB : 0,615
‚ûú En termes de capacit√© √† ordonner les dossiers (ranking), RF et XGB dominent nettement le Logit en pr√©-IA.
‚ûú XGBoost n‚Äôapporte pas de gain substantiel suppl√©mentaire par rapport au RF sur cette sp√©cification (AUC quasi identiques).
Lecture pr√©-IA :
Les mod√®les non lin√©aires (RandomForest, XGBoost) extraient mieux l‚Äôinformation des variables HMDA que le Logit, surtout sur l‚ÄôAUC. N√©anmoins, le surcro√Æt de performance reste mod√©r√© et RF/XGB sont quasiment ex √¶quo.

P√©riode IA
Accuracy :

Logit : 0,832
RF : 0,851
XGB : 0,851
‚ûú Les mod√®les d‚Äôarbres gagnent environ 2 points d‚Äôaccuracy par rapport au Logit.
Precision :

Logit : 0,809
RF : 0,844
XGB : 0,844
‚ûú Parmi les dossiers pr√©dits comme approuv√©s, les mod√®les d‚Äôarbres se trompent nettement moins souvent que le Logit.
Recall :

Logit : 0,904
RF : 0,889
XGB : 0,889
‚ûú L√©g√®re baisse de la sensibilit√© pour les mod√®les d‚Äôarbres, au profit d‚Äôune meilleure pr√©cision.
F1-score :

Logit : 0,854
RF : 0,866
XGB : 0,866
‚ûú Sur le compromis global pr√©cision/sensibilit√©, RF et XGB dominent le Logit.
AUC :

Logit : 0,859
RF : 0,911
XGB : 0,911
‚ûú Les mod√®les d‚Äôarbres atteignent une excellente capacit√© de discrimination (AUC > 0,90), bien au-del√† du Logit.
Lecture IA :
En p√©riode IA, RandomForest et XGBoost offrent des performances tr√®s proches et consid√©rablement sup√©rieures au Logit. XGBoost ne surpasse pas vraiment RF, ce qui sugg√®re que, pour cette combinaison de features, l‚Äôessentiel du gain vient d√©j√† du passage √† une classe de mod√®les non lin√©aires √† base d‚Äôarbres.

3. Comparaison intertemporelle (pr√©-IA vs IA) pour chaque mod√®le
M√™me √† covariables identiques, les performances se transforment fortement entre les deux √®res :

Logit :

AUC : de ‚âà 0,59 (pr√©-IA) √† ‚âà 0,86 (IA),
Accuracy : de ‚âà 0,70 √† ‚âà 0,83.
RandomForest :

AUC : de ‚âà 0,62 (pr√©-IA) √† ‚âà 0,91 (IA),
Accuracy : de ‚âà 0,71 √† ‚âà 0,85.
XGBoost :

AUC : de ‚âà 0,62 (pr√©-IA) √† ‚âà 0,91 (IA),
Accuracy : de ‚âà 0,71 √† ‚âà 0,85.
Interpr√©tation g√©n√©rale : quelle que soit la famille de mod√®le, la pr√©visibilit√© des d√©cisions d‚Äôoctroi est nettement plus √©lev√©e en p√©riode IA qu‚Äôen p√©riode pr√©-IA. Cela peut refl√©ter des r√®gles d‚Äôacceptation plus homog√®nes, une meilleure qualit√© des donn√©es, ou une articulation plus √©troite entre les informations HMDA+ACS et les politiques internes de scoring en p√©riode IA.

4. Formulation pr√™te pour la th√®se (RQ2)
Pour la RQ2, la comparaison syst√©matique des performances du logit, du RandomForest et de XGBoost montre que la transition vers l‚Äô√®re IA s‚Äôaccompagne d‚Äôune forte am√©lioration de la pr√©visibilit√© des d√©cisions de cr√©dit. Sur la p√©riode pr√©-IA (2007‚Äì2017), les AUC demeurent modestes (‚âà 0,59 pour le logit, ‚âà 0,62 pour les mod√®les d‚Äôarbres), ce qui sugg√®re une structure d√©cisionnelle relativement diffuse. En revanche, sur la p√©riode IA (2018‚Äì2023), les m√™mes familles de mod√®les atteignent des AUC nettement sup√©rieures (‚âà 0,86 pour le logit et ‚âà 0,91 pour le RandomForest/XGBoost), avec des accuracies de l‚Äôordre de 0,85. Autrement dit, √† covariables HMDA comparables, les mod√®les non lin√©aires capturent beaucoup mieux la logique d‚Äôacceptation en p√©riode IA, ce qui est coh√©rent avec l‚Äôhypoth√®se d‚Äôune standardisation accrue des processus de scoring et d‚Äôun usage plus syst√©matique de signaux algorithmiques dans la d√©cision finale.

# %% [markdown]
# ## RQ3 ‚Äì Logit sur d√©faut proxy (default_proxy) ~ era + covariables
#
# Objectif :
# - Utiliser la variable default_proxy construite sur desc_df.
# - Estimer un logit de risque (proxy) en fonction de l‚Äô√®re (IA vs pr√©-IA) + contr√¥les loan_purpose / loan_type.
# - Exporter un tableau de coefficients (Table RQ3).
#
# NB : pour √©viter des probl√®mes de m√©moire, on √©chantillonne au maximum 1 000 000 d‚Äôobservations.

# %% [code]
import statsmodels.api as sm

# ------------------------------------------------------------
# 1. (Re)construction √©ventuelle de default_proxy dans desc_df
# ------------------------------------------------------------
rq3_df = desc_df.copy()

for col in ["rate_spread", "lien_status", "action_taken"]:
    rq3_df[col] = pd.to_numeric(rq3_df[col], errors="coerce")

if "default_proxy" not in rq3_df.columns:
    def build_default_proxy(row):
        # Actions "d√©favorables" (refus, retrait, etc.)
        if row["action_taken"] in [3, 4, 5, 6]:
            return 1
        # Spread tr√®s √©lev√©
        if pd.notna(row["rate_spread"]) and row["rate_spread"] > 3:
            return 1
        # Lien junior (second lien)
        if row["lien_status"] == 2:
            return 1
        return 0

    rq3_df["default_proxy"] = rq3_df.apply(build_default_proxy, axis=1)

rq3_df["default_proxy"] = rq3_df["default_proxy"].astype(int)

# ------------------------------------------------------------
# 2. Pr√©paration des variables explicatives
# ------------------------------------------------------------
rq3_df = rq3_df.dropna(subset=["default_proxy", "era", "loan_purpose", "loan_type"]).copy()

# Indicateur binaire era_IA
rq3_df["era_IA"] = (rq3_df["era"] == "IA").astype(int)

# √âchantillonnage pour limiter la taille
MAX_N = 1_000_000
if len(rq3_df) > MAX_N:
    rq3_sample = rq3_df.sample(n=MAX_N, random_state=42)
else:
    rq3_sample = rq3_df

print("Taille √©chantillon RQ3 pour le logit d√©faut proxy :", rq3_sample.shape)

# ------------------------------------------------------------
# 3. Construction de X et y pour statsmodels.Logit
# ------------------------------------------------------------
X_rq3 = pd.get_dummies(
    rq3_sample[["era_IA", "loan_purpose", "loan_type"]],
    columns=["loan_purpose", "loan_type"],
    drop_first=True
)
y_rq3 = rq3_sample["default_proxy"]

# Ajout de la constante et conversion explicite en float
X_rq3 = sm.add_constant(X_rq3, has_constant="add")
X_rq3 = X_rq3.astype(float)
y_rq3 = y_rq3.astype(float)

logit_rq3 = sm.Logit(y_rq3, X_rq3).fit(disp=False)

print("\n=== RQ3 ‚Äì Logit default_proxy ~ era_IA + controls ===")
print(logit_rq3.summary())

# ------------------------------------------------------------
# 4. Tableau des r√©sultats
# ------------------------------------------------------------
params = logit_rq3.params
bse = logit_rq3.bse
zvals = params / bse
pvals = logit_rq3.pvalues
conf_int = logit_rq3.conf_int()
conf_int.columns = ["[0.025]", "[0.975]"]

rq3_table = pd.DataFrame({
    "variable": params.index,
    "Coef.": params.values,
    "Std.Err.": bse.values,
    "z": zvals.values,
    "P>|z|": pvals.values,
    "[0.025]": conf_int["[0.025]"].values,
    "[0.975]": conf_int["[0.975]"].values
})

print("\n=== Table RQ3 ‚Äì Logit default_proxy (√©chantillon) ===")
display(rq3_table)

rq3_path = os.path.join(out_dir, "table_rq3_logit_default_proxy_era_controls.csv")
rq3_table.to_csv(rq3_path, index=False)
print("Table RQ3 sauvegard√©e dans :", rq3_path)


Taille √©chantillon RQ3 pour le logit d√©faut proxy : (1000000, 21)

=== RQ3 ‚Äì Logit default_proxy ~ era_IA + controls ===
                           Logit Regression Results                           
==============================================================================
Dep. Variable:          default_proxy   No. Observations:              1000000
Model:                          Logit   Df Residuals:                   999989
Method:                           MLE   Df Model:                           10
Date:                Fri, 28 Nov 2025   Pseudo R-squ.:                 0.01904
Time:                        01:49:35   Log-Likelihood:            -6.7840e+05
converged:                       True   LL-Null:                   -6.9157e+05
Covariance Type:            nonrobust   LLR p-value:                     0.000
=====================================================================================
                        coef    std err          z      P>|z|      [0.025      0.975]
-------------------------------------------------------------------------------------
const                -0.3020      0.004    -81.174      0.000      -0.309      -0.295
era_IA               -0.0264      0.014     -1.887      0.059      -0.054       0.001
loan_purpose_2.0      1.0203      0.008    122.459      0.000       1.004       1.037
loan_purpose_3.0      0.4496      0.004    100.989      0.000       0.441       0.458
loan_purpose_4.0      1.7734      0.055     32.068      0.000       1.665       1.882
loan_purpose_5.0      3.9959      0.357     11.191      0.000       3.296       4.696
loan_purpose_31.0     0.1906      0.026      7.393      0.000       0.140       0.241
loan_purpose_32.0     0.1287      0.028      4.620      0.000       0.074       0.183
loan_type_2.0         0.5100      0.006     91.233      0.000       0.499       0.521
loan_type_3.0         0.1831      0.014     13.560      0.000       0.157       0.210
loan_type_4.0         0.3023      0.030     10.153      0.000       0.244       0.361
=====================================================================================

=== Table RQ3 ‚Äì Logit default_proxy (√©chantillon) ===
variable	Coef.	Std.Err.	z	P>|z|	[0.025]	[0.975]
0	const	-0.301992	0.003720	-81.173623	0.000000e+00	-0.309283	-0.294700
1	era_IA	-0.026378	0.013981	-1.886667	5.920515e-02	-0.053781	0.001025
2	loan_purpose_2.0	1.020341	0.008332	122.458516	0.000000e+00	1.004011	1.036672
3	loan_purpose_3.0	0.449591	0.004452	100.988760	0.000000e+00	0.440866	0.458317
4	loan_purpose_4.0	1.773422	0.055302	32.067808	1.239706e-225	1.665032	1.881813
5	loan_purpose_5.0	3.995900	0.357052	11.191360	4.494854e-29	3.296090	4.695709
6	loan_purpose_31.0	0.190596	0.025781	7.392984	1.435692e-13	0.140067	0.241125
7	loan_purpose_32.0	0.128720	0.027863	4.619822	3.840689e-06	0.074111	0.183330
8	loan_type_2.0	0.509993	0.005590	91.233497	0.000000e+00	0.499037	0.520949
9	loan_type_3.0	0.183108	0.013504	13.559908	6.922313e-42	0.156641	0.209574
10	loan_type_4.0	0.302335	0.029777	10.153174	3.207597e-24	0.243972	0.360697
Table RQ3 sauvegard√©e dans : C:\Users\33669\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç—ã\data_credit_scoring\tri_state_ai\data_work\tables\table_rq3_logit_default_proxy_era_controls.csv
RQ3 ‚Äì Effet de l‚Äô√®re IA sur le proxy de d√©faut (default_proxy)
Pour la RQ3, on estime un mod√®le logit de la forme :


o√π :

default_proxy = 1 approxime un profil ‚Äúd√©grad√© / risqu√©‚Äù (actions 3‚Äì6, spread √©lev√©, lien junior),
era_IA = 1 si le dossier est en p√©riode IA, 0 sinon,
les contr√¥les incluent les dummies de loan_purpose et loan_type (r√©f√©rences : loan_purpose = 1.0, loan_type = 1.0).
Taille de l‚Äô√©chantillon pour l‚Äôestimation : 1 000 000 observations (√©chantillon al√©atoire de desc_df).

1. R√©sum√© des coefficients (Table RQ3)
Variable	Coef.	Std.Err.	z	p-value	[0.025]	[0.975]
const	-0.3020	0.0037	-81.17	< 0,001	-0.3093	-0.2947
era_IA	-0.0264	0.0140	-1.89	0,059	-0.0538	0.0010
loan_purpose_2.0	1.0203	0.0083	122.46	< 0,001	1.0040	1.0367
loan_purpose_3.0	0.4496	0.0045	100.99	< 0,001	0.4409	0.4583
loan_purpose_4.0	1.7734	0.0553	32.07	< 0,001	1.6650	1.8818
loan_purpose_5.0	3.9959	0.3571	11.19	< 0,001	3.2961	4.6957
loan_purpose_31.0	0.1906	0.0258	7.39	< 0,001	0.1401	0.2411
loan_purpose_32.0	0.1287	0.0279	4.62	< 0,001	0.0741	0.1833
loan_type_2.0	0.5100	0.0056	91.23	< 0,001	0.4990	0.5209
loan_type_3.0	0.1831	0.0135	13.56	< 0,001	0.1566	0.2096
loan_type_4.0	0.3023	0.0298	10.15	< 0,001	0.2440	0.3607
Pseudo R¬≤ (McFadden) : 0,019 (effet global modeste mais statistiquement significatif pour l‚Äôensemble des contr√¥les).
Variable d‚Äôint√©r√™t principale : era_IA (coefficient ‚àí0,0264, p ‚âà 0,059).
2. Effet de l‚Äô√®re IA sur le proxy de d√©faut
Le coefficient associ√© √† era_IA vaut :


En termes d‚Äôodds ratio :

√©

On obtient donc :

Comparaison	Coefficient	OR approx.	Interpr√©tation rapide
IA vs pr√©-IA	-0,026	‚âà 0,97	L√©g√®re baisse (‚âà 3 %) des odds de default_proxy, non significative √† 5 %
La p-value de 0,059 place l‚Äôeffet juste au-dessus du seuil usuel de 5 % :
on peut parler d‚Äôune tendance √† la baisse des odds de ‚Äúd√©faut proxy‚Äù en p√©riode IA,
mais l‚Äôeffet n‚Äôest pas significatif au seuil de 5 % (il le devient √† 10 % si tu utilises ce seuil dans la th√®se).
Substantiellement, m√™me si l‚Äôeffet de signe est favorable (IA ‚Üò d√©faut proxy), l‚Äôampleur est tr√®s modeste : une r√©duction d‚Äôenviron 3 % des odds, √† covariables loan_purpose et loan_type constantes.
3. R√¥le des motifs de pr√™t (loan_purpose)
Les coefficients sur loan_purpose sont, eux, tr√®s significatifs et de grande amplitude :

Par rapport au motif de r√©f√©rence (loan_purpose = 1.0, souvent achat de r√©sidence principale), certains motifs sont associ√©s √† des odds de d√©faut proxy beaucoup plus √©lev√©es :
loan_purpose_2.0 : coefficient ‚âà 1,02 ‚Üí OR ‚âà 2,77
loan_purpose_3.0 : coefficient ‚âà 0,45 ‚Üí OR ‚âà 1,57
loan_purpose_4.0 : coefficient ‚âà 1,77 ‚Üí OR ‚âà 5,89
loan_purpose_5.0 : coefficient ‚âà 4,00 ‚Üí OR ‚âà 54,4 (avec un intervalle de confiance large mais tr√®s au-dessus de 1).
Variable	Coef. approx.	OR approx.	Signal sur le risque (proxy)
loan_purpose_2.0	1,02	‚âà 2,8	odds de d√©faut proxy ‚âà 2,8√ó plus √©lev√©es
loan_purpose_3.0	0,45	‚âà 1,6	odds ‚âà 1,6√ó plus √©lev√©es
loan_purpose_4.0	1,77	‚âà 5,9	odds ‚âà 6√ó plus √©lev√©es
loan_purpose_5.0	3,99	>> 10	odds de d√©faut extr√™mement plus √©lev√©es (proxy tr√®s risqu√©)
Lecture rapide : la variabilit√© du proxy de d√©faut est beaucoup plus structur√©e par le motif de pr√™t que par le simple passage de la p√©riode pr√©-IA √† l‚Äô√®re IA. Certains segments de produits (par ex. refinancements sp√©cifiques, pr√™ts secondaires, motifs 4‚Äì5) concentrent une part disproportionn√©e de profils ‚Äú√† d√©faut proxy‚Äù.

4. R√¥le du type de pr√™t (loan_type)
Les dummies de loan_type sont √©galement significatives :

loan_type_2.0 : coef ‚âà 0,51 ‚Üí OR ‚âà 1,67
loan_type_3.0 : coef ‚âà 0,18 ‚Üí OR ‚âà 1,20
loan_type_4.0 : coef ‚âà 0,30 ‚Üí OR ‚âà 1,35
Variable	Coef. approx.	OR approx.	Interpr√©tation rapide
loan_type_2.0	0,51	‚âà 1,7	odds de d√©faut proxy ‚âà +67 % vs type 1
loan_type_3.0	0,18	‚âà 1,2	odds ‚âà +20 %
loan_type_4.0	0,30	‚âà 1,35	odds ‚âà +35 %
L√† encore, une grande part de la variation du proxy de d√©faut se joue √† l‚Äôint√©rieur de la composition produit (type de pr√™t), plut√¥t que dans un simple d√©calage global entre pr√©-IA et IA.

5. Formulation pr√™te pour la th√®se (RQ3, paragraphe de synth√®se)
Pour la RQ3, nous avons estim√© un mod√®le logit expliquant un proxy de d√©faut (combinaison d‚Äôactions d√©favorables, de spreads √©lev√©s et de liens juniors) par l‚Äô√®re d‚Äôobservation et une s√©rie de contr√¥les de composition (motif et type de pr√™t). Sur un √©chantillon d‚Äôun million de dossiers tir√©s de la base HMDA+ACS, le coefficient associ√© √† l‚Äô√®re IA est l√©g√®rement n√©gatif (‚Äì0,026 ; p ‚âà 0,059), ce qui correspond √† une r√©duction d‚Äôenviron 3 % des odds de d√©faut proxy par rapport √† la p√©riode pr√©-IA. Cet effet reste cependant modeste et n‚Äôest pas significatif au seuil de 5 %, ce qui sugg√®re qu‚Äôen moyenne, la transition vers l‚Äô√®re IA n‚Äôa pas fondamentalement modifi√© le niveau global de risque observ√© au travers de ce proxy.

En revanche, les coefficients attach√©s aux motifs et types de pr√™ts sont tr√®s √©lev√©s et syst√©matiquement significatifs : certains segments produit affichent des odds de d√©faut proxy de deux √† six fois sup√©rieures √† celles du motif de r√©f√©rence, et certains types de pr√™ts augmentent √©galement significativement la probabilit√© de basculer dans le proxy de d√©faut. Autrement dit, la variabilit√© du risque capt√© par ce proxy est principalement structur√©e par la composition des portefeuilles (motif/type de pr√™t), plus que par un simple effet de rupture temporelle entre pr√©-IA et IA.
"