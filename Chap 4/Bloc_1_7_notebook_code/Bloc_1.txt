je vais te l'envoyer par bloc (Bloc_1, Bloc_2, Bloc_3, Bloc_4, Bloc_5, Bloc_6, Bloc_7)et tu garderas tout le contenu de mon notebook en mÃ©moire. voici le Bloc 1 : "thÃ¨se :
# > Chapitre empirique : "AI-Driven Fair Creditworthiness and Credit Scoring:
# > A Two-Decade Analysis in the Tri-State Area (2007â€“2024)"


# 0. Imports # # Chapitre empirique â€“ Notebook maÃ®tre HMDA + ACS (Tri-State, 2007â€“2023)
#
# Ce notebook produit **tous les tableaux et graphiques** mentionnÃ©s dans le chapitre :
# - Comparaison des cohortes prÃ©-IA (2007â€“2017) vs IA (2018â€“2023)
# - ModÃ¨les logit "miroirs"
# - Analyses ACS (hmda_acs_tristate_2018_2023_FINAL)
# - ModÃ¨les ML (RF / XGBoost) et premiÃ¨res mÃ©triques de fairness
#
# ğŸ”— RÃ©fÃ©rence et configuration globale

import os
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt

import statsmodels.api as sm
import statsmodels.formula.api as smf

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# XGBoost est optionnel : installe-le si besoin via `pip install xgboost`
try:
    from xgboost import XGBClassifier
    HAS_XGBOOST = True
except ImportError:
    HAS_XGBOOST = False

plt.style.use("default")

# Pour que les DataFrames s'affichent proprement
pd.set_option("display.max_columns", 100)
pd.set_option("display.width", 160)

# Chemin de travail (adapter si nÃ©cessaire)
BASE_DIR = r"C:\Users\33669\OneDrive\Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹\data_credit_scoring\tri_state_ai\data_work"

CORE_PATH  = os.path.join(BASE_DIR, "hmda_tristate_core_2007_2024_v2.parquet")
MODEL_PATH = os.path.join(BASE_DIR, "hmda_tristate_model_2018_2023_FIXED.parquet")
ACS_PATH   = os.path.join(BASE_DIR, "hmda_acs_tristate_2018_2023_FINAL.parquet")
## 1. Chargement des trois bases et sanity checks
#
# ğŸ”— RÃ©fÃ©rence chapitre :
# - Section 1.1 et 1.2 : "PrÃ©sentation des sources" et "Construction des cohortes"
# - Tableau 1.1 : Vue d'ensemble des trois bases

# 1.1. Chargement des fichiers Parquet

core = pd.read_parquet(CORE_PATH)
model = pd.read_parquet(MODEL_PATH)
hmda_acs = pd.read_parquet(ACS_PATH)

print("core shape :", core.shape)
print("model shape:", model.shape)
print("acs shape  :", hmda_acs.shape)
core shape : (14163286, 12)
model shape: (571820, 15)
acs shape  : (571820, 35)
# 1.2. AperÃ§u des colonnes principales pour vÃ©rifier la cohÃ©rence
# (On imprime quelques colonnes clÃ©s seulement)

def quick_cols(df, name, n=30):
    print(f"\n=== {name} â€“ colonnes (top {n}) ===")
    print(list(df.columns[:n]))

quick_cols(core, "CORE 2007â€“2024")
quick_cols(model, "MODEL 2018â€“2023")
quick_cols(hmda_acs, "HMDA+ACS 2018â€“2023") 


=== CORE 2007â€“2024 â€“ colonnes (top 30) ===
['action_taken', 'applicant_sex', 'county_code', 'hoepa_status', 'lien_status', 'loan_purpose', 'loan_type', 'preapproval', 'purchaser_type', 'rate_spread', 'state_code', 'year']

=== MODEL 2018â€“2023 â€“ colonnes (top 30) ===
['year', 'state_code', 'county_code', 'census_tract', 'geoid_tract', 'loan_amount', 'loan_purpose', 'loan_type', 'lien_status', 'hoepa_status', 'action_taken', 'applicant_sex', 'derived_ethnicity', 'derived_race', 'approved']

=== HMDA+ACS 2018â€“2023 â€“ colonnes (top 30) ===
['year', 'state_code', 'county_code', 'census_tract', 'geoid_tract', 'loan_amount', 'loan_purpose', 'loan_type', 'lien_status', 'hoepa_status', 'action_taken', 'applicant_sex', 'derived_ethnicity', 'derived_race', 'approved', 'NAME', 'acs_median_income', 'acs_pop_total', 'acs_white', 'acs_black', 'acs_asian', 'acs_hispanic', 'acs_unemployed', 'acs_labor_force', 'acs_poverty_num', 'acs_poverty_den', 'state', 'county', 'tract', 'acs_poverty_rate']

## 2. Construction des cohortes prÃ©-IA vs IA
#
# ğŸ”— RÃ©fÃ©rence chapitre :
# - Section 1.2 : "Construction des deux cohortes"
# - Graphique 0.1 : chronologie avec la coupure 2017/2018
#
# Cohortes :
# - pre_ai : annÃ©es 2007â€“2017 dans la base `core`
# - ai_hmda : annÃ©es 2018â€“2023 dans la base `model`
# - ai_acs : annÃ©es 2018â€“2023 dans la base fusionnÃ©e HMDA+ACS

# 2.1. On suppose que la variable d'annÃ©e s'appelle "year" dans les trois bases.
# Adapter si besoin (ex: "activity_year", etc.)

# Filtre prÃ©-IA (2007â€“2017)
pre_ai = core[(core["year"] >= 2007) & (core["year"] <= 2017)].copy()

# Cohorte IA HMDA-only (le fichier 'model' est dÃ©jÃ  restreint Ã  2018â€“2023)
ai_hmda = model.copy()

# Cohorte IA HMDA+ACS fusionnÃ©e
ai_acs = hmda_acs.copy()

for name, df in [("pre_ai", pre_ai), ("ai_hmda", ai_hmda), ("ai_acs", ai_acs)]:
    print(f"{name} â€“ shape: {df.shape}, annÃ©es uniques: {sorted(df['year'].unique())}")

pre_ai â€“ shape: (13512746, 12), annÃ©es uniques: [np.float64(2007.0), np.float64(2008.0), np.float64(2009.0), np.float64(2010.0), np.float64(2011.0), np.float64(2012.0), np.float64(2013.0), np.float64(2014.0), np.float64(2015.0), np.float64(2016.0), np.float64(2017.0)]
ai_hmda â€“ shape: (571820, 15), annÃ©es uniques: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]
ai_acs â€“ shape: (571820, 35), annÃ©es uniques: [np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023)]

## 3. Analyse descriptive â€“ Taux d'approbation et profils de demandeurs
#
# ğŸ”— RÃ©fÃ©rence chapitre :
# - Section 2.1 : "Taux dâ€™approbation"
# - Section 2.2 : "Profil socio-Ã©conomique"
# - Figures 2.1â€“2.4 et Tableaux 2.1â€“2.2
#
# HypothÃ¨se :
# - La variable d'approbation est `approved` (0/1) ou dÃ©rivÃ©e de "action_taken".

# 3.1. Si la variable "approved" n'existe pas encore, on la crÃ©e Ã  partir d'action_taken.
# Exemple : HMDA moderne -> action_taken = 1 (loan originated) => approved = 1

def ensure_approved_flag(df, action_col="action_taken", approved_col="approved"):
    """
    CrÃ©e une variable binaire 'approved' si elle n'existe pas,
    en se basant sur 'action_taken' (HMDA).
    """
    if approved_col in df.columns:
        return df
    df = df.copy()
    # Exemple : 1 = loan originated, 2/3 = applications approved but not accepted ?
    # Ici on code : 1, 2, 3 => 1 ; le reste => 0
    df[approved_col] = df[action_col].isin([1, 2, 3]).astype(int)
    return df

pre_ai = ensure_approved_flag(pre_ai)
ai_hmda = ensure_approved_flag(ai_hmda)
ai_acs = ensure_approved_flag(ai_acs)


print("pre_ai")
pre_ai["approved"].value_counts(normalize=True).head()

pre_ai
approved
1    0.706829
0    0.293171
Name: proportion, dtype: float64

print("ai_hmda")
ai_hmda["approved"].value_counts(normalize=True).head()


ai_hmda
approved
1    0.542304
0    0.457696
Name: proportion, dtype: float64


print("ai_acs")
ai_acs["approved"].value_counts(normalize=True).head()

ai_acs
approved
1    0.542304
0    0.457696
Name: proportion, dtype: float64


'''
Ã€ un niveau agrÃ©gÃ©, la comparaison entre les deux rÃ©gimes met en Ã©vidence une rupture 
nette dans lâ€™intensitÃ© globale de lâ€™octroi de crÃ©dit. Sur la pÃ©riode prÃ©-IA (2007â€“2017), 
la proportion moyenne de demandes approuvÃ©es dans la cohorte pre_ai sâ€™Ã©lÃ¨ve Ã  environ 70,7 %, 
contre 54,2 % seulement dans la cohorte ai_hmda (2018â€“2023), soit une baisse de plus de 16 points 
de pourcentage. Autrement dit, le rÃ©gime dÃ©cisionnel associÃ© Ã  la phase de gÃ©nÃ©ralisation des outils 
algorithmiques opÃ¨re dans un environnement globalement plus restrictif en termes dâ€™approbation brute 
des demandes. Cette observation ne constitue pas en soi une preuve causale de lâ€™impact de lâ€™IA, mais 
elle suggÃ¨re que le passage dâ€™un rÃ©gime prÃ©-algorithmique, plus gÃ©nÃ©reux en volume dâ€™approbations, Ã  
un rÃ©gime post-algorithmique, plus sÃ©lectif, sâ€™accompagne dâ€™un resserrement structurel de lâ€™accÃ¨s au crÃ©dit, 
qui doit Ãªtre examinÃ© de maniÃ¨re plus fine dans les sections suivantes, en particulier sous lâ€™angle des 
disparitÃ©s raciales et territoriales.
'''

# 3.2. Taux d'approbation annuel sur 2007â€“2023 (base core)
# ğŸ”— Graphique 2.1 â€“ "Taux d'approbation, 2007â€“2023"

core = ensure_approved_flag(core)
approval_year = (
    core.groupby("year")["approved"]
    .mean()
    .reset_index()
    .rename(columns={"approved": "approval_rate"})
)

fig, ax = plt.subplots(figsize=(8, 4))
ax.plot(approval_year["year"], approval_year["approval_rate"], marker="o")
ax.axvline(2017.5, color="red", linestyle="--", label="Rupture 2017/2018 (IA)")
ax.set_title("Taux d'approbation moyen â€“ Tri-State, 2007â€“2023")
ax.set_ylabel("Taux d'approbation")
ax.set_xlabel("AnnÃ©e")
ax.legend()
plt.tight_layout()
plt.show()

approval_year.head()

'''
  # InterprÃ©tation du Graphique 2.1 â€“ Taux dâ€™approbation moyen (2007â€“2023)

Le Graphique 2.1 retrace lâ€™Ã©volution du taux dâ€™approbation moyen des demandes 
de prÃªts hypothÃ©caires dans la rÃ©gion Tri-State sur la pÃ©riode 2007â€“2023. La sÃ©rie 
met en Ã©vidence un niveau initialement Ã©levÃ© des taux dâ€™approbation en 2007 et 2008, 
oscillant autour de 72 %, avant de connaÃ®tre une rupture nette en 2009, annÃ©e marquÃ©e par 
lâ€™intensification de la crise financiÃ¨re mondiale. Cette chute, qui ramÃ¨ne le taux dâ€™approbation 
Ã  environ 67 %, traduit un durcissement brutal des conditions dâ€™octroi du crÃ©dit, consÃ©cutif aux 
pertes massives des institutions financiÃ¨res et aux modifications rapides de leurs politiques de gestion du risque.

Ã€ partir de 2010, on observe une phase de stabilisation progressive du taux dâ€™approbation, qui se 
maintient autour de 70 %. Cette relative normalisation rÃ©vÃ¨le lâ€™installation dâ€™un nouvel Ã©quilibre 
post-crise, caractÃ©risÃ© par des standards prudentiels plus stricts et une surveillance rÃ©glementaire renforcÃ©e. 
Cette pÃ©riode constitue ainsi une transition entre un rÃ©gime de dÃ©cision majoritairement fondÃ© sur lâ€™Ã©valuation 
humaine et des systÃ¨mes de scoring statistiques relativement simples, vers un environnement plus structurÃ© et encadrÃ©.

Enfin, la ligne verticale matÃ©rialisant la rupture 2017/2018 permet dâ€™introduire visuellement le basculement 
vers ce que cette Ã©tude qualifie de Â« rÃ©gime algorithmique Â». Cette sÃ©paration graphique ne prÃ©tend pas identifier 
une rupture instantanÃ©e des pratiques, mais sert de repÃ¨re analytique pour comparer deux architectures 
dÃ©cisionnelles : un systÃ¨me prÃ©-algorithmique, dominÃ© par lâ€™intervention humaine et les rÃ¨gles internes, 
et un systÃ¨me post-algorithmique, caractÃ©risÃ© par lâ€™intÃ©gration progressive dâ€™outils automatisÃ©s et de modÃ¨les 
dâ€™apprentissage automatique. Le graphique constitue ainsi un Ã©lÃ©ment clÃ© pour comprendre le cadre temporel de 
lâ€™analyse comparative dÃ©veloppÃ©e dans les sections suivantes.
'''

0	2007.0	0.717529
1	2008.0	0.721486
2	2009.0	0.673220
3	2010.0	0.699725
4	2011.0	0.700351

# 3.3. Tableau 2.1 â€“ Taux d'approbation moyen par cohorte et par Ã‰tat (si 'state' ou Ã©quivalent existe)

if "state" in core.columns:
    approval_by_state = (
        core.groupby(["state", pd.cut(core["year"], [2006, 2017, 2023],
                                      labels=["pre_IA", "IA"])])["approved"]
        .mean()
        .unstack()
    )
    display(approval_by_state)

    # Sauvegarde Ã©ventuelle pour LaTeX
    out_dir = os.path.join(BASE_DIR, "tables")
    os.makedirs(out_dir, exist_ok=True)
    approval_by_state.to_csv(os.path.join(out_dir, "table_2_1_approval_by_state.csv"))


# Dictionnaire FIPS -> Nom de l'Ã‰tat
state_fips_to_name = {
    9: "Connecticut",
    34: "New Jersey",
    36: "New York"
}

# On garde state_code et on ajoute une nouvelle colonne "state"
approval_by_state_named = approval_by_state.copy()

# CrÃ©ation de la colonne lisible "state"
approval_by_state_named["state"] = (
    approval_by_state_named.index
        .astype(int)
        .map(state_fips_to_name)
)

# RÃ©organisation : state_code reste l'index, state devient une colonne
approval_by_state_named = approval_by_state_named.reset_index()

# Affichage propre
display(approval_by_state_named)

'''
# Commentaire du Tableau 2.1 â€“ Taux dâ€™approbation par Ã‰tat (pÃ©riode prÃ©-IA, 2007â€“2017)
Le Tableau 2.1 met en Ã©vidence des diffÃ©rences substantielles dans les taux dâ€™approbation moyens 
des demandes de prÃªts hypothÃ©caires entre les Ã‰tats de la rÃ©gion Tri-State au cours de la pÃ©riode 
prÃ©-algorithmique. Lâ€™Ã‰tat de New York affiche le taux dâ€™approbation le plus Ã©levÃ© (environ 73 %), 
suivi du Connecticut (environ 70 %), tandis que le New Jersey prÃ©sente le niveau dâ€™approbation le 
plus faible (environ 68 %). Ces Ã©carts, bien que relativement modestes en amplitude, traduisent des 
hÃ©tÃ©rogÃ©nÃ©itÃ©s structurelles persistantes dans les pratiques locales dâ€™octroi de crÃ©dit, qui peuvent 
reflÃ©ter des diffÃ©rences institutionnelles entre Ã©tablissements prÃªteurs, des conditions de marchÃ© 
immobilier distinctes, ainsi que des disparitÃ©s socio-Ã©conomiques territoriales.

Ces rÃ©sultats suggÃ¨rent que, mÃªme avant lâ€™intÃ©gration Ã  grande Ã©chelle de systÃ¨mes algorithmiques, 
les dÃ©cisions de crÃ©dit nâ€™Ã©taient pas spatialement neutres et sâ€™inscrivaient dÃ©jÃ  dans des logiques 
territorialisÃ©es. Le fait que New York prÃ©sente un taux dâ€™approbation systÃ©matiquement plus Ã©levÃ© peut 
Ãªtre interprÃ©tÃ© comme le reflet dâ€™un marchÃ© plus profond, dâ€™une plus forte concurrence entre prÃªteurs, 
ou dâ€™un meilleur accÃ¨s au crÃ©dit pour certaines catÃ©gories de mÃ©nages. Ã€ lâ€™inverse, le New Jersey apparaÃ®t 
comme un environnement plus contraignant, ce qui constitue un point de comparaison essentiel pour lâ€™analyse 
des transformations induites par le passage au rÃ©gime algorithmique dans les sections suivantes.

Ces Ã©carts interÃ©tatiques servent ainsi de point de dÃ©part analytique pour Ã©valuer si lâ€™Ã¨re de lâ€™IA a 
amplifiÃ©, attÃ©nuÃ© ou recomposÃ© les inÃ©galitÃ©s territoriales prÃ©existantes dans lâ€™accÃ¨s au crÃ©dit.
'''
cohort	state_code	pre_IA	state
0	9.0	0.704873	Connecticut
1	34.0	0.681274	New Jersey
2	36.0	0.729269	New York


### 3.4. Profils de revenu et de montant de prÃªt
#
# ğŸ”— RÃ©fÃ©rence chapitre :
# - Section 2.2 : distribution des revenus et montants de prÃªts
# - Figures 2.2 et 2.3

# 3.4. Distribution des revenus (si 'applicant_income' existe)

fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)

for ax, df, title in zip(
    axes,
    [ai_hmda, ai_acs],
    ["Cohorte IA (HMDA)", "Cohorte IA (HMDA + ACS)"]
):
    s = pd.to_numeric(df["loan_amount"], errors="coerce").dropna()
    s = s.clip(upper=s.quantile(0.99))
    s.hist(ax=ax, bins=50)

    ax.set_title(title)
    ax.set_xlabel("Montant du prÃªt (99e percentile)")
    ax.set_ylabel("Nombre d'observations")

plt.tight_layout()
plt.show()

'''
La figure 2.2 prÃ©sente la distribution des montants de prÃªts pour la cohorte algorithmique (2018â€“2023), 
en comparant la base HMDA standard et la base enrichie HMDA+ACS. Dans les deux cas, les distributions 
affichent une forte asymÃ©trie Ã  droite, caractÃ©ristique des donnÃ©es de crÃ©dit immobilier, avec une 
concentration marquÃ©e des observations dans les tranches de montants relativement faibles et intermÃ©diaires, 
et une longue traÃ®ne correspondant aux prÃªts de trÃ¨s grande valeur.
La troncation au 99e percentile permet de neutraliser lâ€™influence des valeurs extrÃªmes tout en conservant la 
structure centrale de la distribution. Les deux histogrammes prÃ©sentent une forme remarquablement similaire, 
ce qui confirme que lâ€™enrichissement par les donnÃ©es ACS nâ€™altÃ¨re pas la structure des montants de prÃªt observÃ©s, 
mais agit principalement comme un enrichissement informationnel contextuel plutÃ´t que comme une transformation de lâ€™Ã©chantillon.

Ces rÃ©sultats suggÃ¨rent que, dans le rÃ©gime algorithmique, la dynamique du marchÃ© du crÃ©dit reste dominÃ©e par des 
prÃªts de montants modÃ©rÃ©s, tandis que les prÃªts de montants exceptionnellement Ã©levÃ©s reprÃ©sentent une part marginale 
mais non nÃ©gligeable de lâ€™activitÃ©. Cette structure est cohÃ©rente avec lâ€™idÃ©e que les algorithmes interviennent dans 
un environnement oÃ¹ le volume dâ€™activitÃ© est majoritairement concentrÃ© sur des profils de risque standardisÃ©s, tandis 
que les cas extrÃªmes demeurent relativement rares et potentiellement traitÃ©s de maniÃ¨re plus spÃ©cifique.

En bref, Les distributions des montants de prÃªts dans les bases HMDA et HMDA+ACS montrent une asymÃ©trie marquÃ©e Ã  droite, 
avec une concentration importante des observations sur les montants intermÃ©diaires. La similaritÃ© des formes entre les deux 
distributions confirme que lâ€™enrichissement ACS nâ€™altÃ¨re pas la structure des montants de prÃªt, mais apporte principalement 
un complÃ©ment contextuel pour lâ€™analyse des inÃ©galitÃ©s territoriales.
'''

fig, ax = plt.subplots(figsize=(6, 4))

s = ai_acs["acs_median_income"]
s = s[(s > 0) & (s < 2_000_000)].dropna()

ax.hist(s, bins=50, log=True)

ax.set_title("Revenu mÃ©dian de la zone (ACS) â€“ Ã©chelle log")
ax.set_xlabel("Revenu ACS")
ax.set_ylabel("FrÃ©quence (log)")

plt.tight_layout()
plt.show()

'''
La figure 2.3 reprÃ©sente la distribution du revenu mÃ©dian des zones de recensement (tracts) 
issue de lâ€™American Community Survey (ACS) pour la cohorte algorithmique, en utilisant une 
Ã©chelle logarithmique sur lâ€™axe des ordonnÃ©es. Ce choix mÃ©thodologique permet de visualiser 
efficacement une distribution fortement asymÃ©trique, caractÃ©risÃ©e par une concentration importante 
dâ€™observations dans les tranches de revenu intermÃ©diaire et lâ€™existence dâ€™une longue traÃ®ne 
correspondant aux zones les plus aisÃ©es.
La forme de la distribution suggÃ¨re une hÃ©tÃ©rogÃ©nÃ©itÃ© territoriale marquÃ©e des conditions socio-Ã©conomiques 
dans la rÃ©gion Ã©tudiÃ©e. La majoritÃ© des observations se situent dans une plage de revenus mÃ©dians relativement 
Ã©troite, tandis quâ€™un nombre plus restreint de tracts affiche des niveaux de revenu trÃ¨s Ã©levÃ©s. Lâ€™Ã©chelle 
logarithmique met en Ã©vidence la structure rÃ©elle de cette distribution, qui serait difficilement interprÃ©table 
sous une Ã©chelle linÃ©aire en raison de la dominance visuelle des valeurs extrÃªmes.
Ces rÃ©sultats confirment que lâ€™environnement Ã©conomique dans lequel opÃ¨rent les algorithmes de dÃ©cision de crÃ©dit 
est loin dâ€™Ãªtre homogÃ¨ne. Ils fournissent une base empirique essentielle pour lâ€™analyse des disparitÃ©s territoriales 
dâ€™accÃ¨s au crÃ©dit, en montrant que les dÃ©cisions algorithmiques sâ€™inscrivent dans un espace de fortes inÃ©galitÃ©s de 
richesse locale. Cette hÃ©tÃ©rogÃ©nÃ©itÃ© constitue un Ã©lÃ©ment central pour interprÃ©ter les rÃ©sultats ultÃ©rieurs relatifs 
aux biais potentiels et aux mÃ©canismes de fairness.

En bref, La distribution du revenu mÃ©dian des tracts, reprÃ©sentÃ©e en Ã©chelle logarithmique, met en Ã©vidence une forte 
asymÃ©trie et une hÃ©tÃ©rogÃ©nÃ©itÃ© marquÃ©e des territoires. La majoritÃ© des zones se situent dans des niveaux de revenu 
intermÃ©diaires, tandis quâ€™une minoritÃ© de tracts concentre des niveaux de richesse nettement plus Ã©levÃ©s, soulignant 
lâ€™importance du contexte territorial dans lâ€™analyse des dÃ©cisions de crÃ©dit.
'''
"