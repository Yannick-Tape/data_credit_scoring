voici le Bloc 2 : "# ## 4. Mod√®les logit comparatifs (HMDA-only) ‚Äì cohorte pr√©-IA vs IA
#
# üîó R√©f√©rence chapitre :
# - Section 3 : "Mod√®les logit comparatifs"
# - Tableaux 3.1 et 3.2
#
# Ici on estime deux mod√®les logit avec la m√™me sp√©cification :
# - Mod√®le A : pr√©-IA, 2007‚Äì2017 (`pre_ai`)
# - Mod√®le B : IA, 2018‚Äì2023 (`ai_hmda`)

# 4.1. D√©finition de la formule logit commune et estimation

'''
Choix de la sp√©cification des mod√®les : alternatives m√©thodologiques et justification
La construction des mod√®les logit comparatifs entre la p√©riode pr√©-algorithmique (2007‚Äì2017) 
et la p√©riode algorithmique (2018‚Äì2023) a n√©cessit√© un arbitrage m√©thodologique important, li√© 
aux limites structurelles des bases de donn√©es disponibles. En th√©orie, une sp√©cification 
enrichie aurait pu int√©grer des variables continues d√©crivant la situation financi√®re des 
emprunteurs, notamment le montant du pr√™t demand√© (loan_amount) et le revenu individuel (applicant_income)
, g√©n√©ralement consid√©r√©es comme des d√©terminants centraux des d√©cisions d‚Äôoctroi de cr√©dit.

Plusieurs strat√©gies alternatives ont √©t√© envisag√©es.
Une premi√®re option consistait √† estimer des mod√®les asym√©triques, en incluant loan_amount uniquement 
dans la cohorte IA, et en conservant une sp√©cification plus pauvre pour la cohorte pr√©-IA. Bien que 
techniquement faisable, cette approche aurait compromis la comparabilit√© directe des coefficients 
entre les deux r√©gimes, puisque les mod√®les n‚Äôauraient pas repos√© sur la m√™me information. Dans ce cas, 
toute diff√©rence observ√©e entre les p√©riodes aurait pu refl√©ter autant une diff√©rence de sp√©cification 
qu‚Äôun changement r√©el de logique d√©cisionnelle.

Une deuxi√®me alternative aurait √©t√© de restreindre l‚Äôanalyse √† la cohorte IA enrichie par les donn√©es 
ACS, et de substituer au revenu individuel des variables de contexte territorial (revenu m√©dian de la 
zone, taux de pauvret√©, ch√¥mage local). Cette approche est pertinente pour analyser les disparit√©s socio-spatiales, 
mais elle ne permet pas de maintenir un strict parall√®le avec la p√©riode pr√©-IA, qui ne dispose pas de variables 
√©quivalentes. Elle aurait donc d√©plac√© l‚Äôobjet de l‚Äôanalyse, en passant d‚Äôune comparaison de r√©gimes d√©cisionnels 
√† une analyse transversale propre √† la seule p√©riode algorithmique.

Une troisi√®me possibilit√© aurait √©t√© d‚Äôintroduire des imputations statistiques ou des proxys de revenu pour la p√©riode 
pr√©-IA, √† partir de donn√©es agr√©g√©es externes. Toutefois, une telle strat√©gie aurait introduit un niveau d‚Äôincertitude 
m√©thodologique √©lev√©, difficilement d√©fendable dans un cadre de recherche doctorale ax√©e sur la robustesse et la 
transparence des inf√©rences.

Compte tenu de ces contraintes, le choix m√©thodologique retenu repose sur le principe de parcimonie comparablistique : les 
mod√®les A (pr√©-IA) et B (IA) sont estim√©s avec une sp√©cification strictement identique, limit√©e aux variables effectivement 
observ√©es et communes aux deux cohortes. Cette sp√©cification inclut uniquement la finalit√© du pr√™t, le type de pr√™t, le statut 
HOEPA et une tendance temporelle, excluant volontairement toute variable absente d‚Äôau moins une des p√©riodes.

Ce choix permet de garantir que les diff√©rences estim√©es entre les deux mod√®les refl√®tent effectivement des transformations 
dans la structure des d√©cisions de cr√©dit, et non des artefacts li√©s √† une asym√©trie d‚Äôinformation entre les bases. Il offre 
ainsi un cadre d‚Äôidentification plus cr√©dible pour analyser la transition d‚Äôun r√©gime domin√© par la d√©cision humaine 
discr√©tionnaire vers un r√©gime caract√©ris√© par une plus forte formalisation algorithmique.

En ce sens, l‚Äôadoption d‚Äôune sp√©cification commune peut √™tre interpr√©t√©e non comme une limitation, mais comme une condition 
de validit√© interne de la comparaison intertemporelle, assurant que les contrastes observ√©s entre les coefficients du mod√®le 
A et du mod√®le B traduisent bien des diff√©rences structurelles de comportement institutionnel, plut√¥t que des effets m√©caniques
de disponibilit√© des donn√©es.

En bref, Plusieurs sp√©cifications alternatives ont √©t√© envisag√©es, notamment l‚Äôint√©gration asym√©trique du montant 
du pr√™t uniquement dans la cohorte IA ou l‚Äôutilisation de proxys territoriaux du revenu issus de l‚ÄôACS. 
Ces approches ont √©t√© √©cart√©es afin de pr√©server la comparabilit√© stricte des mod√®les. Le choix a √©t√© fait 
d‚Äôestimer deux mod√®les logit reposant sur une sp√©cification strictement identique, limit√©e aux variables 
communes aux deux p√©riodes, afin de garantir que les diff√©rences observ√©es refl√®tent bien une transformation 
du r√©gime d√©cisionnel et non une simple asym√©trie d‚Äôinformation entre les bases.
'''

def remove_rare_categories(df, col, min_freq=5000):
    counts = df[col].value_counts()
    keep = counts[counts >= min_freq].index
    return df[df[col].isin(keep)]

# Nettoyage des cat√©gories probl√©matiques
for col in ["loan_purpose", "loan_type", "hoepa_status"]:
    pre_ai = remove_rare_categories(pre_ai, col)
    ai_hmda = remove_rare_categories(ai_hmda, col)

logit_formula_stable = (
    "approved ~ C(loan_purpose) + C(loan_type) + C(hoepa_status) + year"
)

logit_pre = smf.logit(logit_formula_stable, data=pre_ai).fit(disp=False)
print("=== Mod√®le pr√©-IA (stable) ===")
print(logit_pre.summary())

logit_ai = smf.logit(logit_formula_stable, data=ai_hmda).fit(disp=False)
print("=== Mod√®le IA (stable) ===")
print(logit_ai.summary())

'''
    # Commentaire interpr√©tatif ‚Äì Mod√®les logit pr√©-IA vs IA (HMDA-only)
Les r√©sultats pr√©sent√©s dans les tableaux 3.1 (p√©riode pr√©-IA) et 3.2 (p√©riode IA) mettent en √©vidence 
une transformation profonde de la structure des d√©cisions d‚Äôoctroi de cr√©dit entre les deux r√©gimes.
Dans la p√©riode pr√©-algorithmique (2007‚Äì2017), le mod√®le pr√©sente un pseudo R¬≤ d‚Äôenviron 0,03, ce qui 
indique une capacit√© explicative relativement faible des variables observ√©es issues du reporting HMDA. 
Cette faible performance sugg√®re que les d√©cisions d‚Äôoctroi reposaient largement sur des √©l√©ments non 
observables dans les donn√©es standardis√©es, tels que le jugement discr√©tionnaire des underwriters, des 
informations qualitatives issues de la relation bancaire, ou des processus internes propres aux institutions 
financi√®res. N√©anmoins, certaines variables contractuelles conservent un pouvoir explicatif significatif : certaines 
finalit√©s de pr√™t sont associ√©es √† des probabilit√©s d‚Äôapprobation plus √©lev√©es, tandis que plusieurs types de 
pr√™ts pr√©sentent des p√©nalit√©s statistiques robustes.
√Ä l‚Äôinverse, dans la p√©riode algorithmique (2018‚Äì2023), le mod√®le atteint un pseudo R¬≤ d‚Äôenviron 0,38, ce qui 
traduit une structuration beaucoup plus forte des d√©cisions autour de r√®gles explicites et codifiables. 
Les coefficients associ√©s aux finalit√©s de pr√™t pr√©sentent des amplitudes beaucoup plus marqu√©es, avec 
certaines cat√©gories fortement favoris√©es et d‚Äôautres quasi syst√©matiquement rejet√©es. Le statut HOEPA 
appara√Æt comme un d√©terminant particuli√®rement discriminant, traduisant l‚Äôint√©gration de contraintes 
r√©glementaires et de filtres de risque directement incorpor√©s dans les logiques d√©cisionnelles. 
La tendance temporelle est √©galement beaucoup plus prononc√©e, sugg√©rant un ajustement dynamique du seuil 
d‚Äôacceptation au cours de la p√©riode algorithmique.

    # Justification du choix de sp√©cification commune
Le choix de cette sp√©cification repose sur une contrainte structurelle majeure li√©e √† la disponibilit√© des donn√©es. 
La base pr√©-IA ne contient ni le montant du pr√™t (loan_amount), ni le revenu individuel de l‚Äôemprunteur (applicant_income). 
La base IA (HMDA-only) contient le montant du pr√™t, mais ne dispose pas non plus d‚Äôune variable de revenu individuel. 
En cons√©quence, il est impossible de construire des variables transform√©es homog√®nes telles que log_loan_amount et 
log_income de mani√®re coh√©rente sur l‚Äôensemble de l‚Äô√©chantillon.

Plusieurs alternatives ont √©t√© envisag√©es, notamment l‚Äôestimation de mod√®les enrichis sp√©cifiques √† la p√©riode IA, 
ou l‚Äôutilisation de proxys territoriaux issus de l‚ÄôACS. Ces options ont √©t√© volontairement √©cart√©es dans le cadre de 
la comparaison principale, car elles auraient rompu la sym√©trie informationnelle entre les deux p√©riodes. Le choix a 
donc √©t√© fait de privil√©gier une approche de comparabilit√© stricte, en estimant deux mod√®les reposant sur une sp√©cification 
rigoureusement identique et limit√©e aux variables r√©ellement observ√©es dans les deux cohortes.

Ce choix m√©thodologique permet d‚Äôinterpr√©ter les diff√©rences entre les coefficients du mod√®le pr√©-IA et du mod√®le IA comme 
le reflet d‚Äôune transformation r√©elle du r√©gime d√©cisionnel, et non comme un artefact li√© √† une asym√©trie de donn√©es. Autrement 
dit, la diff√©rence de performance et de structure entre les deux mod√®les constitue un indice empirique robuste d‚Äôune formalisation 
accrue des r√®gles d‚Äôoctroi dans la p√©riode post-2017.

    # En bref,
Les estimations comparatives des mod√®les logit r√©v√®lent une rupture nette entre les p√©riodes pr√©-IA et IA. Alors que les 
d√©cisions d‚Äôoctroi apparaissent faiblement expliqu√©es par les variables observables durant la p√©riode pr√©-algorithmique, 
elles deviennent beaucoup plus syst√©matiques et pr√©visibles dans la p√©riode algorithmique. Ce contraste soutient l‚Äôhypoth√®se 
d‚Äôune mont√©e en puissance de r√®gles formalis√©es et de proc√©dures automatis√©es dans le processus d‚Äôoctroi du cr√©dit.

'''
=== Mod√®le pr√©-IA (stable) ===
                           Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:             13511720
Model:                          Logit   Df Residuals:                 13511713
Method:                           MLE   Df Model:                            6
Date:                Mon, 24 Nov 2025   Pseudo R-squ.:                 0.02917
Time:                        18:59:22   Log-Likelihood:            -7.9359e+06
converged:                       True   LL-Null:                   -8.1744e+06
Covariance Type:            nonrobust   LLR p-value:                     0.000
==========================================================================================
                             coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------------------
Intercept                -20.0442      0.390    -51.418      0.000     -20.808     -19.280
C(loan_purpose)[T.2.0]     1.0863      0.003    342.960      0.000       1.080       1.093
C(loan_purpose)[T.3.0]    -0.0148      0.001    -11.440      0.000      -0.017      -0.012
C(loan_type)[T.2.0]       -0.7786      0.002   -510.010      0.000      -0.782      -0.776
C(loan_type)[T.3.0]       -0.4629      0.004   -118.745      0.000      -0.471      -0.455
C(loan_type)[T.4.0]       -0.5534      0.008    -68.006      0.000      -0.569      -0.537
year                       0.0105      0.000     53.950      0.000       0.010       0.011
==========================================================================================
=== Mod√®le IA (stable) ===
                           Logit Regression Results                           
==============================================================================
Dep. Variable:               approved   No. Observations:               569500
Model:                          Logit   Df Residuals:                   569490
Method:                           MLE   Df Model:                            9
Date:                Mon, 24 Nov 2025   Pseudo R-squ.:                  0.3812
Time:                        18:59:39   Log-Likelihood:            -2.4301e+05
converged:                       True   LL-Null:                   -3.9270e+05
Covariance Type:            nonrobust   LLR p-value:                     0.000
=========================================================================================
                            coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------
Intercept              -213.3616      4.705    -45.351      0.000    -222.583    -204.141
C(loan_purpose)[T.2]      0.3186      0.016     20.012      0.000       0.287       0.350
C(loan_purpose)[T.4]      0.3594      0.017     20.999      0.000       0.326       0.393
C(loan_purpose)[T.5]     -4.6193      0.088    -52.375      0.000      -4.792      -4.446
C(loan_purpose)[T.31]     0.3716      0.010     37.261      0.000       0.352       0.391
C(loan_purpose)[T.32]     0.3505      0.011     32.863      0.000       0.330       0.371
C(loan_type)[T.2]        -0.7475      0.011    -69.893      0.000      -0.768      -0.727
C(loan_type)[T.3]        -0.4651      0.017    -27.020      0.000      -0.499      -0.431
C(hoepa_status)[T.3]     -3.5122      0.008   -432.025      0.000      -3.528      -3.496
year                      0.1064      0.002     45.673      0.000       0.102       0.111
=========================================================================================
Variable / Indicateur	Pr√©-IA (2007‚Äì2017)	IA (2018‚Äì2023)	Interpr√©tation comparative
Nombre d‚Äôobservations	13 511 720	569 500	Forte asym√©trie d‚Äô√©chantillons entre p√©riodes, mais stabilit√© des r√©sultats structurels.
Pseudo R¬≤	0,029	0,381	Le mod√®le explique tr√®s peu de variance en pr√©-IA, mais devient tr√®s explicatif en r√©gime IA ‚Üí d√©cisions plus codifi√©es.
Effet loan_purpose (g√©n√©ral)	Effets h√©t√©rog√®nes, un cas fortement favorable (T.2.0)	Effets structur√©s, plusieurs cat√©gories favoris√©es	Passage d‚Äôun sch√©ma flou √† un sch√©ma d√©cisionnel standardis√©.
loan_purpose = 2	Coef ‚âà +1,09 (odds √ó2,96)	Coef ‚âà +0,32 (odds √ó1,38)	Impact toujours positif mais plus mod√©r√© en r√©gime IA.
loan_purpose = 3	Coef ‚âà ‚àí0,015 (quasi neutre)	Non pr√©sent	Diff√©rences de codification entre p√©riodes.
loan_purpose = 5	Non pr√©sent	Coef ‚âà ‚àí4,62 (odds √ó0,01)	En IA : cat√©gorie pratiquement automatiquement rejet√©e.
loan_purpose = 31‚Äì32	Non pr√©sent	Coef ‚âà +0,35 √† +0,37	En IA : cat√©gories syst√©matiquement favoris√©es.
Effet loan_type (g√©n√©ral)	Tous les types alternatifs p√©nalis√©s	M√™me structure de p√©nalisation	Continuit√© du syst√®me de pr√©f√©rence de risque entre r√©gimes.
loan_type = 2	Coef ‚âà ‚àí0,78 (odds √ó0,46)	Coef ‚âà ‚àí0,75 (odds √ó0,47)	Effet n√©gatif stable dans le temps.
loan_type = 3	Coef ‚âà ‚àí0,46 (odds √ó0,63)	Coef ‚âà ‚àí0,47 (odds √ó0,63)	Stabilit√© remarquable des p√©nalit√©s.
loan_type = 4	Coef ‚âà ‚àí0,55	Non pr√©sent	Diff√©rences de structure des donn√©es entre cohortes.
Effet HOEPA (hoepa_status)	Non discriminant / non structur√©	Coef ‚âà ‚àí3,51 (odds √ó0,03)	En IA : filtrage du risque tr√®s agressif sur produits √† risque.
Effet du temps (year)	Coef ‚âà +0,0105 (~+1,1 %/an)	Coef ‚âà +0,1064 (~+11 %/an)	Acc√©l√©ration forte de l‚Äôassouplissement post-IA.
Lecture globale	D√©cisions peu explicables par variables HMDA	D√©cisions fortement gouvern√©es par r√®gles observables	Transition vers d√©cision algorithmique plus standardis√©e.
# %% [markdown]
# ## 5. Disparit√©s raciales ‚Äì mod√®les logit avec race/ethnicit√©
#
# üîó R√©f√©rence chapitre :
# - Section 4 : "Disparit√©s raciales pr√©-IA vs IA"
# - Tableaux 4.1 et 4.2
#
# Hypoth√®se :
# - Variables de race : `race_white`, `race_black`, `race_hispanic`, etc. OU `applicant_race_1_name`.
# Adapter la formule √† ton encoding r√©el.


# On repart de la formule stable commune (sans race)
logit_formula_stable = (
    "approved ~ C(loan_purpose) + C(loan_type) + C(hoepa_status) + year"
)

print("Colonnes pr√©-IA :", [c for c in pre_ai.columns if "race" in c.lower() or "ethnic" in c.lower()])
print("Colonnes IA     :", [c for c in ai_hmda.columns if "race" in c.lower() or "ethnic" in c.lower()])

# 5.1. Mod√®le avec race pour la cohorte IA uniquement
if "derived_race" in ai_hmda.columns:
    logit_formula_ia_race = logit_formula_stable + " + C(derived_race)"
elif "derived_ethnicity" in ai_hmda.columns:
    logit_formula_ia_race = logit_formula_stable + " + C(derived_ethnicity)"
else:
    raise ValueError("Aucune variable de race/ethnicit√© trouv√©e dans ai_hmda.")

# Estimation mod√®le IA avec race
logit_ai_race = smf.logit(logit_formula_ia_race, data=ai_hmda.dropna()).fit(disp=False)
print(logit_ai_race.summary().tables[1])

Colonnes pr√©-IA : []
Colonnes IA     : ['derived_ethnicity', 'derived_race']
================================================================================================================================
                                                                   coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------------------------------------
Intercept                                                     -268.7664      4.834    -55.597      0.000    -278.241    -259.292
C(loan_purpose)[T.2]                                             0.3019      0.016     18.456      0.000       0.270       0.334
C(loan_purpose)[T.4]                                             0.3427      0.018     19.543      0.000       0.308       0.377
C(loan_purpose)[T.5]                                            -4.1515      0.101    -41.291      0.000      -4.349      -3.954
C(loan_purpose)[T.31]                                            0.3932      0.010     38.742      0.000       0.373       0.413
C(loan_purpose)[T.32]                                            0.3880      0.011     35.646      0.000       0.367       0.409
C(loan_type)[T.2]                                               -0.6386      0.011    -58.219      0.000      -0.660      -0.617
C(loan_type)[T.3]                                               -0.3850      0.017    -22.135      0.000      -0.419      -0.351
C(hoepa_status)[T.3]                                            -3.6233      0.008   -426.523      0.000      -3.640      -3.607
C(derived_race)[T.American Indian or Alaska Native]             -0.0203      0.129     -0.157      0.875      -0.274       0.233
C(derived_race)[T.Asian]                                         0.4341      0.108      4.013      0.000       0.222       0.646
C(derived_race)[T.Black or African American]                     0.1389      0.108      1.283      0.199      -0.073       0.351
C(derived_race)[T.Free Form Text Only]                          -0.2858      0.238     -1.200      0.230      -0.753       0.181
C(derived_race)[T.Joint]                                         0.3687      0.112      3.301      0.001       0.150       0.588
C(derived_race)[T.Native Hawaiian or Other Pacific Islander]    -0.0758      0.140     -0.540      0.589      -0.351       0.199
C(derived_race)[T.Race Not Available]                           -0.7873      0.108     -7.321      0.000      -0.998      -0.577
C(derived_race)[T.White]                                         0.2776      0.107      2.585      0.010       0.067       0.488
year                                                             0.1338      0.002     55.925      0.000       0.129       0.138
================================================================================================================================

'''
    # Analyse fairness :

Les r√©sultats du mod√®le logit int√©grant les variables de race pour la p√©riode IA (2018‚Äì2023) mettent en 
√©vidence une reconfiguration des dynamiques de fairness sous r√©gime algorithmique.
Contrairement aux attentes issues de la litt√©rature sur la discrimination historique du cr√©dit, le mod√®le 
ne d√©tecte aucune p√©nalit√© statistiquement significative associ√©e aux emprunteurs noirs, une fois contr√¥l√©s 
les d√©terminants structurels du pr√™t (type, finalit√©, statut HOEPA, ann√©e).

Ce r√©sultat sugg√®re une transition d‚Äôun r√©gime de discrimination potentiellement directe vers des logiques 
de s√©lection davantage indirectes, structurelles ou informationnelles.

   ## Trois r√©gularit√©s fortes √©mergent :
        1. Avantage relatif pour certains groupes
Les emprunteurs asiatiques et blancs b√©n√©ficient d‚Äôun avantage statistiquement significatif, ce qui sugg√®re 
que les algorithmes capturent des signaux corr√©l√©s √† des profils historiquement favoris√©s (stabilit√© patrimoniale, 
zones g√©ographiques, type de produits financiers).

        2. P√©nalit√© informationnelle comme proxy de risque
La variable Race Not Available est tr√®s fortement p√©nalis√©e, ce qui indique que les syst√®mes automatis√©s valorisent 
fortement la compl√©tude de l‚Äôinformation. Ce m√©canisme peut produire une forme de discrimination indirecte, car les 
groupes historiquement marginalis√©s sont plus susceptibles d‚Äôavoir des dossiers incomplets.

        3. Effacement de la discrimination explicite
L‚Äôabsence de significativit√© pour les emprunteurs noirs ne signifie pas absence d‚Äôin√©galit√©s, mais plut√¥t une mutation 
de leur nature : la discrimination ne passe plus par la race d√©clar√©e, mais par des variables corr√©l√©es (type de produit, 
localisation, statut r√©glementaire, qualit√© du dossier).

En somme, le r√©gime IA ne supprime pas les in√©galit√©s, il les reconfigure sous une forme plus algorithmique, plus indirecte 
et potentiellement plus difficile √† d√©tecter.
'''

Groupe racial (derived_race)	Coefficient (logit)	p-value	Significativit√©	Odds Ratio (‚âà)	Effet sur la probabilit√© d‚Äôapprobation	Lecture en termes de fairness
Asian	+0.434	< 0.001	Oui	1.54	+54 %	Avantage significatif ‚Üí profil favoris√© par l‚Äôalgorithme
White	+0.278	0.010	Oui	1.32	+32 %	Avantage significatif ‚Üí traitement pr√©f√©rentiel relatif
Joint	+0.369	0.001	Oui	1.45	+45 %	Les dossiers conjoints sont favoris√©s
Black or African American	+0.139	0.199	Non	1.15	Non significatif	Aucune preuve de discrimination directe dans le mod√®le conditionnel
American Indian / Alaska Native	‚àí0.020	0.875	Non	0.98	Non significatif	Pas d‚Äôeffet mesurable
Native Hawaiian / Pacific Islander	‚àí0.076	0.589	Non	0.93	Non significatif	Aucun effet d√©tect√©
Free Form Text Only	‚àí0.286	0.230	Non	0.75	Non significatif	Effet n√©gatif non robuste
Race Not Available	‚àí0.787	< 0.001	Oui	0.46	‚àí54 %	Forte p√©nalit√© ‚Üí discrimination indirecte via qualit√© de l‚Äôinformation
Effet temporel (year)	+0.134	< 0.001	Oui	1.14/an	Hausse annuelle des chances d‚Äôapprobation	L‚Äôalgorithme devient progressivement plus permissif

'''
Les r√©sultats mettent en √©vidence une transformation des m√©canismes de discrimination sous r√©gime algorithmique. 
La race noire n‚Äôest plus associ√©e √† une p√©nalit√© directe statistiquement significative, mais des disparit√©s 
persistent via des canaux indirects, notamment la qualit√© de l‚Äôinformation et les cat√©gories administratives. 
Les emprunteurs asiatiques et blancs b√©n√©ficient d‚Äôun avantage syst√©matique, traduisant une reconfiguration de 
la fairness davantage fond√©e sur la structure informationnelle des dossiers que sur la race d√©clar√©e.
'''

Groupe racial (derived_race)	Coefficient (logit)	Significatif ? (p-value)	Odds ratio approx.	Interpr√©tation conditionnelle (√† caract√©ristiques de pr√™t identiques)
Asian	+0.4341	Oui (p < 0.001)	‚âà 1.54	Les emprunteurs asiatiques ont ‚âà 54 % de chances d‚Äôapprobation en plus que la cat√©gorie de r√©f√©rence.
White	+0.2776	Oui (p ‚âà 0.010)	‚âà 1.32	Les emprunteurs blancs ont ‚âà 32 % de chances d‚Äôapprobation en plus que la cat√©gorie de r√©f√©rence.
Joint (dossier conjoint)	+0.3687	Oui (p ‚âà 0.001)	‚âà 1.45	Les demandes conjointes pr√©sentent ‚âà 45 % de chances d‚Äôapprobation en plus.
Race Not Available	‚àí0.7873	Oui (p < 0.001)	‚âà 0.46	Les dossiers sans information de race ont ‚âà 54 % de chances d‚Äôapprobation en moins ‚Üí forte p√©nalit√©.
American Indian or Alaska Native	‚àí0.0203	Non (p ‚âà 0.875)	‚âà 0.98	Pas de diff√©rence statistiquement d√©tectable par rapport √† la cat√©gorie de r√©f√©rence.
Black or African American	+0.1389	Non (p ‚âà 0.199)	‚âà 1.15	Coefficient positif mais non significatif ‚Üí aucune preuve statistique d‚Äôun traitement diff√©rent.
Native Hawaiian or Other Pacific Islander	‚àí0.0758	Non (p ‚âà 0.589)	‚âà 0.93	Pas d‚Äôeffet significatif identifi√©.
Free Form Text Only	‚àí0.2858	Non (p ‚âà 0.230)	‚âà 0.75	Effet n√©gatif non significatif ‚Üí interpr√©tation prudente.

'''
Lecture : les coefficients sont interpr√©t√©s relativement √† une cat√©gorie de r√©f√©rence implicite. 
Les r√©sultats montrent un avantage significatif pour les emprunteurs asiatiques et blancs, ainsi 
qu‚Äôune forte p√©nalit√© pour les dossiers sans information de race, tandis qu‚Äôaucune diff√©rence 
statistiquement significative n‚Äôest d√©tect√©e pour les emprunteurs noirs dans ce mod√®le conditionnel.
'''

race_cols_pre = [c for c in pre_ai.columns if "race" in c.lower() or "ethnic" in c.lower()]
if len(race_cols_pre) == 0:
    print("‚ö†Ô∏è Aucun indicateur de race/ethnicit√© disponible dans la cohorte pr√©-IA :")
    print("   ‚Üí impossible d‚Äôestimer un mod√®le logit avec race pour 2007‚Äì2017 avec cette base.")


'''
        # Notes pour la section ¬´ Disparit√©s raciales ¬ª / limites m√©thodologiques :

L‚Äôabsence totale d‚Äôindicateur de race ou d‚Äôethnicit√© dans la cohorte pr√©-IA (2007‚Äì2017) a des cons√©quences 
m√©thodologiques majeures pour l‚Äôanalyse des in√©galit√©s. Concr√®tement, cela signifie qu‚Äôil est **impossible 
d‚Äôestimer un mod√®le logit conditionnel int√©grant la race** pour la p√©riode pr√©-algorithmique √† partir de 
cette base. On ne peut donc pas comparer de mani√®re sym√©trique les coefficients raciaux entre le r√©gime 
pr√©-IA et le r√©gime IA : toute analyse des disparit√©s raciales reste structurellement cantonn√©e √† la p√©riode 2018‚Äì2023.

Cette contrainte limite la port√©e des conclusions en termes d‚Äô√©volution historique de la discrimination. 
On peut montrer, pour la cohorte IA, comment les probabilit√©s d‚Äôapprobation varient selon la race, toutes 
choses √©gales par ailleurs, mais on ne peut pas dire si ces √©carts se sont accentu√©s, r√©duits ou simplement 
reconfigur√©s** par rapport √† la p√©riode ant√©rieure. En d‚Äôautres termes, l‚Äôanalyse de fairness est transversale 
pour la p√©riode algorithmique, mais ne peut pas √™tre pleinement intertemporelle.

En pratique, cela impose une strat√©gie en deux temps :
    1. utiliser des mod√®les **sans race** pour comparer la structure globale des d√©cisions pr√©-IA vs IA (sp√©cification commune, 
        centr√©e sur les caract√©ristiques du pr√™t) ;
    2. analyser les **disparit√©s raciales uniquement dans le r√©gime IA**, en reconnaissant explicitement que cette partie de 
        l‚Äôanalyse ne dispose pas de contre-factuel direct avant 2018.

Cette limitation n‚Äôinvalide pas les r√©sultats, mais elle doit √™tre clairement assum√©e comme une contrainte 
de donn√©es : les conclusions sur la fairness raciale portent sur l‚Äôarchitecture algorithmique contemporaine, 
et non sur une trajectoire longue de la discrimination de 2007 √† 2023.

'''
‚ö†Ô∏è Aucun indicateur de race/ethnicit√© disponible dans la cohorte pr√©-IA :
   ‚Üí impossible d‚Äôestimer un mod√®le logit avec race pour 2007‚Äì2017 avec cette base.

"